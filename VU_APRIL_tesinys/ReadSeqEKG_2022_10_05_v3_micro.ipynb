{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perdarytas iš ReadSeqEKG_2022_10_05_v2.py, tam kad perdaryti pūpsnių klasifikaciją su su micro moduliu. \n",
    "# \n",
    "# Skriptas užduoto ilgio sekų skaitymui iš MIT2ZIVE EKG įrašų ir požymių skaičiavimui.\n",
    "# Skriptą atsiuntė Povilas 2022 10 05, tam kad išsiaiškinti, kodėl nesutampa pavasario ir vasaros\n",
    "# požymių ilgiai. Pasirodė, kad požymių skaičius pasikeitė, nes 'vasaros' požymiuose dingo požymis\n",
    "# Rl/Rr.\n",
    "# Atsiųstas skriptas dar dirba su senesniu duomenų variantu:\n",
    "# Nuoroda į aplanką su EKG įrašais (.npa) ir anotacijomis (.json) - dar nepataisyti įrašai npa į npy\n",
    "# db_path = Path(db_path, 'records')  # all_beats_attr šiame aplanke dar su apskaičiuotais RR1 ir RR2\n",
    "\n",
    "# Šis skriptas perdarytas darbui su naujesniais duomenimis:  all_beats_attr jau be apskaičiuotų RR1 ir RR2\n",
    "# ir naudoja npy failus. apply_FDA perpavadintas į apply_FDA_vasara\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys, json\n",
    "import math\n",
    "import random\n",
    "\n",
    "import scipy.signal\n",
    "import skfda\n",
    "from skfda import FDataGrid\n",
    "from skfda.preprocessing.smoothing import BasisSmoother\n",
    "from skfda.representation.basis import BSpline, Fourier\n",
    "from matplotlib import pyplot as plt\n",
    "from zive_cnn_fda_vu_v1 import get_seq_start_end\n",
    "from zive_cnn_fda_vu_v1 import read_seq_from_signal\n",
    "# from zive_cnn_fda_vu_v1 import read_RR_arr_from_signal\n",
    "from zive_util_vu import get_filename, split_SubjCode \n",
    "from zive_util_vu import zive_read_df_rpeaks\n",
    "\n",
    "def read_RR_arr_from_signal(atr_sample, idx, nl_steps, nr_steps):\n",
    "# Nuskaito ir pateikia EKG seką apie R dantelį seq: reikšmiu kiekis wl_side - iš kairės pusės, \n",
    "# reikšmiu kiekis wr_side - iš dešinės pusės, R dantelio vietą EKG įraše sample,\n",
    "# ir atitinkamo pūpsnio klasės numerį label: 0, 1, 2.\n",
    "# Taip pat pateikia seką RRl_arr iš nl_steps RR reikšmių tarp iš eilės einančių R dantelių į kairę nuo einamo R dantelio \n",
    "# ir seką RRr_arr nr_steps RR reikšmių tarp iš eilės einančių R dantelių į dešinę nuo einamo R dantelio dantelio.\n",
    "# Seka iš kairės RRl_arr prasideda nuo tolimiausio nuo R dantelio atskaitymo ir jai pasibaigus,\n",
    "# toliau ją pratesia RRl_arr. \n",
    "\n",
    "# **************************** Tikrinimai ******************************************************************\n",
    "\n",
    "    # Tikriname, ar skaičiuodami RR neišeisime už atr_sample ribų\n",
    "    if (idx + nr_steps) >= len(atr_sample):\n",
    "        txt = f\"Klaida 1! idx, nl_steps: {idx}, {nr_steps} Skaičiuojant RR viršijama pūpsnių atributo masyvo riba.\" \n",
    "        raise Exception(txt)  \n",
    "        # Reikia mažinti nr_steps arba koreguoti viršutinę idx ribą\n",
    "    \n",
    "    if ((idx - nl_steps) < 0):\n",
    "        txt = f\"Klaida 2! idx, nl_steps: {idx}, {nl_steps} Skaičiuojant RR išeinama už pūpsnių atributo masyvo ribų.\"\n",
    "        raise Exception(txt)  \n",
    "        # Reikia mažinti nl_steps arba didinti apatinę idx ribą \n",
    "    \n",
    "# **************************** Tikrinimų pabaiga ******************************************************************\n",
    "\n",
    "    # Suformuojame RR sekas kairėje ir dešinėje idx atžvilgiu\n",
    "    if (nl_steps != 0):\n",
    "        RRl_arr = np.zeros(shape=(nl_steps), dtype=int)\n",
    "        for i in range(nl_steps):\n",
    "            RRl_arr[nl_steps-i-1] = atr_sample[idx-i] - atr_sample[idx-i-1]\n",
    "    else:    \n",
    "        RRl_arr = None\n",
    "\n",
    "    if (nr_steps != 0):\n",
    "        RRr_arr = np.zeros(shape=(nr_steps), dtype=int)\n",
    "        for i in range(nr_steps):\n",
    "            RRr_arr[i] = atr_sample[idx+i+1] - atr_sample[idx+i]\n",
    "    else:\n",
    "        RRr_arr = None        \n",
    "    \n",
    "    return RRl_arr, RRr_arr\n",
    "\n",
    "def create_SubjCode(userNr, recordingNr):\n",
    "    # SubjCode = userNr + recordingNr\n",
    "    # pvz. SubjCode = 10002\n",
    "    if (userNr < 1000):  # duomenys mit2zive\n",
    "        return userNr\n",
    "    else:  # duomenys zive\n",
    "        str_code = str(userNr) + str(recordingNr)\n",
    "        SubjCode = int(str_code)\n",
    "        return SubjCode\n",
    "\n",
    "def get_SubjCode(idx, all_beats_attr):\n",
    "    row = all_beats_attr.loc[idx]\n",
    "    SubjCode = create_SubjCode(row['userNr'], row['recordingNr'])\n",
    "    return SubjCode\n",
    "\n",
    "def read_rec(rec_dir, SubjCode):\n",
    "    file_path = Path(rec_dir, str(SubjCode) + '.npa')\n",
    "    signal = np.load(file_path, mmap_mode='r')\n",
    "    # print(f\"SubjCode: {SubjCode}  signal.shape: {signal.shape}\")\n",
    "    return signal\n",
    "\n",
    "def read_rec_attrib(rec_dir, SubjCode):\n",
    "    # Pritaikyta nuskaityti json informaciją tiek mit2zive, tiek zive atvejams\n",
    "    file_path = Path(rec_dir, str(SubjCode) + '.json')\n",
    "\n",
    "    if (SubjCode > 1000): # zive atvejis\n",
    "        with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "            data = json.loads(f.read())\n",
    "        df = pd.json_normalize(data, record_path =['rpeaks'])\n",
    "    else: # mit2zive atvejis\n",
    "        df = pd.read_json(file_path, orient = 'records')\n",
    "\n",
    "    atr_sample = df['sampleIndex'].to_numpy()\n",
    "    atr_symbol = df['annotationValue'].to_numpy()\n",
    "    return atr_sample, atr_symbol\n",
    "\n",
    "\n",
    "def read_df_rpeaks(rec_dir, SubjCode):\n",
    "    # Pritaikyta nuskaityti json informaciją tiek mit2zive, tiek zive atvejams\n",
    "    file_path = Path(rec_dir, str(SubjCode) + '.json')\n",
    "\n",
    "    if (SubjCode > 1000): # zive atvejis\n",
    "        with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "            data = json.loads(f.read())\n",
    "        df = pd.json_normalize(data, record_path =['rpeaks'])\n",
    "    else: # mit2zive atvejis\n",
    "        df = pd.read_json(file_path, orient = 'records')\n",
    "    return df\n",
    "\n",
    "def get_spike_width(orig, derivate, reample_points, positions):\n",
    "    ret = pd.DataFrame(columns=[\"P_val\", \"Q_val\", \"R_val\", \"S_val\", \"T_val\", \"P_pos\", \"Q_pos\", \"R_pos\", \"S_pos\", \"T_pos\", \"QRS\", \"PR\",\"ST\",\"QT\"])\n",
    "    R = positions[0]\n",
    "    asign = np.sign(derivate)\n",
    "    signchange = ((np.roll(asign, 1) - asign) != 0).astype(int)\n",
    "    #plt.figure()\n",
    "    #plt.plot(signchange)\n",
    "    Q = None\n",
    "    for down in range(positions[0] - 1, 0, -1):\n",
    "        if signchange[down] == 1:\n",
    "            Q = down\n",
    "            break\n",
    "    S = None\n",
    "    times_changed = 0\n",
    "    for up in range(positions[0], reample_points, 1):\n",
    "        if (signchange[up] == 1):\n",
    "            if (times_changed == 1):\n",
    "                S = up\n",
    "                break\n",
    "            else:\n",
    "                times_changed += 1\n",
    "    if (Q != None) & (S != None):\n",
    "        QRS = math.fabs(S-Q)\n",
    "        P=positions[1]\n",
    "        T=positions[2]\n",
    "        PR = math.fabs(Q-P)\n",
    "        ST = math.fabs(T-S)\n",
    "        QT = math.fabs(T-Q)\n",
    "        row = {\"P_val\": orig[P], \"Q_val\":orig[Q], \"R_val\": orig[R], \"S_val\": orig[S], \"T_val\":orig[T],\n",
    "                           \"P_pos\":P * 1./ reample_points, \"Q_pos\":Q * 1./ reample_points,\n",
    "                           \"R_pos\":R * 1./ reample_points, \"S_pos\":S * 1./ reample_points,\n",
    "                           \"T_pos\": T * 1./ reample_points,\n",
    "                           \"QRS\":QRS * 1./ reample_points, \"PR\":PR * 1./ reample_points,\n",
    "                           \"ST\":ST * 1./ reample_points, \"QT\":QT * 1./ reample_points}\n",
    "        ret = pd.DataFrame(row, index=[0])\n",
    "        return ret\n",
    "    else:\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_FDA_vasara(signal, idx_lst, atr_sample):\n",
    "    # randomlist = random.sample(range(0, len(all_beats_attr)), 3)\n",
    "    #basis = BSpline(n_basis=40, domain_range=(0,1), order=3)\n",
    "    # basis = Fourier(n_basis=70, domain_range=(0,1))\n",
    "    #smoother = BasisSmoother(basis = basis, return_basis=True, method='svd')\n",
    "    # count = len(train_set_idx)\n",
    "    count = len(idx_lst)\n",
    "    resapmling_points = 200\n",
    "    fraction_to_drop_l = 0.7\n",
    "    fraction_to_drop_r = 0.7\n",
    "    samples = np.linspace(0, 1, resapmling_points)\n",
    "    nl_RR =1\n",
    "    nr_RR = 1\n",
    "    keys_RR = []\n",
    "    for tmp_l in range(nl_RR):\n",
    "        keys_RR.append('RR_l_' + str(tmp_l))\n",
    "    for tmp_l in range(nl_RR - 1):\n",
    "        keys_RR.append('RR_l_' + str(tmp_l) + '/' + 'RR_l_' + str(tmp_l + 1))\n",
    "    for tmp_r in range(nr_RR):\n",
    "        keys_RR.append('RR_r_' + str(tmp_r))\n",
    "    for tmp_r in range(nr_RR):\n",
    "        keys_RR.append('RR_r_' + str(tmp_r) + '/' + 'RR_r_' + str(tmp_r + 1))\n",
    "\n",
    "    # print(f'FDA keys_RR: {keys_RR}')\n",
    "\n",
    "    train_set_stats = pd.DataFrame()\n",
    "    train_set_points = pd.DataFrame()\n",
    "    Rythm_Data = pd.DataFrame()\n",
    "    omit_idx = pd.DataFrame()\n",
    "\n",
    "    for idx in idx_lst:\n",
    "        RRl, RRr = read_RR_arr_from_signal(atr_sample, idx, nl_steps=1, nr_steps=1)\n",
    "        wl_side = math.floor(RRl[0] * fraction_to_drop_l)  # pakeista all_beats_attr.loc[idx][5] į RRl, kj\n",
    "        wr_side = math.floor(RRr[0] * fraction_to_drop_r)  # pakeista all_beats_attr.loc[idx][6] į RRr, kj\n",
    "        seq_1d = read_seq_from_signal(signal, atr_sample, idx, wl_side, wr_side)\n",
    "        # print(f'idx: {idx}')\n",
    "        # print(f'FDA wl_side: {wl_side} wr_side: {wr_side}')\n",
    "       \n",
    "        RPT = []\n",
    "        # seq_1d, sample, label, RRl, RRr = read_seq_RR_arr(db_path, all_beats_attr, idx, wl_side, wr_side,nl_RR, nr_RR)\n",
    "        dictRR = {}\n",
    "        for tmp_l in range(nl_RR):\n",
    "            dictRR[keys_RR[tmp_l]] = RRl[tmp_l]\n",
    "        for tmp_l in range(nl_RR - 1):\n",
    "            dictRR[keys_RR[tmp_l + nl_RR]] = RRl[tmp_l] / RRl[tmp_l + 1]\n",
    "            #keys_RR.append('RR_l_' + str(tmp_l) + '/' + 'RR_l_' + str(tmp_l + 1))\n",
    "        for tmp_r in range(nr_RR):\n",
    "            dictRR[keys_RR[tmp_r + 2 * nl_RR - 1]] = RRr[tmp_r]\n",
    "        for tmp_r in range(nr_RR - 1):\n",
    "            dictRR[keys_RR[tmp_r + 3 * nl_RR - 1]] = RRr[tmp_r] / RRr[tmp_r + 1]\n",
    "        dictRR['RR_r/RR_l'] = RRl[tmp_r] / RRr[tmp_l]\n",
    "        # print(f'FDA dictRR: {dictRR}')\n",
    "\n",
    "        fd = FDataGrid(data_matrix=seq_1d)\n",
    "\n",
    "        fdd = fd.derivative()\n",
    "        fd = fd.evaluate(samples)\n",
    "        fd = fd.reshape(resapmling_points)\n",
    "\n",
    "        fdd = fdd.evaluate(samples)\n",
    "        fdd = fdd.reshape(resapmling_points)\n",
    "\n",
    "        RPT.append(fd.argmax()) #0-th  element is R\n",
    "        \n",
    "        # print(f'RPT: {RPT}')\n",
    "\n",
    "        indexes_lower = scipy.signal.argrelextrema(fdd[math.floor(RPT[0]*0.5):RPT[0] - math.floor(RPT[0]*0.05)], comparator=np.greater, order=3)\n",
    "        indexes_lower = tuple([math.floor(RPT[0]*0.5) + 1 + x for x in indexes_lower])\n",
    "        values_lower = fd[indexes_lower]\n",
    "        ind_low = np.argpartition(values_lower, -1)[-1:]\n",
    "        ind_low[::-1].sort()\n",
    "\n",
    "        indexes_upper = scipy.signal.argrelextrema(fdd[RPT[0] + 2:math.floor(RPT[0]*1.8)], comparator=np.greater, order=3) + RPT[0] + 2\n",
    "        values_upper = fd[indexes_upper[0]]\n",
    "        ind_up = np.argpartition(values_upper, -1)[-1:]\n",
    "        tmp1 = np.sort(ind_up)\n",
    "\n",
    "        # if (label != None) & (len(ind_low)>=1) & (len(ind_up)>=1):\n",
    "        if (len(ind_low)>=1) & (len(ind_up)>=1):\n",
    "            RPT.append(indexes_lower[0][ind_low[0]])  # 1-st is P\n",
    "            RPT.append(indexes_upper[0][tmp1[0]]) # 2nd is T\n",
    "            \n",
    "            # print(f'RPT: {RPT}')\n",
    "\n",
    "            tmp = get_spike_width(fd, fdd, resapmling_points, RPT)\n",
    "            # print(f'Rythm_Data: {tmp}')\n",
    "            \n",
    "            if not tmp.empty:\n",
    "                Rythm_Data = pd.concat([Rythm_Data,tmp], axis=0)\n",
    "                # print(\"Processing -- %d; idx -- %d\" % (count, idx))\n",
    "                count -= 1\n",
    "\n",
    "                dict_full ={'idx': idx, 'seq_size': seq_1d.shape[0], 'label': 0}\n",
    "                dict_full = dict(dict_full, **dictRR)\n",
    "                dict_full.update({'wl_side': wl_side, 'wr_side': wr_side, \"signal_mean\": np.mean(fd), \"signal_std\": np.std(fd)})\n",
    "                # print(f'\\nidx, dict_full: {idx}, {dict_full}')\n",
    "                \n",
    "                df_tmp = pd.DataFrame([dict_full])\n",
    "                # print(df_tmp)\n",
    "                train_set_stats = pd.concat([train_set_stats, df_tmp], axis=0)\n",
    "\n",
    "                df_tmp = pd.Series(fd).to_frame().T\n",
    "                train_set_points = pd.concat([train_set_points, df_tmp], axis=0)\n",
    "            else:\n",
    "                omit_idx = pd.concat([omit_idx,pd.DataFrame({'idx': idx})], axis=1)\n",
    "        else:\n",
    "            omit_idx = pd.concat([omit_idx,pd.DataFrame({'idx': idx})], axis=1)\n",
    "\n",
    "    # print(f'\\ntrain_set_stats:')\n",
    "    # print(train_set_stats.head())\n",
    "    \n",
    "    # print(f'\\nRythm_Data:')\n",
    "    # print(Rythm_Data.head())\n",
    "    \n",
    "    # print(f'\\ntrain_set_points:')\n",
    "    # print(train_set_points.head())\n",
    "    \n",
    "    # print(f'\\nomit_idx:')\n",
    "    # print(omit_idx.head())\n",
    "\n",
    "    train_set_stats = pd.concat([train_set_stats, Rythm_Data, train_set_points], axis=1)\n",
    "    \n",
    "    # print(f'\\ntrain_set_stats_united:')\n",
    "    # print(train_set_stats.head())\n",
    "    # print(f'\\nomit_idx:')\n",
    "    # print(omit_idx.head())\n",
    "\n",
    "    return train_set_stats, omit_idx\n",
    "\n",
    "\n",
    "def get_beat_features_fda_vu_v1_vasara(signal, atr_sample, idx):\n",
    "    resapmling_points = 200\n",
    "    fraction_to_drop_l = 0.7\n",
    "    fraction_to_drop_r = 0.7\n",
    "    samples = np.linspace(0, 1, resapmling_points)\n",
    "    nl_RR =1\n",
    "    nr_RR = 1\n",
    "    keys_RR = []\n",
    "    for tmp_l in range(nl_RR):\n",
    "        keys_RR.append('RR_l_' + str(tmp_l))\n",
    "    for tmp_l in range(nl_RR - 1):\n",
    "        keys_RR.append('RR_l_' + str(tmp_l) + '/' + 'RR_l_' + str(tmp_l + 1))\n",
    "    for tmp_r in range(nr_RR):\n",
    "        keys_RR.append('RR_r_' + str(tmp_r))\n",
    "    for tmp_r in range(nr_RR):\n",
    "        keys_RR.append('RR_r_' + str(tmp_r) + '/' + 'RR_r_' + str(tmp_r + 1))\n",
    "\n",
    "    # print(f'idx: {idx}')\n",
    "    # print(f'get keys_RR: {keys_RR}')\n",
    "\n",
    "    train_set_stats = pd.DataFrame()\n",
    "    train_set_points = pd.DataFrame()\n",
    "    Rythm_Data = pd.DataFrame()\n",
    "    omit_idx = pd.DataFrame()\n",
    "\n",
    "    RRl_arr, RRr_arr = read_RR_arr_from_signal(atr_sample, idx, nl_steps=1, nr_steps=1)\n",
    "    wl_side = math.floor(RRl_arr[0] * fraction_to_drop_l)  # pakeista all_beats_attr.loc[idx][5] į RRl, kj\n",
    "    wr_side = math.floor(RRr_arr[0] * fraction_to_drop_r)  # pakeista all_beats_attr.loc[idx][6] į RRr, kj\n",
    "    \n",
    "    # print(f'wl_side: {wl_side} wr_side: {wr_side}')\n",
    "\n",
    "    seq_1d = read_seq_from_signal(signal, atr_sample, idx, wl_side, wr_side)\n",
    "\n",
    "    RPT = []\n",
    "    dictRR = {}\n",
    "    for tmp_l in range(nl_RR):\n",
    "        dictRR[keys_RR[tmp_l]] = RRl_arr[tmp_l]\n",
    "    for tmp_l in range(nl_RR - 1):\n",
    "        dictRR[keys_RR[tmp_l + nl_RR]] = RRl_arr[tmp_l] / RRl_arr[tmp_l + 1]\n",
    "        #keys_RR.append('RR_l_' + str(tmp_l) + '/' + 'RR_l_' + str(tmp_l + 1))\n",
    "    for tmp_r in range(nr_RR):\n",
    "        dictRR[keys_RR[tmp_r + 2 * nl_RR - 1]] = RRr_arr[tmp_r]\n",
    "    for tmp_r in range(nr_RR - 1):\n",
    "        dictRR[keys_RR[tmp_r + 3 * nl_RR - 1]] = RRr_arr[tmp_r] / RRr_arr[tmp_r + 1]\n",
    "    dictRR['RR_r/RR_l'] = RRl_arr[tmp_r] / RRr_arr[tmp_l]\n",
    "    # print(f'dictRR: {dictRR}')\n",
    "    \n",
    "    fd = FDataGrid(data_matrix=seq_1d)\n",
    "\n",
    "    fdd = fd.derivative()\n",
    "    fd = fd.evaluate(samples)\n",
    "    fd = fd.reshape(resapmling_points)\n",
    "\n",
    "    fdd = fdd.evaluate(samples)\n",
    "    fdd = fdd.reshape(resapmling_points)\n",
    "\n",
    "    RPT.append(fd.argmax()) #0-th  element is R\n",
    "    # print(f'RPT: {RPT}')\n",
    "\n",
    "    indexes_lower = scipy.signal.argrelextrema(fdd[math.floor(RPT[0]*0.5):RPT[0] - math.floor(RPT[0]*0.05)], comparator=np.greater, order=3)\n",
    "    indexes_lower = tuple([math.floor(RPT[0]*0.5) + 1 + x for x in indexes_lower])\n",
    "    values_lower = fd[indexes_lower]\n",
    "    ind_low = np.argpartition(values_lower, -1)[-1:]\n",
    "    ind_low[::-1].sort()\n",
    "\n",
    "    indexes_upper = scipy.signal.argrelextrema(fdd[RPT[0] + 2:math.floor(RPT[0]*1.8)], comparator=np.greater, order=3) + RPT[0] + 2\n",
    "    values_upper = fd[indexes_upper[0]]\n",
    "    ind_up = np.argpartition(values_upper, -1)[-1:]\n",
    "    tmp1 = np.sort(ind_up)\n",
    "\n",
    "    if (len(ind_low)>=1) & (len(ind_up)>=1):\n",
    "\n",
    "# I. Rythm_Data: 'P_val', 'Q_val', 'R_val', 'S_val', 'T_val', 'P_pos', 'Q_pos', 'R_pos',\n",
    "#  'S_pos', 'T_pos', 'QRS', 'PR', 'ST', 'QT' - viso 14 požymių\n",
    "\n",
    "        RPT.append(indexes_lower[0][ind_low[0]])  # 1-st is P\n",
    "        RPT.append(indexes_upper[0][tmp1[0]]) # 2nd is T\n",
    "    \n",
    "        # print(f'RPT: {RPT}')\n",
    "\n",
    "        Rythm_Data = get_spike_width(fd, fdd, resapmling_points, RPT)\n",
    "        # print(f'get Rythm_Data {Rythm_Data}')\n",
    "\n",
    "        if not Rythm_Data.empty:\n",
    "\n",
    "# II. train_set_stats\": 'idx', 'seq_size', 'RR_l_0', 'RR_r_0', 'RR_r/RR_l', 'wl_side', 'wr_side',\n",
    "# 'signal_mean', 'signal_std' - viso 9 požymiai\n",
    "\n",
    "            dict_full ={'idx': idx, 'seq_size': seq_1d.shape[0]}\n",
    "            dict_full = dict(dict_full, **dictRR)\n",
    "            dict_full.update({'wl_side': wl_side, 'wr_side': wr_side, \"signal_mean\": np.mean(fd), \"signal_std\": np.std(fd)})\n",
    "            # print(f'dict: {dict_full}')\n",
    "            train_set_stats = pd.DataFrame(dict_full, index=[0])\n",
    "\n",
    "# III. train_set_points: '0', '1', '2', ... , '197', '198', '199' - viso 200 požymių\n",
    "            \n",
    "            train_set_points = pd.Series(fd).to_frame().T\n",
    "        else:\n",
    "            omit_idx = pd.DataFrame({'idx': idx}, index=[0])\n",
    "    else:\n",
    "        omit_idx = pd.DataFrame({'idx': idx}, index=[0])\n",
    "\n",
    "    # print(f'\\ntrain_set_stats:')\n",
    "    # print(train_set_stats.head())\n",
    "    \n",
    "    # print(f'\\nRythm_Data:')\n",
    "    # print(Rythm_Data.head())\n",
    "    \n",
    "    # print(f'\\ntrain_set_points:')\n",
    "    # print(train_set_points.head())\n",
    "    \n",
    "    # print(f'\\nomit_idx:')\n",
    "    # print(omit_idx.head())\n",
    "\n",
    "\n",
    "    train_set_stats = pd.concat([train_set_stats, Rythm_Data, train_set_points], axis=1)\n",
    "\n",
    "    # print(f'\\ntrain_set_stats_united:')\n",
    "    # print(train_set_stats.head())\n",
    "    \n",
    "    # print(f'\\nomit_idx:')\n",
    "    # print(omit_idx.head())\n",
    "\n",
    "    return train_set_stats, omit_idx\n",
    "\n",
    "\n",
    "def get_beat_features_set_fda_vu_v1(signal, df_rpeaks, idx_lst):\n",
    "# Apskaičiuojami užduotų EKG signalo pūpsnių (per idx_lst) požymiai ir iš jų\n",
    "# suformuojamas požymių dataframe masyvas, pridedant 'label'\n",
    "\n",
    "    all_beats = {'N':0,'R':0, 'L':0, 'e':0, 'j':0, 'A':1,'a':1, 'J':1, 'S':1, 'V':2, 'E':2, 'F':3, 'U':3, 'Q':3}\n",
    "\n",
    "    beat_features_set = pd.DataFrame()\n",
    "    omit_idx_set = pd.DataFrame()\n",
    "\n",
    "    atr_sample = df_rpeaks['sampleIndex'].to_numpy()\n",
    "    atr_symbol = df_rpeaks['annotationValue'].to_numpy()\n",
    "    # Jei pasitaiko symbol 'U' arba 'F', pūpsniui suteikiame klasę 3, kurią vėliau apvalysime  \n",
    "    test_labels = np.array([all_beats[symbol] for symbol in atr_symbol])\n",
    "    \n",
    "    # print(\"\\nGet beat features set from signal:\")\n",
    "    for idx in idx_lst:\n",
    "        beat_features, omit_idx = get_beat_features_fda_vu_v1_vasara(signal, atr_sample, idx)\n",
    "        # beat_features_set = beat_features_set.append(beat_features, ignore_index=True)\n",
    "        if omit_idx.empty:\n",
    "            beat_features['label'] = test_labels[idx]\n",
    "            beat_features_set = pd.concat([beat_features_set, beat_features])\n",
    "        else:\n",
    "            omit_idx_set = pd.concat([omit_idx_set, omit_idx])\n",
    "\n",
    "    # Konvertuojame int pozymius į float64\n",
    "    beat_features_set['RR_l_0'] = beat_features_set['RR_l_0'].astype(float)\n",
    "    beat_features_set['RR_r_0'] = beat_features_set['RR_r_0'].astype(float)\n",
    "\n",
    "    return beat_features_set, omit_idx_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS in my system :  win32\n",
      "\n",
      "Bendras MIT ir Zive duomenų aplankas:  D:\\DI\\Data\\MIT&ZIVE\n",
      "MIT2ZIVE EKG įrašų aplankas:  MIT2ZIVE\n",
      "\n",
      "SubjCode: 100 userNr: 100 file_name: 100 signal_length: 361111\n",
      "[    10     42    205 ... 360824 360963 361106]\n",
      "   sampleIndex annotationValue\n",
      "0           10               Q\n",
      "1           42               N\n",
      "2          205               N\n",
      "3          367               N\n",
      "4          525               N\n",
      "5          683               N\n",
      "6          841               N\n",
      "7         1005               N\n",
      "8         1135               A\n",
      "9         1334               N\n",
      "[2, 3, 4, 5]\n",
      "\n",
      "Variantas: apply_FDA_vasara:\n",
      "\n",
      "\n",
      "train_set_data:\n",
      "   idx  seq_size  label  RR_l_0  RR_r_0  RR_r/RR_l  wl_side  wr_side  signal_mean  signal_std     P_val     Q_val     R_val     S_val     T_val  P_pos  Q_pos  R_pos  S_pos  T_pos    QRS     PR     ST     QT         0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43        44        45        46        47        48        49        50        51        52        53        54        55        56        57        58        59        60        61        62        63        64        65        66        67        68        69        70        71        72        73        74        75  ...       100       101  \\\n",
      "0    2       227      0     163     162   1.006173      114      113    -0.314849    0.155551 -0.210547 -0.532434  0.901030 -0.437992 -0.306871  0.350  0.480  0.505  0.530  0.850  0.050  0.130  0.320  0.370 -0.345000 -0.346172 -0.360271 -0.360593 -0.371940 -0.369789 -0.358302 -0.374095 -0.364658 -0.361442 -0.363357 -0.346763 -0.326488 -0.335694 -0.309316 -0.295929 -0.292462 -0.277029 -0.255019 -0.256356 -0.247441 -0.244548 -0.252880 -0.246723 -0.250719 -0.248176 -0.256332 -0.260674 -0.265593 -0.264196 -0.275915 -0.284704 -0.270633 -0.274207 -0.277322 -0.269010 -0.277614 -0.285818 -0.277468 -0.285830 -0.299573 -0.301814 -0.307492 -0.297321 -0.285301 -0.293950 -0.300552 -0.299392 -0.313714 -0.310332 -0.299298 -0.323749 -0.314391 -0.306292 -0.319920 -0.321527 -0.308618 -0.307935 -0.303784 -0.294036 -0.301563 -0.298642 -0.289829 -0.306477 -0.299381 -0.282532 -0.274272 -0.270010 -0.249773 -0.238505 -0.210547 -0.207332 -0.222532 -0.225095 -0.225362 -0.234528  ...  0.728513  0.901030   \n",
      "0    3       223      0     162     158   1.025316      113      110    -0.340495    0.144071 -0.224874 -0.541396  0.843898 -0.453412 -0.319268  0.395  0.490  0.510  0.530  0.835  0.040  0.095  0.305  0.345 -0.427999 -0.432776 -0.450995 -0.443079 -0.452087 -0.459156 -0.453758 -0.461519 -0.468621 -0.448637 -0.439844 -0.428688 -0.388230 -0.364482 -0.348019 -0.323124 -0.324644 -0.325999 -0.307356 -0.303922 -0.316572 -0.305581 -0.312397 -0.310810 -0.302677 -0.310897 -0.318937 -0.306760 -0.307363 -0.310075 -0.298663 -0.305329 -0.314094 -0.312559 -0.314789 -0.323772 -0.319964 -0.328871 -0.337433 -0.331447 -0.339216 -0.345260 -0.333039 -0.338761 -0.343035 -0.324615 -0.340383 -0.343358 -0.332000 -0.347920 -0.355221 -0.343370 -0.345000 -0.343116 -0.331206 -0.339996 -0.346638 -0.339297 -0.343741 -0.349456 -0.333174 -0.339799 -0.335667 -0.334281 -0.338971 -0.339361 -0.317037 -0.301049 -0.286968 -0.267450 -0.263914 -0.249702 -0.229924 -0.227681 -0.243448 -0.240328  ... -0.067007  0.414736   \n",
      "0    4       220      0     158     158   1.000000      110      110    -0.337768    0.136691 -0.248173 -0.606742  0.811256 -0.430214 -0.288670  0.345  0.480  0.505  0.525  0.825  0.045  0.135  0.300  0.345 -0.415001 -0.419899 -0.417792 -0.419330 -0.434400 -0.427461 -0.420000 -0.423518 -0.413740 -0.396526 -0.377846 -0.346413 -0.333411 -0.331934 -0.318078 -0.309522 -0.309176 -0.302331 -0.300002 -0.309096 -0.312891 -0.303549 -0.317900 -0.319078 -0.309297 -0.315537 -0.310865 -0.309142 -0.325469 -0.320769 -0.322423 -0.348844 -0.338054 -0.333216 -0.345507 -0.353412 -0.356563 -0.362157 -0.353989 -0.346486 -0.353245 -0.363670 -0.355771 -0.366505 -0.369667 -0.360479 -0.370596 -0.369764 -0.352990 -0.353703 -0.364492 -0.345503 -0.352169 -0.360386 -0.355002 -0.369778 -0.367298 -0.357273 -0.361148 -0.360137 -0.352761 -0.344739 -0.335139 -0.307673 -0.305432 -0.295878 -0.280669 -0.278467 -0.267319 -0.248173 -0.263494 -0.275509 -0.268127 -0.275337 -0.276436 -0.268395  ...  0.645853  0.811256   \n",
      "0    5       220      0     158     158   1.000000      110      110    -0.333569    0.128838 -0.245452 -0.497076  0.770206 -0.434827 -0.297069  0.335  0.485  0.505  0.525  0.845  0.040  0.150  0.320  0.360 -0.383995 -0.370112 -0.379600 -0.375282 -0.371814 -0.384543 -0.388172 -0.371631 -0.371629 -0.346765 -0.319003 -0.319685 -0.311228 -0.291756 -0.292708 -0.282461 -0.278785 -0.288630 -0.292999 -0.282998 -0.295035 -0.296227 -0.282211 -0.289547 -0.300290 -0.290898 -0.296809 -0.299431 -0.300443 -0.313803 -0.313760 -0.300314 -0.322326 -0.332299 -0.318331 -0.323765 -0.326672 -0.321124 -0.328195 -0.340114 -0.332139 -0.340209 -0.347008 -0.338391 -0.334157 -0.335613 -0.329280 -0.335582 -0.358136 -0.351825 -0.347077 -0.348744 -0.340905 -0.351191 -0.363444 -0.352085 -0.348142 -0.347812 -0.332904 -0.334648 -0.337454 -0.316071 -0.293005 -0.296367 -0.279975 -0.275467 -0.269300 -0.245452 -0.242168 -0.254216 -0.245208 -0.252498 -0.261764 -0.263362 -0.262319 -0.250159  ...  0.579393  0.770206   \n",
      "\n",
      "        102       103       104       105       106       107       108       109       110       111       112       113       114       115       116       117       118       119       120       121       122       123       124       125       126       127       128       129       130       131       132       133       134       135       136       137       138       139       140       141       142       143       144       145       146       147       148       149       150       151       152       153       154       155       156       157       158       159       160       161       162       163       164       165       166       167       168       169       170       171       172       173       174       175       176       177       178       179       180       181       182       183       184       185       186       187       188       189       190       191       192       193       194       195       196       197       198       199  \n",
      "0  0.646788  0.068561 -0.311259 -0.452218 -0.437992 -0.395716 -0.387999 -0.381688 -0.391097 -0.384759 -0.384331 -0.401981 -0.403456 -0.397810 -0.393090 -0.379635 -0.390193 -0.407397 -0.396310 -0.398257 -0.403132 -0.404131 -0.411769 -0.406280 -0.398140 -0.394394 -0.402031 -0.387487 -0.400316 -0.398165 -0.379536 -0.393589 -0.403104 -0.388418 -0.397665 -0.408884 -0.400935 -0.413609 -0.419979 -0.415046 -0.424929 -0.430989 -0.429076 -0.446162 -0.443481 -0.446669 -0.458163 -0.458055 -0.455573 -0.466437 -0.456536 -0.442170 -0.439106 -0.400003 -0.366839 -0.354668 -0.329943 -0.322156 -0.325999 -0.310803 -0.300164 -0.318728 -0.306988 -0.309125 -0.313117 -0.303024 -0.309942 -0.318506 -0.306871 -0.307011 -0.310286 -0.298638 -0.305731 -0.314230 -0.312364 -0.315136 -0.323244 -0.320718 -0.330911 -0.336769 -0.330145 -0.342925 -0.345034 -0.331804 -0.340419 -0.336448 -0.328599 -0.345937 -0.336422 -0.332001 -0.355951 -0.352582 -0.342964 -0.345000 -0.336106 -0.333644 -0.347101 -0.343998  \n",
      "0  0.843898  0.796448  0.039593 -0.464709 -0.453412 -0.401128 -0.390519 -0.397776 -0.401575 -0.393539 -0.397671 -0.404698 -0.401583 -0.411621 -0.412708 -0.412839 -0.427660 -0.418431 -0.408783 -0.425730 -0.419094 -0.412728 -0.416679 -0.404842 -0.398251 -0.407465 -0.399089 -0.399638 -0.417203 -0.423591 -0.416026 -0.420489 -0.417636 -0.404764 -0.415812 -0.409487 -0.397504 -0.399956 -0.386269 -0.393185 -0.402181 -0.408361 -0.411790 -0.418794 -0.419124 -0.413059 -0.434104 -0.431681 -0.420000 -0.422261 -0.417048 -0.400063 -0.381414 -0.350558 -0.333059 -0.333543 -0.320556 -0.309129 -0.309523 -0.303135 -0.300002 -0.308392 -0.312865 -0.302986 -0.317674 -0.319268 -0.309338 -0.315597 -0.310513 -0.309293 -0.326710 -0.320045 -0.325097 -0.347738 -0.336923 -0.334201 -0.348311 -0.352558 -0.358235 -0.362761 -0.351788 -0.347059 -0.356198 -0.360797 -0.357983 -0.370583 -0.365071 -0.360157 -0.376320 -0.365717 -0.350765 -0.357374 -0.356555 -0.347153 -0.358146 -0.356849 -0.355005 -0.383003  \n",
      "0  0.423059 -0.231163 -0.490879 -0.430214 -0.395306 -0.405045 -0.389207 -0.394596 -0.408614 -0.400441 -0.396871 -0.410643 -0.406798 -0.405232 -0.407000 -0.393341 -0.389860 -0.398640 -0.399698 -0.396608 -0.403693 -0.395294 -0.384226 -0.387754 -0.386364 -0.384529 -0.393644 -0.379560 -0.379983 -0.393334 -0.385468 -0.379606 -0.386796 -0.378595 -0.385355 -0.379234 -0.375130 -0.376941 -0.388241 -0.366539 -0.377801 -0.386512 -0.376915 -0.375306 -0.378651 -0.371032 -0.375124 -0.392570 -0.383563 -0.367230 -0.364985 -0.334574 -0.319477 -0.318265 -0.298002 -0.296008 -0.286568 -0.280097 -0.279209 -0.293001 -0.289904 -0.286969 -0.296447 -0.288670 -0.282687 -0.299462 -0.296040 -0.287117 -0.302574 -0.298557 -0.305011 -0.314613 -0.306203 -0.309763 -0.331769 -0.323798 -0.316441 -0.330853 -0.323634 -0.321911 -0.333209 -0.337471 -0.335448 -0.344930 -0.342757 -0.336030 -0.333213 -0.337973 -0.325534 -0.344315 -0.358741 -0.349410 -0.348493 -0.344020 -0.342795 -0.361588 -0.360604 -0.345000  \n",
      "0  0.367520 -0.249638 -0.468012 -0.434827 -0.396240 -0.396033 -0.414238 -0.416993 -0.397446 -0.405314 -0.402128 -0.390499 -0.395000 -0.389423 -0.388292 -0.408977 -0.407264 -0.396404 -0.405731 -0.415067 -0.405523 -0.409171 -0.416231 -0.413808 -0.413646 -0.412179 -0.397170 -0.395002 -0.396325 -0.402663 -0.416329 -0.421456 -0.398454 -0.401218 -0.404987 -0.396849 -0.403699 -0.415667 -0.397350 -0.405931 -0.424999 -0.424628 -0.434864 -0.445277 -0.448045 -0.453873 -0.445375 -0.429373 -0.436985 -0.445656 -0.425021 -0.415766 -0.409105 -0.379969 -0.366286 -0.352531 -0.324370 -0.305321 -0.317353 -0.309818 -0.311535 -0.315326 -0.307137 -0.307081 -0.311365 -0.304937 -0.302116 -0.297069 -0.281200 -0.298280 -0.312995 -0.303001 -0.313729 -0.326175 -0.320804 -0.329833 -0.336552 -0.325118 -0.317717 -0.336145 -0.336626 -0.321693 -0.322883 -0.330406 -0.331388 -0.336761 -0.321897 -0.322989 -0.346626 -0.340841 -0.329923 -0.328576 -0.324543 -0.323970 -0.333492 -0.331005 -0.330000 -0.340000  \n",
      "\n",
      "[4 rows x 224 columns]\n",
      "\n",
      "omitted:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Variantas: get_beat_features_fda_vu_v1_vasara:----------------------------------------------\n",
      "\n",
      "\n",
      "train_set_data:\n",
      "   idx  seq_size  RR_l_0  RR_r_0  RR_r/RR_l  wl_side  wr_side  signal_mean  signal_std     P_val     Q_val     R_val     S_val     T_val  P_pos  Q_pos  R_pos  S_pos  T_pos    QRS     PR     ST     QT         0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26        27        28        29        30        31        32        33        34        35        36        37        38        39        40        41        42        43        44        45        46        47        48        49        50        51        52        53        54        55        56        57        58        59        60        61        62        63        64        65        66        67        68        69        70        71        72        73        74        75        76  ...       101       102  \\\n",
      "0    2       227   163.0   162.0   1.006173      114      113    -0.314849    0.155551 -0.210547 -0.532434  0.901030 -0.437992 -0.306871  0.350  0.480  0.505  0.530  0.850  0.050  0.130  0.320  0.370 -0.345000 -0.346172 -0.360271 -0.360593 -0.371940 -0.369789 -0.358302 -0.374095 -0.364658 -0.361442 -0.363357 -0.346763 -0.326488 -0.335694 -0.309316 -0.295929 -0.292462 -0.277029 -0.255019 -0.256356 -0.247441 -0.244548 -0.252880 -0.246723 -0.250719 -0.248176 -0.256332 -0.260674 -0.265593 -0.264196 -0.275915 -0.284704 -0.270633 -0.274207 -0.277322 -0.269010 -0.277614 -0.285818 -0.277468 -0.285830 -0.299573 -0.301814 -0.307492 -0.297321 -0.285301 -0.293950 -0.300552 -0.299392 -0.313714 -0.310332 -0.299298 -0.323749 -0.314391 -0.306292 -0.319920 -0.321527 -0.308618 -0.307935 -0.303784 -0.294036 -0.301563 -0.298642 -0.289829 -0.306477 -0.299381 -0.282532 -0.274272 -0.270010 -0.249773 -0.238505 -0.210547 -0.207332 -0.222532 -0.225095 -0.225362 -0.234528 -0.230457  ...  0.901030  0.646788   \n",
      "0    3       223   162.0   158.0   1.025316      113      110    -0.340495    0.144071 -0.224874 -0.541396  0.843898 -0.453412 -0.319268  0.395  0.490  0.510  0.530  0.835  0.040  0.095  0.305  0.345 -0.427999 -0.432776 -0.450995 -0.443079 -0.452087 -0.459156 -0.453758 -0.461519 -0.468621 -0.448637 -0.439844 -0.428688 -0.388230 -0.364482 -0.348019 -0.323124 -0.324644 -0.325999 -0.307356 -0.303922 -0.316572 -0.305581 -0.312397 -0.310810 -0.302677 -0.310897 -0.318937 -0.306760 -0.307363 -0.310075 -0.298663 -0.305329 -0.314094 -0.312559 -0.314789 -0.323772 -0.319964 -0.328871 -0.337433 -0.331447 -0.339216 -0.345260 -0.333039 -0.338761 -0.343035 -0.324615 -0.340383 -0.343358 -0.332000 -0.347920 -0.355221 -0.343370 -0.345000 -0.343116 -0.331206 -0.339996 -0.346638 -0.339297 -0.343741 -0.349456 -0.333174 -0.339799 -0.335667 -0.334281 -0.338971 -0.339361 -0.317037 -0.301049 -0.286968 -0.267450 -0.263914 -0.249702 -0.229924 -0.227681 -0.243448 -0.240328 -0.251547  ...  0.414736  0.843898   \n",
      "0    4       220   158.0   158.0   1.000000      110      110    -0.337768    0.136691 -0.248173 -0.606742  0.811256 -0.430214 -0.288670  0.345  0.480  0.505  0.525  0.825  0.045  0.135  0.300  0.345 -0.415001 -0.419899 -0.417792 -0.419330 -0.434400 -0.427461 -0.420000 -0.423518 -0.413740 -0.396526 -0.377846 -0.346413 -0.333411 -0.331934 -0.318078 -0.309522 -0.309176 -0.302331 -0.300002 -0.309096 -0.312891 -0.303549 -0.317900 -0.319078 -0.309297 -0.315537 -0.310865 -0.309142 -0.325469 -0.320769 -0.322423 -0.348844 -0.338054 -0.333216 -0.345507 -0.353412 -0.356563 -0.362157 -0.353989 -0.346486 -0.353245 -0.363670 -0.355771 -0.366505 -0.369667 -0.360479 -0.370596 -0.369764 -0.352990 -0.353703 -0.364492 -0.345503 -0.352169 -0.360386 -0.355002 -0.369778 -0.367298 -0.357273 -0.361148 -0.360137 -0.352761 -0.344739 -0.335139 -0.307673 -0.305432 -0.295878 -0.280669 -0.278467 -0.267319 -0.248173 -0.263494 -0.275509 -0.268127 -0.275337 -0.276436 -0.268395 -0.250153  ...  0.811256  0.423059   \n",
      "0    5       220   158.0   158.0   1.000000      110      110    -0.333569    0.128838 -0.245452 -0.497076  0.770206 -0.434827 -0.297069  0.335  0.485  0.505  0.525  0.845  0.040  0.150  0.320  0.360 -0.383995 -0.370112 -0.379600 -0.375282 -0.371814 -0.384543 -0.388172 -0.371631 -0.371629 -0.346765 -0.319003 -0.319685 -0.311228 -0.291756 -0.292708 -0.282461 -0.278785 -0.288630 -0.292999 -0.282998 -0.295035 -0.296227 -0.282211 -0.289547 -0.300290 -0.290898 -0.296809 -0.299431 -0.300443 -0.313803 -0.313760 -0.300314 -0.322326 -0.332299 -0.318331 -0.323765 -0.326672 -0.321124 -0.328195 -0.340114 -0.332139 -0.340209 -0.347008 -0.338391 -0.334157 -0.335613 -0.329280 -0.335582 -0.358136 -0.351825 -0.347077 -0.348744 -0.340905 -0.351191 -0.363444 -0.352085 -0.348142 -0.347812 -0.332904 -0.334648 -0.337454 -0.316071 -0.293005 -0.296367 -0.279975 -0.275467 -0.269300 -0.245452 -0.242168 -0.254216 -0.245208 -0.252498 -0.261764 -0.263362 -0.262319 -0.250159 -0.263872  ...  0.770206  0.367520   \n",
      "\n",
      "        103       104       105       106       107       108       109       110       111       112       113       114       115       116       117       118       119       120       121       122       123       124       125       126       127       128       129       130       131       132       133       134       135       136       137       138       139       140       141       142       143       144       145       146       147       148       149       150       151       152       153       154       155       156       157       158       159       160       161       162       163       164       165       166       167       168       169       170       171       172       173       174       175       176       177       178       179       180       181       182       183       184       185       186       187       188       189       190       191       192       193       194       195       196       197       198       199  label  \n",
      "0  0.068561 -0.311259 -0.452218 -0.437992 -0.395716 -0.387999 -0.381688 -0.391097 -0.384759 -0.384331 -0.401981 -0.403456 -0.397810 -0.393090 -0.379635 -0.390193 -0.407397 -0.396310 -0.398257 -0.403132 -0.404131 -0.411769 -0.406280 -0.398140 -0.394394 -0.402031 -0.387487 -0.400316 -0.398165 -0.379536 -0.393589 -0.403104 -0.388418 -0.397665 -0.408884 -0.400935 -0.413609 -0.419979 -0.415046 -0.424929 -0.430989 -0.429076 -0.446162 -0.443481 -0.446669 -0.458163 -0.458055 -0.455573 -0.466437 -0.456536 -0.442170 -0.439106 -0.400003 -0.366839 -0.354668 -0.329943 -0.322156 -0.325999 -0.310803 -0.300164 -0.318728 -0.306988 -0.309125 -0.313117 -0.303024 -0.309942 -0.318506 -0.306871 -0.307011 -0.310286 -0.298638 -0.305731 -0.314230 -0.312364 -0.315136 -0.323244 -0.320718 -0.330911 -0.336769 -0.330145 -0.342925 -0.345034 -0.331804 -0.340419 -0.336448 -0.328599 -0.345937 -0.336422 -0.332001 -0.355951 -0.352582 -0.342964 -0.345000 -0.336106 -0.333644 -0.347101 -0.343998      0  \n",
      "0  0.796448  0.039593 -0.464709 -0.453412 -0.401128 -0.390519 -0.397776 -0.401575 -0.393539 -0.397671 -0.404698 -0.401583 -0.411621 -0.412708 -0.412839 -0.427660 -0.418431 -0.408783 -0.425730 -0.419094 -0.412728 -0.416679 -0.404842 -0.398251 -0.407465 -0.399089 -0.399638 -0.417203 -0.423591 -0.416026 -0.420489 -0.417636 -0.404764 -0.415812 -0.409487 -0.397504 -0.399956 -0.386269 -0.393185 -0.402181 -0.408361 -0.411790 -0.418794 -0.419124 -0.413059 -0.434104 -0.431681 -0.420000 -0.422261 -0.417048 -0.400063 -0.381414 -0.350558 -0.333059 -0.333543 -0.320556 -0.309129 -0.309523 -0.303135 -0.300002 -0.308392 -0.312865 -0.302986 -0.317674 -0.319268 -0.309338 -0.315597 -0.310513 -0.309293 -0.326710 -0.320045 -0.325097 -0.347738 -0.336923 -0.334201 -0.348311 -0.352558 -0.358235 -0.362761 -0.351788 -0.347059 -0.356198 -0.360797 -0.357983 -0.370583 -0.365071 -0.360157 -0.376320 -0.365717 -0.350765 -0.357374 -0.356555 -0.347153 -0.358146 -0.356849 -0.355005 -0.383003      0  \n",
      "0 -0.231163 -0.490879 -0.430214 -0.395306 -0.405045 -0.389207 -0.394596 -0.408614 -0.400441 -0.396871 -0.410643 -0.406798 -0.405232 -0.407000 -0.393341 -0.389860 -0.398640 -0.399698 -0.396608 -0.403693 -0.395294 -0.384226 -0.387754 -0.386364 -0.384529 -0.393644 -0.379560 -0.379983 -0.393334 -0.385468 -0.379606 -0.386796 -0.378595 -0.385355 -0.379234 -0.375130 -0.376941 -0.388241 -0.366539 -0.377801 -0.386512 -0.376915 -0.375306 -0.378651 -0.371032 -0.375124 -0.392570 -0.383563 -0.367230 -0.364985 -0.334574 -0.319477 -0.318265 -0.298002 -0.296008 -0.286568 -0.280097 -0.279209 -0.293001 -0.289904 -0.286969 -0.296447 -0.288670 -0.282687 -0.299462 -0.296040 -0.287117 -0.302574 -0.298557 -0.305011 -0.314613 -0.306203 -0.309763 -0.331769 -0.323798 -0.316441 -0.330853 -0.323634 -0.321911 -0.333209 -0.337471 -0.335448 -0.344930 -0.342757 -0.336030 -0.333213 -0.337973 -0.325534 -0.344315 -0.358741 -0.349410 -0.348493 -0.344020 -0.342795 -0.361588 -0.360604 -0.345000      0  \n",
      "0 -0.249638 -0.468012 -0.434827 -0.396240 -0.396033 -0.414238 -0.416993 -0.397446 -0.405314 -0.402128 -0.390499 -0.395000 -0.389423 -0.388292 -0.408977 -0.407264 -0.396404 -0.405731 -0.415067 -0.405523 -0.409171 -0.416231 -0.413808 -0.413646 -0.412179 -0.397170 -0.395002 -0.396325 -0.402663 -0.416329 -0.421456 -0.398454 -0.401218 -0.404987 -0.396849 -0.403699 -0.415667 -0.397350 -0.405931 -0.424999 -0.424628 -0.434864 -0.445277 -0.448045 -0.453873 -0.445375 -0.429373 -0.436985 -0.445656 -0.425021 -0.415766 -0.409105 -0.379969 -0.366286 -0.352531 -0.324370 -0.305321 -0.317353 -0.309818 -0.311535 -0.315326 -0.307137 -0.307081 -0.311365 -0.304937 -0.302116 -0.297069 -0.281200 -0.298280 -0.312995 -0.303001 -0.313729 -0.326175 -0.320804 -0.329833 -0.336552 -0.325118 -0.317717 -0.336145 -0.336626 -0.321693 -0.322883 -0.330406 -0.331388 -0.336761 -0.321897 -0.322989 -0.346626 -0.340841 -0.329923 -0.328576 -0.324543 -0.323970 -0.333492 -0.331005 -0.330000 -0.340000      0  \n",
      "\n",
      "[4 rows x 224 columns]\n",
      "\n",
      "omitted:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Pabaiga\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", 6000, \"display.max_columns\",200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os = sys.platform\n",
    "print(\"OS in my system : \", my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:\n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    # Duomenu_aplankas = \"F:\\DI\\Data\\MIT&ZIVE\"   # variantas: Windows\n",
    "    Duomenu_aplankas = 'D:\\DI\\Data\\MIT&ZIVE'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/povilas/Documents/kardio'  # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "#  MIT2ZIVE duomenų aplankas\n",
    "db_folder = 'MIT2ZIVE'\n",
    "\n",
    "# Nuoroda į DUOM_TST duomenų aplanką\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su EKG įrašais (.npa) ir anotacijomis (.json)\n",
    "db_path = Path(db_path, 'records')  # all_beats_attr šiame aplanke dar su apskaičiuotais R\n",
    "\n",
    "# Anotacijoms priskirtos klasės: įtrauktos tiek MIT tiek Zive anotacijos\n",
    "selected_beats = {'N': 0, 'S': 1, 'V': 2}\n",
    "\n",
    "print(\"\\nBendras MIT ir Zive duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"MIT2ZIVE EKG įrašų aplankas: \", db_folder)\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "import datetime\n",
    "\n",
    "# Įvairios operacijos, naudojant EKG įrašus ir all_beats_attr.csv\n",
    "\n",
    " # Nuskaitome pūpsnių atributų failą\n",
    "file_path = Path(db_path, 'all_beats_attr.csv')\n",
    "all_beats_attr = pd.read_csv(file_path, index_col=0)\n",
    "#\n",
    "\n",
    "# beats_skiped = 1\n",
    "#create training set:\n",
    "# train_set_idx = pd.read_csv(Path(db_path, 'train_ind_lst_tst.csv'), header = None, index_col=0)\n",
    "# print(train_set_idx)\n",
    "\n",
    " # Nuskaitome EKG įrašą (npy formatu)\n",
    "\n",
    "SubjCode = 100\n",
    "sign_raw = read_rec(db_path, SubjCode)\n",
    "signal_length = sign_raw.shape[0]\n",
    "signal = sign_raw\n",
    "\n",
    "# Surandame ir išvedame įrašo atributus\n",
    "file_name = get_filename(db_path, SubjCode)\n",
    "userNr, recNr = split_SubjCode(SubjCode)\n",
    "print(f\"\\nSubjCode: {SubjCode} userNr: {userNr:>2} file_name: {file_name:>2} signal_length: {signal_length}\")\n",
    "\n",
    "# Filtruojame signalą\n",
    "# signal = signal_filter(signal=sign_raw, sampling_rate=200, lowcut=0.2, method=\"butterworth\", order=5)\n",
    "\n",
    "# Nuskaitome paciento anotacijas ir jų indeksus\n",
    "\n",
    "atr_sample, atr_symbol = read_rec_attrib(db_path, SubjCode)\n",
    "print(atr_sample)\n",
    "\n",
    "df_rpeaks = read_df_rpeaks(db_path, SubjCode)\n",
    "print(df_rpeaks.head(10))\n",
    "\n",
    "idx_lst = [2, 3, 4, 5]\n",
    "print(idx_lst)\n",
    "\n",
    "print(f'\\nVariantas: apply_FDA_vasara:\\n')\n",
    "train_set_data, omitted = apply_FDA_vasara(signal, idx_lst, atr_sample)\n",
    "\n",
    "# print(\"\\n\", \"train_set_data DATA:\")\n",
    "# train_set_data.info()\n",
    "# print(list(train_set_data.columns))\n",
    "# # print(train_set_data.keys())\n",
    "print(\"\\ntrain_set_data:\")\n",
    "print(train_set_data.head())\n",
    "print(\"\\nomitted:\")\n",
    "print(omitted.head())\n",
    "\n",
    "\n",
    "print(f'\\nVariantas: get_beat_features_fda_vu_v1_vasara:----------------------------------------------\\n')\n",
    "train_set_data, omitted = get_beat_features_set_fda_vu_v1(signal, df_rpeaks, idx_lst)\n",
    "\n",
    "# train_set_data, omitted = apply_FDA_vasara(train_set_idx, all_beats_attr)\n",
    "\n",
    "# print(\"\\n\", \"train_set_data DATA:\")\n",
    "# train_set_data.info()\n",
    "# print(list(train_set_data.columns))\n",
    "# # print(train_set_data.keys())\n",
    "print(\"\\ntrain_set_data:\")\n",
    "print(train_set_data.head())\n",
    "print(\"\\nomitted:\")\n",
    "print(omitted.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(train_set_data['label'].value_counts())\n",
    "# train_set_data.to_csv(Path(db_path, 'train_data_RR_1_MIT_v2.csv'), index = False)\n",
    "# omitted.to_csv(Path(db_path, 'train_data_omitted_idx_RR_1_v2.csv'), index = False)\n",
    "\n",
    "#create validation set:\n",
    "# test_set_idx = pd.read_csv(Path(db_path, 'validate_ind_lst.csv'), header = None, index_col=0)\n",
    "# test_set_data, omitted = apply_FDA_vasara_vasara(test_set_idx, all_beats_attr)\n",
    "# test_set_data.to_csv(Path(db_path, 'test_data_RR_1_MIT.csv'), index = False)\n",
    "# omitted.to_csv(Path(db_path, 'test_data_omitted_idx_RR_1.csv'), index = False)\n",
    "\n",
    "\n",
    "print(\"\\nPabaiga\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ecg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f36dab35816871602f0a4fffa6415a4e758bca001397bb3d9f7e90aab6637a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
