{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_set_points1\n",
      "[ 1.65888161 -0.12672339  0.32063801 -0.2422466   1.55435793]\n",
      "          0         1         2         3         4\n",
      "0  1.658882 -0.126723  0.320638 -0.242247  1.554358\n",
      "\n",
      "train_set_points2\n",
      "[-0.64958845  0.73745269 -0.50387097  1.25469393 -0.95916288]\n",
      "          0         1         2         3         4\n",
      "0 -0.649588  0.737453 -0.503871  1.254694 -0.959163\n",
      "\n",
      "train_set_points\n",
      "          0         1         2         3         4\n",
      "0  1.658882 -0.126723  0.320638 -0.242247  1.554358\n",
      "          0         1         2         3         4\n",
      "0  1.658882 -0.126723  0.320638 -0.242247  1.554358\n",
      "0 -0.649588  0.737453 -0.503871  1.254694 -0.959163\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skfda import FDataGrid\n",
    "\n",
    "train_set_points = pd.DataFrame()\n",
    "resampling_points = 5\n",
    "\n",
    "print('\\ntrain_set_points1')\n",
    "fd = np.random.randn(resampling_points) # outputs a single floating point number\n",
    "print(fd)\n",
    "fd = FDataGrid(data_matrix=fd)\n",
    "samples = np.linspace(0, 1, resampling_points)\n",
    "fd = fd.evaluate(samples)  \n",
    "fd = fd.reshape(resampling_points)\n",
    "# print(fd)\n",
    "\n",
    "train_set_points1 = pd.Series(fd).to_frame().T\n",
    "print(train_set_points1.head(5))\n",
    "\n",
    "# train_set_points1 = train_set_points1.append(pd.Series(fd), ignore_index=True)\n",
    "# print(train_set_points1.head(10))\n",
    "\n",
    "print('\\ntrain_set_points2')\n",
    "fd = np.random.randn(resampling_points) # outputs a single floating point number\n",
    "print(fd)\n",
    "fd = FDataGrid(data_matrix=fd)\n",
    "samples = np.linspace(0, 1, resampling_points)\n",
    "fd = fd.evaluate(samples)  \n",
    "fd = fd.reshape(resampling_points)\n",
    "# print(fd)\n",
    "\n",
    "train_set_points2 = pd.Series(fd).to_frame().T\n",
    "print(train_set_points2.head(5))\n",
    "\n",
    "print('\\ntrain_set_points')\n",
    "train_set_points = pd.concat([train_set_points, train_set_points1])\n",
    "print(train_set_points.head(5))\n",
    "train_set_points = pd.concat([train_set_points, train_set_points2])\n",
    "print(train_set_points.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['N', 'S', 'V']\n",
      "0 0 {'N': 2}\n",
      "   N\n",
      "N  2\n",
      "0 1 {'N': 2, 'S': 2}\n",
      "   N  S\n",
      "N  2  2\n",
      "0 2 {'N': 2, 'S': 2, 'V': 0}\n",
      "   N  S  V\n",
      "N  2  2  0\n",
      "1 0 {'N': 0}\n",
      "   N\n",
      "S  0\n",
      "1 1 {'N': 0, 'S': 4}\n",
      "   N  S\n",
      "S  0  4\n",
      "1 2 {'N': 0, 'S': 4, 'V': 0}\n",
      "   N  S  V\n",
      "S  0  4  0\n",
      "2 0 {'N': 0}\n",
      "   N\n",
      "V  0\n",
      "2 1 {'N': 0, 'S': 0}\n",
      "   N  S\n",
      "V  0  0\n",
      "2 2 {'N': 0, 'S': 0, 'V': 2}\n",
      "   N  S  V\n",
      "V  0  0  2\n",
      "Confusion Matrix\n",
      "   N  S  V\n",
      "N  2  2  0\n",
      "S  0  4  0\n",
      "V  0  0  2\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix\n",
      "0 0 {'N': 0.5}\n",
      "      N\n",
      "N 0.500\n",
      "0 1 {'N': 0.5, 'S': 0.5}\n",
      "      N     S\n",
      "N 0.500 0.500\n",
      "0 2 {'N': 0.5, 'S': 0.5, 'V': 0.0}\n",
      "      N     S     V\n",
      "N 0.500 0.500 0.000\n",
      "1 0 {'N': 0.0}\n",
      "      N\n",
      "S 0.000\n",
      "1 1 {'N': 0.0, 'S': 1.0}\n",
      "      N     S\n",
      "S 0.000 1.000\n",
      "1 2 {'N': 0.0, 'S': 1.0, 'V': 0.0}\n",
      "      N     S     V\n",
      "S 0.000 1.000 0.000\n",
      "2 0 {'N': 0.0}\n",
      "      N\n",
      "V 0.000\n",
      "2 1 {'N': 0.0, 'S': 0.0}\n",
      "      N     S\n",
      "V 0.000 0.000\n",
      "2 2 {'N': 0.0, 'S': 0.0, 'V': 1.0}\n",
      "      N     S     V\n",
      "V 0.000 0.000 1.000\n",
      "      N     S     V\n",
      "N 0.500 0.500 0.000\n",
      "S 0.000 1.000 0.000\n",
      "V 0.000 0.000 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cm2df(cm, labels):\n",
    "    df = pd.DataFrame()\n",
    "    # rows\n",
    "    for i, row_label in enumerate(labels):\n",
    "        rowdata={}\n",
    "        # columns\n",
    "        # for j, col_label in enumerate(labels): \n",
    "        #     rowdata[col_label]=cm[i,j]\n",
    "        # df = df.append(pd.DataFrame.from_dict({row_label:rowdata}, orient='index'))\n",
    "        for j, col_label in enumerate(labels): \n",
    "            rowdata[col_label]=cm[i,j]\n",
    "            print(i,j, rowdata)\n",
    "            row_df = pd.DataFrame.from_dict({row_label:rowdata}, orient='index')\n",
    "            print(row_df)\n",
    "        df = pd.concat([df, row_df])\n",
    "    return df[labels]\n",
    "\n",
    "def show_confusion_matrix(cnf_matrix, class_names):\n",
    "    df = cm2df(cnf_matrix, class_names)\n",
    "    print('Confusion Matrix')\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    flag_of_zero_values = False\n",
    "    for i in range(len(class_names)):\n",
    "        if (cnf_matrix[i,i] == 0):\n",
    "            flag_of_zero_values = True\n",
    "\n",
    "    if flag_of_zero_values != True:\n",
    "        cnf_matrix_n = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "        df = cm2df(cnf_matrix_n, class_names)\n",
    "        pd.options.display.float_format = \"{:,.3f}\".format\n",
    "        print(df)\n",
    "    else:\n",
    "        print('Zero values! Cannot calculate Normalized Confusion Matrix')\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "selected_beats = {'N':0, 'S':1, 'V':2}\n",
    "class_names = list(selected_beats.keys()) \n",
    "print(f\"class_names: {class_names}\")\n",
    "\n",
    "y_validate = np.array([0,0,2,1,0,1,0,1,2,1]).astype('int')\n",
    "y_predicted = np.array([1,1,2,1,0,1,0,1,2,1]).astype('int')\n",
    "\n",
    "confusion = confusion_matrix(y_validate, y_predicted)\n",
    "\n",
    "show_confusion_matrix(confusion, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ecg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f36dab35816871602f0a4fffa6415a4e758bca001397bb3d9f7e90aab6637a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
