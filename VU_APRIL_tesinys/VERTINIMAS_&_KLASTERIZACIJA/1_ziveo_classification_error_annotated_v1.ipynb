{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# # Skriptas zive EKG pūpsnių CNN VU klasifikatoriaus testavimui ir tikslumo įvertinimui.\n",
    "# Įvertinimas atliekamas su rpeaks, paimtais iš json failo, kuris yra gydytojų koreguotas\n",
    "# Toks įvertinimas parodo, ką galėtų pasiekti ML klasifikacija, jei Neurokit be klaidų\n",
    "# sužymėtų rpeaks\n",
    "#  \n",
    "# Skripte yra galimybė išvesti ekstrasistolių vietas įraše.\n",
    "# Dirbant su daug įrašų reiktų užblokuoti: classification = []  # Užblokuota\n",
    " \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import time\n",
    "import sys, os, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from vertinimas_util import show_confusion_matrix\n",
    "from vertinimas_util import create_dir, zive_read_file_1ch, zive_read_df_rpeaks\n",
    "from vertinimas_util import runtime\n",
    "from vertinimas_util import get_label_sums, get_rid_off_class_3\n",
    "\n",
    "from zive_cnn_fda_vu_v3_micro_modif import classify_cnn_fda_vu_vasara_v2_modif\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "def zive_read_rec_id(db_path, file_name):\n",
    "    file_path = Path(db_path, file_name + '.json')\n",
    "    with open(file_path,'r', encoding=\"utf8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    userId = data[\"userId\"]\n",
    "    recId = data[\"recordingId\"]\n",
    "    return userId, recId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skriptas zive-arrh EKG segmentų apmokyto klasifikatoriaus tikslumo įvertinimui\n",
      "Modelis CNN VU su EKG sekos reikšmėmis, EKG formos požymiais, RR intervalais prieš ir po R dantelio\n",
      "OS in my system :  linux\n",
      "\n",
      "Bendras duomenų aplankas:  /home/kesju/DI\n",
      "Zive duomenų aplankas:  DUOM_2022_RUDUO_2\n",
      "Aplankas su originaliais EKG įrašais ir anotacijomis (.json)  /home/kesju/DI/DUOM_2022_RUDUO_2/records_selected\n",
      "Diskretizavimo dažnis:  200\n",
      "Klasifikavimo schema: {'N': 0, 'S': 1, 'V': 2}\n",
      "Klasių skaičius: 3\n",
      "Visos galimos anotacijos: ['N', 'S', 'V', 'U']\n",
      "Modelio ir scaler parametrai nuskaitomas iš aplanko:  model_cnn_fda_vu_v1\n",
      "\n",
      "EKG įrašas nefiltruotas\n",
      "\n",
      "Atliekama pūpsnių su anotacijomis ['N', 'S', 'V'] pacientų įrašuose klasifikacija\n",
      "\n",
      "Aplankas rezultatams: /home/kesju/DI/DUOM_2022_RUDUO_2/rezultatai_tst\n",
      "Directory '/home/kesju/DI/DUOM_2022_RUDUO_2/rezultatai_tst' already exists\n",
      "['1631141.764']\n",
      "\n",
      "Zive įrašas:  1631141.764\n",
      "\n",
      "file_name: 1631141.764 userId: 613b1d673d08d4d1f3cdc8f8 recId: 613b22d53d08d4fe94cdc9ed signal_length: 127999\n",
      "len(atr_sample): 865\n",
      "omitted.index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 20:37:22.286173: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 20:37:22.292131: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-02-18 20:37:23.074042: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_y: [0 1 2 3] [805  43  15   2] 865\n",
      "N:  845 S: 20 V:  0 U:  0  Nml:  805 Sml: 43 Vml: 15 Uml:  2  Nprec: 1.00 Nrec: 0.95 Nfsc: 0.97  Sprec: 0.12 Srec: 0.25 Sfsc: 0.16  Vprec: 0.00 Vrec: 0.00 Vfsc: 0.00\n",
      "\n",
      "\n",
      "Runtime: 00:00:38\n",
      "\n",
      "Rezultatai įrašyti į:  /home/kesju/DI/DUOM_2022_RUDUO_2/rezultatai_tst/klasifikacijos_rezultatai_irasams.csv\n",
      "\n",
      "Atributų freimas įrašytas: į  /home/kesju/DI/DUOM_2022_RUDUO_2/rezultatai_tst/all_beats_attr.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pagrindinis skriptas\n",
    "\n",
    "print(\"Skriptas zive-arrh EKG segmentų apmokyto klasifikatoriaus tikslumo įvertinimui\")\n",
    "print('Modelis CNN VU su EKG sekos reikšmėmis, EKG formos požymiais, RR intervalais prieš ir po R dantelio')\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\\\DI'   # variantas: Windows\n",
    "    # Duomenu_aplankas = 'F:\\DI\\Data\\MIT&ZIVE\\VU'   # variantas: Herkulis\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI'   # arba variantas: UBUNTU, be Docker\n",
    "    # Duomenu_aplankas = '/home/kesju/DI/GITLAB'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Vietinės talpyklos aplankas ir pūpsnių atributų failas\n",
    "db_folder = 'DUOM_2022_RUDUO_2'\n",
    "# db_folder = 'analysis'\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "selected_beats = {'N':0, 'S':1, 'V':2}\n",
    "all_beats =  {'N':0, 'S':1, 'V':2, 'U':3}  \n",
    "\n",
    "# Diskretizavimo dažnis:\n",
    "fs = 200\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////\n",
    "\n",
    "#  Nuoroda į aplanką su MIT2ZIVE duomenų rinkiniu\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su EKG įrašais (.npy) ir anotacijomis (.json)\n",
    "rec_dir = Path(db_path, 'records_selected')\n",
    "# rec_dir = Path(db_path, 'test')\n",
    "\n",
    "# Nuoroda į modelio aplanką\n",
    "# model_dir = Path(Duomenu_aplankas, 'DNN', 'best_models', 'all_ft')\n",
    "model_dir = 'model_cnn_fda_vu_v1'\n",
    "\n",
    "# Užduodame, ar filtruojame įrašus\n",
    "Filtr_flag = False  # True - filtruoti\n",
    "\n",
    "\n",
    "# Išvedame parametrus\n",
    "print(\"\\nBendras duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"Zive duomenų aplankas: \", db_folder)\n",
    "print(\"Aplankas su originaliais EKG įrašais ir anotacijomis (.json) \", rec_dir)\n",
    "print(\"Diskretizavimo dažnis: \", fs)\n",
    "print('Klasifikavimo schema:', selected_beats)\n",
    "print('Klasių skaičius:', len(selected_beats))\n",
    "print('Visos galimos anotacijos:', list(all_beats.keys()))\n",
    "print(\"Modelio ir scaler parametrai nuskaitomas iš aplanko: \", model_dir)\n",
    "# print(\"\\n\")\n",
    "\n",
    "if (Filtr_flag):\n",
    "    # Filtruojame izoliniją su 0.5 Hz žemo dažnumo filtru\n",
    "    lowcut = 0.5\n",
    "    method = 'butterworth'\n",
    "    order = 5\n",
    "    print(f\"\\nEKG įrašai filtruojami su Neurokit2\")\n",
    "    print(f\"Parametrai: lowcut:{lowcut} method: {method} order: {order} \")\n",
    "else:\n",
    "    print(f\"\\nEKG įrašas nefiltruotas\")\n",
    "print()\n",
    "\n",
    "# PASIRUOŠIMAS\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", 6000)\n",
    "# pd.set_option(\"display.max_columns\",200)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Naudojamų požymių sąrašas \n",
    "all_features = ['seq_size','RR_l_0', 'RR_r_0', 'RR_r/RR_l','wl_side','wr_side',\n",
    "                'signal_mean', 'signal_std', 'P_val', 'Q_val', 'R_val', 'S_val', 'T_val',\n",
    "                'P_pos', 'Q_pos', 'R_pos', 'S_pos', 'T_pos', 'QRS', 'PR', 'ST', 'QT', '0', '1', '2',\n",
    "                '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
    "                '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32',\n",
    "                '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
    "                '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
    "                '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74',\n",
    "                '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88',\n",
    "                '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
    "                '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114',\n",
    "                '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126',\n",
    "                '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
    "                '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150',\n",
    "                '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162',\n",
    "                '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
    "                '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186',\n",
    "                '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198',\n",
    "                '199']\n",
    "\n",
    "print(f\"Atliekama pūpsnių su anotacijomis {list(selected_beats.keys())} pacientų įrašuose klasifikacija\")\n",
    "\n",
    "# NURODOME PACIENTŲ SĄRAŠĄ\n",
    "# VARIANTAS, KAI UŽDUODAMI FAILŲ VARDAI IR SKAITOMI ORIGINALUS ZIVE FAILAI \n",
    "# 20 atrinktų testinių sąrašas\n",
    "FileNames = [\n",
    "1626934.963,\n",
    "1626931.201,\n",
    "1630715.664,\n",
    "1630714.569,\n",
    "1630729.576,\n",
    "1630735.143,\n",
    "1630693.635,\n",
    "1630734.526,\n",
    "1630718.396,\n",
    "1630721.49,\n",
    "1631139.883,\n",
    "1631083.411,\n",
    "1631039.923,\n",
    "1631029.786,\n",
    "1632342.032,\n",
    "1633428.56,\n",
    "1633584.898,\n",
    "1633405.853,\n",
    "1634112.089,\n",
    "1636451.86\n",
    "]\n",
    "\n",
    "FileNames = [1626934.963] #\n",
    "\n",
    "# 4 testiniai įrašai GitLab\n",
    "FileNames = [1625400.796, 1625402.027, 1630757.924, 1631141.764] #  \n",
    "\n",
    "FileNames = [1625400.796] #\n",
    "FileNames = [1625402.027] #\n",
    "FileNames = [1630757.924] #\n",
    "FileNames = [1631141.764] #\n",
    "# mark1\n",
    "\n",
    "path_for_results = Path(db_path, 'rezultatai_tst')\n",
    "print(f\"\\nAplankas rezultatams: {path_for_results}\")\n",
    "create_dir(path_for_results)\n",
    "\n",
    "# Kas kiek išvedamas apdorotų sekų skaičius\n",
    "show_period = 100\n",
    "\n",
    "# Klasių simbolinių vardų sąrašas ir klasių skaičius\n",
    "class_names = list(selected_beats.keys()) \n",
    "n_classes = len(selected_beats)\n",
    "# print(class_names)\n",
    "\n",
    "                    # SUFORMUOJAME all_beats_attr\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "annot_grouping = {'N':'N', 'S':'S', 'V':'V', 'U':'U'}\n",
    "\n",
    "# Sukūriame masyvą sekų atributų sąrašui\n",
    "# https://sparkbyexamples.com/pandas/pandas-empty-dataframe-with-specific-column-types/\n",
    "\n",
    "all_beats_attr = pd.DataFrame({'file_name': pd.Series(dtype='str'),\n",
    "                   'sample': pd.Series(dtype='int'),\n",
    "                   'symbol': pd.Series(dtype='str'),\n",
    "                   'label': pd.Series(dtype='int'),\n",
    "                   'pred_label': pd.Series(dtype='int')\n",
    "                   })\n",
    "\n",
    "df_rec_results = pd.DataFrame({'file_name':pd.Series(dtype='str'),  \n",
    "    'userId':pd.Series(dtype='str'), 'recId':pd.Series(dtype='int'), 'signal_length':pd.Series(dtype='int'),\n",
    "    'N':pd.Series(dtype='int'), 'S':pd.Series(dtype='int'), 'V':pd.Series(dtype='int'), 'U':pd.Series(dtype='int'),\n",
    "    'Nml':pd.Series(dtype='int'), 'Sml':pd.Series(dtype='int'), 'Vml':pd.Series(dtype='int'), 'Uml':pd.Series(dtype='int'),\n",
    "    'Nprec':pd.Series(dtype='float') , 'Nrec':pd.Series(dtype='float'), 'Nfsc':pd.Series(dtype='float'),\n",
    "    'Sprec':pd.Series(dtype='float') , 'Srec':pd.Series(dtype='float'), 'Sfsc':pd.Series(dtype='float'),\n",
    "    'Vprec':pd.Series(dtype='float') , 'Vrec':pd.Series(dtype='float'), 'Vfsc':pd.Series(dtype='float'), \n",
    "     'Err%':pd.Series(dtype='float'), 'Noise%':pd.Series(dtype='float')})\n",
    "# Pandas Empty DataFrame with Specific Column Types\n",
    "# https://sparkbyexamples.com/pandas/pandas-empty-dataframe-with-specific-column-types/\n",
    "\n",
    "rows_list = []\n",
    "\n",
    "# CIKLAS PER PACIENTŲ ĮRAŠUS\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "file_names=[\"%.3f\" % i for i in FileNames]\n",
    "print(file_names)\n",
    "\n",
    "# Ciklas per visą įrašų sąrašą\n",
    "for file_name in file_names:\n",
    "    print(f\"\\nZive įrašas:  {file_name:>2}\")\n",
    "    \n",
    "    df_rpeaks = zive_read_df_rpeaks(rec_dir, file_name)\n",
    "    atr_sample = df_rpeaks['sampleIndex'].to_numpy()\n",
    "    atr_symbol = df_rpeaks['annotationValue'].to_numpy()\n",
    "\n",
    "    # Nuskaitome EKG įrašą (Zive formatu)\n",
    "    filepath = Path(rec_dir, file_name)\n",
    "    sign_raw = zive_read_file_1ch(filepath)\n",
    "\n",
    "    signal_length = sign_raw.shape[0]\n",
    "    signal = sign_raw\n",
    "    \n",
    "    if (Filtr_flag):\n",
    "        signal = nk.signal_filter(signal=sign_raw, sampling_rate=200, lowcut=lowcut, method=method, order=order)\n",
    "        # signal = nk.signal_filter(signal=sign_raw, sampling_rate=200, lowcut=0.2, method=\"butterworth\", order=5)\n",
    "        signal_length = signal.shape[0]\n",
    "    else:\n",
    "        signal = sign_raw\n",
    "        signal_length = sign_raw.shape[0]\n",
    "\n",
    "    # Surandame ir išvedame įrašo atributus\n",
    "    userId, recId = zive_read_rec_id(rec_dir, file_name)\n",
    "\n",
    "    print(f\"\\nfile_name: {file_name:>2} userId: {userId} recId: {recId} signal_length: {signal_length}\")\n",
    "\n",
    "    # Jei pasitaiko symbol 'U' arba 'F', pūpsniui suteikiame klasę 3, kurią vėliau apvalysime  \n",
    "    test_labels = np.array([all_beats[symbol] for symbol in atr_symbol])\n",
    "\n",
    "    label_sums, total = get_label_sums(test_labels, all_beats)  \n",
    "    # print(\"test_labels: \", list(all_beats.keys()), label_sums, \"Total:\", total)\n",
    "\n",
    "    # Surandame ML anotacijų skaitmenines reikšmes pred_labels\n",
    "    # Jei atr_symbol atranda anotaciją 'U', tai jos neklasifikuoja,\n",
    "    # bet iš karto patalpina '3' į pred_labels atitinkamą vietą.\n",
    "    # Į pred_labels taip pat įrašomas '3' pirmam ir paskutiniam pūpsniui,\n",
    "    # o taip pat pakliuvusiems į ommited sritį, \n",
    "    # pred_labels = predict_cnn_fda_vu_v1_micro(signal, atr_sample, atr_symbol, model_dir)\n",
    "    # mark2      Taisomas vieta //////////////////////////////////////////////\n",
    "\n",
    "    pred_labels = classify_cnn_fda_vu_vasara_v2_modif(signal, atr_sample, model_dir)\n",
    "    \n",
    "    # pred_labels turi būti tokio pat ilgio, kaip ir test_labels\n",
    "    if (len(test_labels) != len(pred_labels)):\n",
    "        raise Exception(f\"Klaida! file_name: {file_name}. Nesutampa test_labels ir pred_labels ilgiai\")     \n",
    "\n",
    "    label_sums_ml, total = get_label_sums(pred_labels, all_beats)  \n",
    "    # print(\"pred_labels: \", list(all_beats.keys()), label_sums_ml, \"Total:\", total)\n",
    "\n",
    "    # Surandame vietas su ekstrasistolemis ir išvedame jų sąrašą vizualiniam įvertinimui. \n",
    "    classification=[]\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "        if ((pred_labels[i] != 0) or test_labels[i] != 0):\n",
    "            classification.append({'i':i, 'sample':i_sample, 'annot':test_labels[i], 'pred':pred_labels[i]})\n",
    "\n",
    "    # Vietų sąrašas išvedamas\n",
    "    # Dirbant su daug įrašų sąrašo išvedimą reikia užblokuoti !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    classification = []  # uzblokuota\n",
    "    if (classification):\n",
    "        print('\\nVietos su ekstrasistolėmis test_y arba pred_y:')\n",
    "        for row in classification:\n",
    "            print(f\"i: {row['i']:>7} sample: {row['sample']:>7}   annot_label: {row['annot']:>2}   pred_label: {row['pred']:>2}\")  \n",
    "\n",
    "    # Ciklas per visas paciento įrašo anotacijas (simbolius) ir jų vietas (i_sample)\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "\n",
    "        # Formuojame pūpsnio atributus\n",
    "        beats_attr = {'file_name':file_name, 'sample':int(i_sample), \n",
    "                        'symbol':str(atr_symbol[i]), 'label':test_labels[i], 'pred_label':pred_labels[i]}\n",
    "\n",
    "        # Kaupiame su concat\n",
    "        df_new_row = pd.DataFrame([beats_attr])\n",
    "        all_beats_attr = pd.concat([all_beats_attr, df_new_row])\n",
    "\n",
    " # Suformuojame klasių numerių masyvus confusion matricai skaičiuoti, surandama confusion matrica\n",
    "\n",
    "    # pred_labels turi būti tokio pat ilgio, kaip ir test_labels\n",
    "    if (len(test_labels) != len(pred_labels)):\n",
    "        raise Exception(f\"Klaida! file_name: {file_name}. Nesutampa test_labels ir pred_labels ilgiai\")     \n",
    "\n",
    "    test_labels_mod, pred_labels_mod = get_rid_off_class_3(test_labels, pred_labels)\n",
    "    label_sums_ml_3, total = get_label_sums(pred_labels_mod, all_beats)  \n",
    "    # print(\"pred_labels_3: \", list(all_beats.keys()), label_sums_ml_3, \"Total:\", total)\n",
    "\n",
    "    confusion = confusion_matrix(test_labels_mod, pred_labels_mod)\n",
    "    # print()\n",
    "    # print(confusion)\n",
    "    prec,rec,fsc,sup = precision_recall_fscore_support(test_labels_mod, pred_labels_mod, labels=[0, 1, 2], zero_division=0)\n",
    "\n",
    "    str1 =f\"N:{int(label_sums[0]):>5} S:{(int(label_sums[1])):3} V:{int(label_sums[2]):3} U:{int(label_sums[3]):3}\" \n",
    "    str2 =f\"  Nml:{int(label_sums_ml[0]):>5} Sml:{(int(label_sums_ml[1])):3} Vml:{int(label_sums_ml[2]):3} Uml:{int(label_sums_ml[3]):3}\" \n",
    "    str3 = f\"  Nprec:{prec[0]:>5.2f} Nrec:{rec[0]:5.2f} Nfsc:{fsc[0]:5.2f}\"\n",
    "    str4 = f\"  Sprec:{prec[1]:>5.2f} Srec:{rec[1]:5.2f} Sfsc:{fsc[1]:5.2f}\"\n",
    "    str5 = f\"  Vprec:{prec[2]:>5.2f} Vrec:{rec[2]:5.2f} Vfsc:{fsc[2]:5.2f}\"\n",
    "    # print()\n",
    "    print(str1+str2+str3+str4+str5)\n",
    "\n",
    "    dict_rec_results = {'file_name':file_name,\n",
    "    'userId': userId, 'recId': recId, 'signal_length': signal_length,\n",
    "    'N':label_sums[0], 'S':label_sums[1], 'V':label_sums[2], 'U':label_sums[3],\n",
    "    'Nml':label_sums_ml[0], 'Sml':label_sums_ml[1], 'Vml':label_sums_ml[2], 'Uml':label_sums_ml[3],\n",
    "    'Nprec':prec[0], 'Nrec':rec[0], 'Nfsc':fsc[0],\n",
    "    'Sprec':prec[1], 'Srec':rec[1], 'Sfsc':fsc[1],\n",
    "    'Vprec':prec[2], 'Vrec':rec[2], 'Vfsc':fsc[2] \n",
    "    }\n",
    "    rows_list.append(dict_rec_results)\n",
    "\n",
    "df_rec_results =  pd.DataFrame(rows_list) \n",
    "\n",
    "# Ciklo per pacientų įrašus pabaiga\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\n')\n",
    "runtime(end_time-start_time)\n",
    "\n",
    "filepath = Path(path_for_results, 'klasifikacijos_rezultatai_irasams.csv') \n",
    "df_rec_results.to_csv(filepath)    \n",
    "print(f'\\nRezultatai įrašyti į:  {filepath}')\n",
    "\n",
    "# Pernumeruojame indeksus, kad būtų nuo 0 iš eilės\n",
    "all_beats_attr.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Įrašome sekos atributų masyvą į rec_dir aplanką\n",
    "file_path = Path(path_for_results, 'all_beats_attr.csv')\n",
    "all_beats_attr.to_csv(file_path)\n",
    "print(\"\\nAtributų freimas įrašytas: į \", file_path, \"\\n\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODELIO TIKSLUMO VERTINIMO REZULTATAI\n",
      "Modelis iš aplanko:  model_cnn_fda_vu_v1\n",
      "Pūpsnių klasės:  ['N', 'S', 'V', 'U'] [845  20   0   0] Total: 865\n",
      "Klasifikuojamos klasės: ['N', 'S', 'V']\n",
      "\n",
      "APIBENDRINTI REZULTATAI\n",
      "\n",
      "Confusion Matrix\n",
      "     N   S   V\n",
      "N  802  38   3\n",
      "S    3   5  12\n",
      "V    0   0   0\n",
      "\n",
      "\n",
      "Zero values! Cannot calculate Normalized Confusion Matrix\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N      0.996     0.951     0.973       843\n",
      "           S      0.116     0.250     0.159        20\n",
      "           V      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.935       863\n",
      "   macro avg      0.371     0.400     0.377       863\n",
      "weighted avg      0.976     0.935     0.954       863\n",
      "\n",
      "\n",
      "Apibendrinti_rezultatai įrašyti į:  /home/kesju/DI/DUOM_2022_RUDUO_2/rezultatai_tst/apibendrinti_rezultatai.csv\n"
     ]
    }
   ],
   "source": [
    "# MODELIO TIKSLUMO VERTINIMO IŠ VERTINIMO IMTIES REZULTATAI\n",
    "\n",
    "# Nuskaitome pūpsnių atributų masyvą\n",
    "file_path = Path(path_for_results, 'all_beats_attr.csv')\n",
    "all_beats_attr = pd.read_csv(file_path, index_col=0, dtype = {'file_name': str, \n",
    "                                            'sample': int, 'symbol': str, 'label': int, 'pred_label':int })\n",
    "\n",
    "# Sukūriame anotuotų ir automatiškai priskirtų klasių visų įrašų pūpsniams sąrašus \n",
    "validate_ind_lst = all_beats_attr.index\n",
    "y_validate = np.array(all_beats_attr['label']).astype('int')\n",
    "y_predicted = np.array(all_beats_attr['pred_label']).astype('int')\n",
    "\n",
    "print(\"\\nMODELIO TIKSLUMO VERTINIMO REZULTATAI\")\n",
    "print(\"Modelis iš aplanko: \", model_dir)\n",
    "\n",
    "label_sums, total = get_label_sums(y_validate, all_beats)  \n",
    "print(\"Pūpsnių klasės: \", list(all_beats.keys()), label_sums, \"Total:\", total)\n",
    "print(\"Klasifikuojamos klasės: ['N', 'S', 'V']\")\n",
    "y_validate_mod, y_predicted_mod = get_rid_off_class_3(y_validate, y_predicted)\n",
    "\n",
    "# APIBENDRINTI REZULTATAI\n",
    "\n",
    "print('\\nAPIBENDRINTI REZULTATAI\\n')\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++  čia reiktų įdėtiy_validate, y_predicted valymą nuo 3 klasės\n",
    "\n",
    "# Skaičiuojame ir išvedame klasifikavimo lentelę\n",
    "confusion = confusion_matrix(y_validate_mod, y_predicted_mod)\n",
    "pd.set_option('display.precision',3)\n",
    "show_confusion_matrix(confusion, class_names)\n",
    "# print('\\n')\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "# target_names = [key for (key, value) in selected_beats.items()]\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 6000)\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(classification_report(y_validate_mod, y_predicted_mod, target_names=class_names, digits=3))\n",
    "report = classification_report(y_validate_mod, y_predicted_mod, target_names=class_names, output_dict=True)\n",
    "# output_dictbool, default=False, If True, return output as dict.\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "# https://medium.com/@asmaiya/you-can-something-like-this-84d28e0fd31f\n",
    "\n",
    "# Įrašome į diską\n",
    "filepath = Path(path_for_results, 'apibendrinti_rezultatai.csv') \n",
    "df_report.to_csv(filepath)    \n",
    "print(f'\\nApibendrinti_rezultatai įrašyti į:  {filepath}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_lnx38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72fad068c9d13e52ed0ef400fe86b8a1dd89b57112dd527cb7ae681e2ac89056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
