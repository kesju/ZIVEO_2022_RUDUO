{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# # Skriptas zive EKG pūpsnių CNN VU klasifikatoriaus testavimui ir tikslumo įvertinimui.\n",
    " # Įvertinimas atliekamas su rpeaks, gautais iš Neurokit2, pūpsnių anotacijos paimtos iš \n",
    " # gydytojų koreguoto json failo. Anotacijos paimtos tik tiems rpeaks, kurie randami json faile.\n",
    " # Jei yra Neurokit rpeaks, kuriems json faile nerasta atitikmenų, tam rpeaks-ui priskiriama\n",
    " # anotacija 'U'.\n",
    "#  Įvertinimas atitinka realią situaciją, kai gydytojas nesikiša į anotacijų redagavimą.\n",
    "\n",
    "# Skripte yra galimybė išvesti ekstrasistolių vietas įraše.\n",
    "# Dirbant su daug įrašų reiktų užblokuoti: classification = []  # Užblokuota\n",
    " \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import time\n",
    "import sys, os, json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from vertinimas_util import show_confusion_matrix\n",
    "from vertinimas_util import create_dir, zive_read_file_1ch, zive_read_df_rpeaks\n",
    "from vertinimas_util import runtime, AnalyseHeartrate\n",
    "from vertinimas_util import get_label_sums, get_rid_off_class_3\n",
    "\n",
    "from zive_cnn_fda_vu_v3_micro_modif import classify_cnn_fda_vu_vasara_v2_modif\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "def read_signal_modif(filename):\n",
    "    \"\"\"\n",
    "    Tinka EKG įrašų skaitymui tiek zive, tiek mit2zive atveju.\n",
    "    zive atveju filename pvz. 1621694.321, 1621694.321.json\n",
    "    mit2zive atveju, pvz. 100.000, 100.000.json - dalis iki taško ne ilgesnė\n",
    "    už 4 simbolius\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "        file_path: string \n",
    "    Return\n",
    "    -----------\n",
    "        signl: numpy array, float\n",
    "    \"\"\"   \n",
    "    file_path = Path(filename)\n",
    "    name = file_path.stem\n",
    "    \n",
    "    if len(name) < 7:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            signl_loaded = np.load(f) \n",
    "        return signl_loaded\n",
    "    else:        \n",
    "        signl_loaded = zive_read_file_1ch(file_path)\n",
    "        return signl_loaded\n",
    "\n",
    "\n",
    "def zive_read_rec_id(db_path, file_name):\n",
    "    file_path = Path(db_path, file_name + '.json')\n",
    "    with open(file_path,'r', encoding=\"utf8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    userId = data[\"userId\"]\n",
    "    recId = data[\"recordingId\"]\n",
    "    return userId, recId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skriptas zive-arrh EKG segmentų apmokyto klasifikatoriaus tikslumo įvertinimui\n",
      "Modelis CNN VU su EKG sekos reikšmėmis, EKG formos požymiais, RR intervalais prieš ir po R dantelio\n",
      "\n",
      "Įvertinimas atliekamas su rpeaks, gautais iš Neurokit2, pūpsnių anotacijos paimtos iš\n",
      "gydytojų koreguoto json failo. Anotacijos paimtos tik tiems rpeaks, kurie randami json faile.\n",
      "Jei yra Neurokit rpeaks, kuriems json faile nerasta atitikmenų, tam rpeaks-ui priskiriama\n",
      "anotacija 'U'.\n",
      "Įvertinimas atitinka realią situaciją, kai gydytojas nesikiša į anotacijų redagavimą.\n",
      "OS in my system :  linux\n",
      "\n",
      "Bendras duomenų aplankas:  /home/kesju/DI\n",
      "Zive duomenų aplankas:  MAKETAS\n",
      "Aplankas su originaliais EKG įrašais ir anotacijomis (.json)  /home/kesju/DI/MAKETAS/data\n",
      "Diskretizavimo dažnis:  200\n",
      "Klasifikavimo schema: {'N': 0, 'S': 1, 'V': 2}\n",
      "Klasių skaičius: 3\n",
      "Visos galimos anotacijos: ['N', 'S', 'V', 'U', 'F']\n",
      "Modelio ir scaler parametrai nuskaitomas iš aplanko:  model_cnn_fda_vu_v1\n",
      "\n",
      "EKG įrašas nefiltruotas\n",
      "\n",
      "Atliekama pūpsnių su anotacijomis ['N', 'S', 'V'] pacientų įrašuose klasifikacija\n",
      "Viso duomenų: 3 Duomenų sąrašas: ['10801.001' '10802.002' '10803.003']\n",
      "\n",
      "Aplankas rezultatams: /home/kesju/DI/MAKETAS/rezultatai_tst\n",
      "Directory '/home/kesju/DI/MAKETAS/rezultatai_tst' already exists\n",
      "\n",
      "Zive įrašas:  10801.001\n",
      "Informacija iš json failo. Labels:  ['N', 'S', 'V', 'U', 'F'] [556   0   7   1   0] Total: 564\n",
      "Anotuojant pridėta rpikų: 206 , jos bus ignoruojamos. Panaikinta: 201 , joms bus priskiriama anotacija 'U', bus perkelta: 358\n",
      "file_name: 10801.001 userId: 108 recId: 10801 signal_length: 120370  rpeaks: 559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 21:28:10.650378: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 21:28:10.662369: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-04-06 21:28:12.019920: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:  554 S:  0 V:  5 U:  0  Nml:  536 Sml:  2 Vml:  6 Uml: 15  Nprec: 1.00 Nrec: 0.99 Nfsc: 0.99  Sprec: 0.00 Srec: 0.00 Sfsc: 0.00  Vprec: 0.50 Vrec: 0.60 Vfsc: 0.55\n",
      "\n",
      "Zive įrašas:  10802.002\n",
      "Informacija iš json failo. Labels:  ['N', 'S', 'V', 'U', 'F'] [565   1   4   1   0] Total: 571\n",
      "Anotuojant pridėta rpikų: 216 , jos bus ignoruojamos. Panaikinta: 217 , joms bus priskiriama anotacija 'U', bus perkelta: 355\n",
      "file_name: 10802.002 userId: 108 recId: 10802 signal_length: 120370  rpeaks: 572\n",
      "N:  568 S:  1 V:  3 U:  0  Nml:  543 Sml:  3 Vml:  5 Uml: 21  Nprec: 1.00 Nrec: 0.99 Nfsc: 1.00  Sprec: 0.33 Srec: 1.00 Sfsc: 0.50  Vprec: 0.40 Vrec: 0.67 Vfsc: 0.50\n",
      "\n",
      "Zive įrašas:  10803.003\n",
      "Informacija iš json failo. Labels:  ['N', 'S', 'V', 'U', 'F'] [619   3   6   0   0] Total: 628\n",
      "Anotuojant pridėta rpikų: 442 , jos bus ignoruojamos. Panaikinta: 432 , joms bus priskiriama anotacija 'U', bus perkelta: 186\n",
      "file_name: 10803.003 userId: 108 recId: 10803 signal_length: 120370  rpeaks: 618\n",
      "N:  615 S:  2 V:  1 U:  0  Nml:  547 Sml:  7 Vml: 11 Uml: 53  Nprec: 1.00 Nrec: 0.97 Nfsc: 0.99  Sprec: 0.29 Srec: 1.00 Sfsc: 0.44  Vprec: 0.09 Vrec: 1.00 Vfsc: 0.17\n",
      "\n",
      "\n",
      "Runtime: 00:02:14\n",
      "\n",
      "Rezultatai įrašyti į:  /home/kesju/DI/MAKETAS/rezultatai_tst/klasifikacijos_rezultatai_irasams.csv\n",
      "\n",
      "Atributų freimas įrašytas: į  /home/kesju/DI/MAKETAS/rezultatai_tst/all_beats_attr.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pagrindinis skriptas\n",
    "\n",
    "print(\"Skriptas zive-arrh EKG segmentų apmokyto klasifikatoriaus tikslumo įvertinimui\")\n",
    "print('Modelis CNN VU su EKG sekos reikšmėmis, EKG formos požymiais, RR intervalais prieš ir po R dantelio')\n",
    "\n",
    "print(f\"\\nĮvertinimas atliekamas su rpeaks, gautais iš Neurokit2, pūpsnių anotacijos paimtos iš\") \n",
    "print(f\"gydytojų koreguoto json failo. Anotacijos paimtos tik tiems rpeaks, kurie randami json faile.\")\n",
    "print(f\"Jei yra Neurokit rpeaks, kuriems json faile nerasta atitikmenų, tam rpeaks-ui priskiriama\")\n",
    "print(f\"anotacija 'U'.\")\n",
    "print(f\"Įvertinimas atitinka realią situaciją, kai gydytojas nesikiša į anotacijų redagavimą.\")\n",
    "\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\\\DI'   # variantas: Windows\n",
    "    # Duomenu_aplankas = 'F:\\DI\\Data\\MIT&ZIVE\\VU'   # variantas: Herkulis\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI'   # arba variantas: UBUNTU, be Docker\n",
    "    # Duomenu_aplankas = '/home/kesju/DI/GITLAB'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Vietinės talpyklos aplankas ir pūpsnių atributų failas\n",
    "db_folder = 'MAKETAS'\n",
    "# db_folder = 'analysis'\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "selected_beats = {'N':0, 'S':1, 'V':2}\n",
    "all_beats =  {'N':0, 'S':1, 'V':2, 'U':3, 'F':3}  \n",
    "\n",
    "# Diskretizavimo dažnis:\n",
    "fs = 200\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////\n",
    "\n",
    "#  Nuoroda į aplanką su MIT2ZIVE duomenų rinkiniu\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su EKG įrašais (.npy) ir anotacijomis (.json)\n",
    "rec_dir = Path(db_path, 'data')\n",
    "# rec_dir = Path(db_path, 'test')\n",
    "\n",
    "# Nuoroda į modelio aplanką\n",
    "# model_dir = Path(Duomenu_aplankas, 'DNN', 'best_models', 'all_ft')\n",
    "model_dir = 'model_cnn_fda_vu_v1'\n",
    "\n",
    "# Užduodame, ar filtruojame įrašus\n",
    "Filtr_flag = False  # True - filtruoti\n",
    "\n",
    "\n",
    "# Išvedame parametrus\n",
    "print(\"\\nBendras duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"Zive duomenų aplankas: \", db_folder)\n",
    "print(\"Aplankas su originaliais EKG įrašais ir anotacijomis (.json) \", rec_dir)\n",
    "print(\"Diskretizavimo dažnis: \", fs)\n",
    "print('Klasifikavimo schema:', selected_beats)\n",
    "print('Klasių skaičius:', len(selected_beats))\n",
    "print('Visos galimos anotacijos:', list(all_beats.keys()))\n",
    "print(\"Modelio ir scaler parametrai nuskaitomas iš aplanko: \", model_dir)\n",
    "# print(\"\\n\")\n",
    "\n",
    "if (Filtr_flag):\n",
    "    # Filtruojame izoliniją su 0.5 Hz žemo dažnumo filtru\n",
    "    lowcut = 0.5\n",
    "    method = 'butterworth'\n",
    "    order = 5\n",
    "    print(f\"\\nEKG įrašai filtruojami su Neurokit2\")\n",
    "    print(f\"Parametrai: lowcut:{lowcut} method: {method} order: {order} \")\n",
    "else:\n",
    "    print(f\"\\nEKG įrašas nefiltruotas\")\n",
    "print()\n",
    "\n",
    "# PASIRUOŠIMAS\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", 6000)\n",
    "# pd.set_option(\"display.max_columns\",200)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Naudojamų požymių sąrašas \n",
    "all_features = ['seq_size','RR_l_0', 'RR_r_0', 'RR_r/RR_l','wl_side','wr_side',\n",
    "                'signal_mean', 'signal_std', 'P_val', 'Q_val', 'R_val', 'S_val', 'T_val',\n",
    "                'P_pos', 'Q_pos', 'R_pos', 'S_pos', 'T_pos', 'QRS', 'PR', 'ST', 'QT', '0', '1', '2',\n",
    "                '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
    "                '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32',\n",
    "                '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
    "                '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
    "                '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74',\n",
    "                '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88',\n",
    "                '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
    "                '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114',\n",
    "                '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126',\n",
    "                '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
    "                '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150',\n",
    "                '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162',\n",
    "                '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
    "                '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186',\n",
    "                '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198',\n",
    "                '199']\n",
    "\n",
    "print(f\"Atliekama pūpsnių su anotacijomis {list(selected_beats.keys())} pacientų įrašuose klasifikacija\")\n",
    "\n",
    "# NURODOME PACIENTŲ SĄRAŠĄ\n",
    "\n",
    "# 4 testiniai įrašai GitLab\n",
    "FileNames = [1625400.796, 1625402.027, 1630757.924, 1631141.764] #  \n",
    "\n",
    "# Sąrašas testavimui\n",
    "FileNames = [\n",
    "            1625405.103, # 1,  nesutampančių 10, anotatoriaus panaikintų rpikų: 3, pridėtų: 7\n",
    "            1642627.410, # 0,  nesutampančių 41, anotatoriaus panaikintų rpikų: 41, pridėtų: 0    \n",
    "            1638801.784, # 2 ,  nesutampančių 40, anotatoriaus panaikintų rpikų: 22, pridėtų: 18\n",
    "            1637623.546, # 0 ,  nesutampančių 37, anotatoriaus panaikintų rpikų: 37, pridėtų: 0\n",
    "            1637622.288, # 1 ,  nesutampančių 33, anotatoriaus panaikintų rpikų: 32, pridėtų: 1\n",
    "            1636596.765, # 0 ,  nesutampančių 22, anotatoriaus panaikintų rpikų: 21, pridėtų: 1\n",
    "            1632731.258, # 0 ,  nesutampančių 22, anotatoriaus panaikintų rpikų: 21, pridėtų: 1\n",
    "            1632729.377] # 0 ,  nesutampančių 19, anotatoriaus panaikintų rpikų: 0, pridėtų: 19\n",
    "\n",
    "# FileNames = [1625405.103] # nesutampa\n",
    "\n",
    "FileNames = [ # Naudoti atnaujintam analyse.py testuoti, visi kokybės 0\n",
    "1631141.137,\n",
    "1631039.807,\n",
    "1633434.198,\n",
    "1636495.646,\n",
    "1631027.284,\n",
    "1630733.908,\n",
    "1642627.410\n",
    "]\n",
    "\n",
    "# VARIANTAS, KAI UŽDUODAMI FAILŲ VARDAI IR SKAITOMI ORIGINALUS ZIVE FAILAI \n",
    "# 20 atrinktų testinių sąrašas\n",
    "FileNames = [\n",
    "1626934.963,\n",
    "1626931.201,\n",
    "1630715.664,\n",
    "1630714.569,\n",
    "1630729.576,\n",
    "1630735.143,\n",
    "1630693.635,\n",
    "1630734.526,\n",
    "1630718.396,\n",
    "1630721.49,\n",
    "1631139.883,\n",
    "1631083.411,\n",
    "1631039.923,\n",
    "1631029.786,\n",
    "1632342.032,\n",
    "1633428.56,\n",
    "1633584.898,\n",
    "1633405.853,\n",
    "1634112.089,\n",
    "1636451.86\n",
    "]\n",
    "\n",
    "\n",
    "# Testavimui\n",
    "FileNames = [\n",
    "1626934.963,\n",
    "10301.001\n",
    "]\n",
    "\n",
    "# DS2 - Train imties pacientai\n",
    "PacientNrs1 = [\n",
    "    100, 103, 105, 111, 113, 117, 121, 123, 200, 202, 210, 212, 213, 214, 219, 221, 222, 228, 231, 232, 233, 234\n",
    "]\n",
    "\n",
    "# DS1 - Validate imties pacientai (Povilo tvarka)\n",
    "PacientNrs2 = [\n",
    "101, 106, 108, 109, 112, 114, 115, 116, 118, 119, 122, 124, 201, 203, 205, 208, 209, 215, 220, 223,230]\n",
    "\n",
    "PacientNrsTst = [108]\n",
    "\n",
    "# Formuojame failų vardus sudalintiems MIT2ZIVE duomenims į 3 dalis (iš MAKETO):\n",
    "n = 3\n",
    "file_names = []\n",
    "# Ciklas per pacientų įrašus\n",
    "for record_nr in PacientNrsTst:\n",
    "    for sub_recId in range(n):\n",
    "        # Suformuojame padalinto EKG įrašo failo vardą (pvz. iš '100' padarome 10001.001) \n",
    "        rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "        rec_ext = '{:03d}'.format(sub_recId+1)\n",
    "        file_name = str(record_nr) + rec_sub + '.' + rec_ext\n",
    "        file_names.append(file_name) \n",
    "print(\"Viso duomenų:\", len(file_names), \"Duomenų sąrašas:\", np.array(file_names))        \n",
    "\n",
    "path_for_results = Path(db_path, 'rezultatai_tst')\n",
    "print(f\"\\nAplankas rezultatams: {path_for_results}\")\n",
    "create_dir(path_for_results)\n",
    "\n",
    "# Kas kiek išvedamas apdorotų sekų skaičius\n",
    "show_period = 100\n",
    "\n",
    "# Klasių simbolinių vardų sąrašas ir klasių skaičius\n",
    "class_names = list(selected_beats.keys()) \n",
    "n_classes = len(selected_beats)\n",
    "# print(class_names)\n",
    "\n",
    "                    # SUFORMUOJAME all_beats_attr\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "annot_grouping = {'N':'N', 'S':'S', 'V':'V', 'U':'U'}\n",
    "\n",
    "# Sukūriame masyvą sekų atributų sąrašui\n",
    "# https://sparkbyexamples.com/pandas/pandas-empty-dataframe-with-specific-column-types/\n",
    "\n",
    "all_beats_attr = pd.DataFrame({'file_name': pd.Series(dtype='str'),\n",
    "                   'sample': pd.Series(dtype='int'),\n",
    "                   'symbol': pd.Series(dtype='str'),\n",
    "                   'label': pd.Series(dtype='int'),\n",
    "                   'pred_label': pd.Series(dtype='int')\n",
    "                   })\n",
    "\n",
    "df_rec_results = pd.DataFrame({'file_name':pd.Series(dtype='str'),  \n",
    "    'userId':pd.Series(dtype='str'), 'recId':pd.Series(dtype='int'), 'signal_length':pd.Series(dtype='int'),\n",
    "    'N':pd.Series(dtype='int'), 'S':pd.Series(dtype='int'), 'V':pd.Series(dtype='int'), 'U':pd.Series(dtype='int'),\n",
    "    'Nml':pd.Series(dtype='int'), 'Sml':pd.Series(dtype='int'), 'Vml':pd.Series(dtype='int'), 'Uml':pd.Series(dtype='int'),\n",
    "    'Nprec':pd.Series(dtype='float') , 'Nrec':pd.Series(dtype='float'), 'Nfsc':pd.Series(dtype='float'),\n",
    "    'Sprec':pd.Series(dtype='float') , 'Srec':pd.Series(dtype='float'), 'Sfsc':pd.Series(dtype='float'),\n",
    "    'Vprec':pd.Series(dtype='float') , 'Vrec':pd.Series(dtype='float'), 'Vfsc':pd.Series(dtype='float'), \n",
    "     'Err%':pd.Series(dtype='float'), 'Noise%':pd.Series(dtype='float')})\n",
    "# Pandas Empty DataFrame with Specific Column Types\n",
    "# https://sparkbyexamples.com/pandas/pandas-empty-dataframe-with-specific-column-types/\n",
    "\n",
    "rows_list = []\n",
    "\n",
    "# CIKLAS PER PACIENTŲ ĮRAŠUS\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Šios dvi eilutės MIT2ZIVE duomenims nereikalingos\n",
    "# file_names=[\"%.3f\" % i for i in FileNames]\n",
    "# print(file_names)\n",
    "\n",
    "# Ciklas per visą įrašų sąrašą\n",
    "for file_name in file_names:\n",
    "    print(f\"\\nZive įrašas:  {file_name:>2}\")\n",
    "\n",
    "# mark2\n",
    " # ////////////////////////////////////////////////////////////////////////////////////////\n",
    "    # Šita dalis skirta atr_sample ir atr_symbol parengimui\n",
    "    # Jie bus gauti kombinuojant Neurokit rpeaks ir anotacijas iš json\n",
    "    # Įrašas prieš ieškant rpeaks su Neurokit gali būti filtruojamas\n",
    "\n",
    "    # Nuskaitome gydytojo koreguotus EKG įrašo atributus iš įrašo json \n",
    "    df_rpeaks = zive_read_df_rpeaks(rec_dir, file_name)\n",
    "    rpeaks_from_json = df_rpeaks['sampleIndex'].to_numpy()\n",
    "    symbols_from_json = df_rpeaks['annotationValue'].to_numpy()\n",
    "    \n",
    "    # Informacija iš json failo. Jei pasitaiko symbol 'U' arba 'F', pūpsniui suteikiame klasę 3  \n",
    "    test_labels = np.array([all_beats[symbol] for symbol in symbols_from_json])\n",
    "    label_sums, total = get_label_sums(test_labels, all_beats)  \n",
    "    print(\"Informacija iš json failo. Labels: \", list(all_beats.keys()), label_sums, \"Total:\", total)\n",
    "\n",
    "    # print(\"\\nAnotacijos iš json:\")\n",
    "    # print(f\"i     index   rpeak\")\n",
    "    # for i in range(len(rpeaks_from_json)):\n",
    "    #     if (symbols_from_json[i] != 'N'):\n",
    "    #         print(f\"{i}  {rpeaks_from_json[i]:>7}  {symbols_from_json[i]:>9}\")\n",
    "\n",
    "    # Paruošiame įrašą rpeaks suradimui panaudojant Neurokit\n",
    "\n",
    "    # Nuskaitome EKG įrašą (Zive formatu)\n",
    "    filepath = Path(rec_dir, file_name)\n",
    "\n",
    "    # sign_raw = zive_read_file_1ch(filepath) #zive_read_file_1ch pakeistas į read_signal_modif,\n",
    "    # kuris skaito ir mit2zive duomenis\n",
    "\n",
    "    sign_raw = read_signal_modif(filepath)\n",
    "\n",
    "    signal_length = sign_raw.shape[0]\n",
    "    signal = sign_raw\n",
    "    \n",
    "    # Filtracija/ arba ne\n",
    "    if (Filtr_flag):\n",
    "        signal = nk.signal_filter(signal=sign_raw, sampling_rate=200, lowcut=lowcut, method=method, order=order)\n",
    "        # signal = nk.signal_filter(signal=sign_raw, sampling_rate=200, lowcut=0.2, method=\"butterworth\", order=5)\n",
    "        signal_length = signal.shape[0]\n",
    "    else:\n",
    "        signal = sign_raw\n",
    "        signal_length = sign_raw.shape[0]\n",
    "\n",
    "    # Surandame rpeaks su Neurokit\n",
    "    ecg_signal_df = pd.DataFrame(signal, columns=['orig'])\n",
    "    analysis_results = AnalyseHeartrate(ecg_signal_df)\n",
    "    rpeaks_from_signal = analysis_results['rpeaks']\n",
    "    # print(f\"rpeaks iš signal: {len(rpeaks_from_signal)}\")\n",
    "\n",
    "    # Formuojame atr_sample ir pradinį atr_symbol\n",
    "    atr_sample = rpeaks_from_signal\n",
    "    atr_symbol = np.full(len(rpeaks_from_signal), 'N',  dtype=str)\n",
    "\n",
    "    # Fiksuojame, kiek rankiniu būdu pridėta rpikų, jas ignoruosime\n",
    "    ab = np.setdiff1d(rpeaks_from_json, rpeaks_from_signal)\n",
    "    # print(\"Reikšmės faile rpeaks_from_json kurių nėra faile rpeaks_from_signal\")\n",
    "\n",
    "    # Surandame masyve rpeaks_from_signal reikšmes rpeaks, kurios yra ir rpeaks_from_json\n",
    "    aa, ind_a, ind_b = np.intersect1d(rpeaks_from_signal, rpeaks_from_json, assume_unique=True,return_indices=True )\n",
    "    # if (len(aa) == len(rpeaks_from_signal)):\n",
    "    #     print(\"\\nVisi Neurokit rpikai yra ir json:\", len(aa))\n",
    "    # else:\n",
    "    #     print(\"\\nPanaikinta:\", len(rpeaks_from_signal) - len(aa))\n",
    "\n",
    "    # Šioms reikšmėms anotacijas perrašysime iš json\n",
    "    atr_symbol[ind_a] = symbols_from_json[ind_b]    \n",
    "\n",
    "    # Surandame masyve rpeaks_from_signal reikšmes rpeaks, kurios rpeaks_from_json yra panaikintos\n",
    "    ba = np.setdiff1d(rpeaks_from_signal, rpeaks_from_json, assume_unique=True)\n",
    "    print(\"Anotuojant pridėta rpikų:\", len(ab),\", jos bus ignoruojamos. Panaikinta:\", len(ba),\", joms bus priskiriama anotacija 'U', bus perkelta:\", len(ind_a) )\n",
    "    \n",
    "    # rpeaks reikšmės, kurios anotuojant yra pridėtos. Jos yra ignoruojamos\n",
    "    # if (np.size(ab) != 0):\n",
    "    #     print(\"\\nPridėtos reikšmės:\")\n",
    "    #     sorter = np.argsort(rpeaks_from_json)\n",
    "    #     idxs = sorter[np.searchsorted(rpeaks_from_json, ab, sorter=sorter)]\n",
    "    #     print(f\"i     index   rpeak\")\n",
    "    #     for i in range(len(idxs)):\n",
    "    #         print(f\"{i} {idxs[i]:>9} {ab[i]:>7} {symbols_from_json[idxs[i]]} \")\n",
    "\n",
    "    # rpeaks reikšmėms iš rpeaks_from_signal, kurios rpeaks_from_json yra panaikintos, anotacijos priskiriamos 'U'\n",
    "    # if (np.size(ba) != 0):\n",
    "    #     print(\"\\nPanaikintos reikšmės:\")\n",
    "    #     sorter = np.argsort(rpeaks_from_signal)\n",
    "    #     idxs = sorter[np.searchsorted(rpeaks_from_signal, ba, sorter=sorter)]\n",
    "    #     print(f\"i     index   rpeak\")\n",
    "    #     for i in range(len(idxs)):\n",
    "    #         print(f\"{i} {idxs[i]:>9} {ba[i]:>7}\")\n",
    "    #     atr_symbol[idxs] = 'U'\n",
    "\n",
    "    # print(\"\\nlen(atr_symbol)\", len(atr_symbol))\n",
    "    # print(f\"i     index   rpeak\")\n",
    "    # for i in range(len(atr_symbol)):\n",
    "    #     if (atr_symbol[i] != 'N'):\n",
    "    #         print(f\"{i} {atr_sample[i]:>7} {atr_symbol[i]:>7} \")\n",
    "\n",
    "# Pasiruošimo pabaiga: toliau perduodame   atr_sample, atr_symbol ir signal, signal_length\n",
    "# ///////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# \n",
    "\n",
    "    # Surandame ir išvedame įrašo atributus\n",
    "    userId, recId = zive_read_rec_id(rec_dir, file_name)\n",
    "\n",
    "    print(f\"file_name: {file_name:>2} userId: {userId} recId: {recId} signal_length: {signal_length}  rpeaks: {len(rpeaks_from_signal)}\")\n",
    "\n",
    "    # Jei pasitaiko symbol 'U' arba 'F', pūpsniui suteikiame klasę 3, kurią vėliau apvalysime  \n",
    "    test_labels = np.array([all_beats[symbol] for symbol in atr_symbol])\n",
    "\n",
    "    label_sums, total = get_label_sums(test_labels, all_beats)  \n",
    "    # print(\"test_labels: \", list(all_beats.keys()), label_sums, \"Total:\", total)\n",
    "\n",
    "    # Surandame ML anotacijų skaitmenines reikšmes pred_labels\n",
    "    # Jei atr_symbol atranda anotaciją 'U', tai jos neklasifikuoja,\n",
    "    # bet iš karto patalpina '3' į pred_labels atitinkamą vietą.\n",
    "    # Į pred_labels taip pat įrašomas '3' pirmam ir paskutiniam pūpsniui,\n",
    "    # o taip pat pakliuvusiems į ommited sritį, \n",
    "    # pred_labels = predict_cnn_fda_vu_v1_micro(signal, atr_sample, atr_symbol, model_dir)\n",
    "\n",
    "    pred_labels = classify_cnn_fda_vu_vasara_v2_modif(signal, atr_sample, model_dir, all_features)\n",
    "    \n",
    "    # pred_labels turi būti tokio pat ilgio, kaip ir test_labels\n",
    "    if (len(test_labels) != len(pred_labels)):\n",
    "        raise Exception(f\"Klaida! file_name: {file_name}. Nesutampa test_labels ir pred_labels ilgiai\")     \n",
    "\n",
    "    label_sums_ml, total = get_label_sums(pred_labels, all_beats)  \n",
    "    # print(\"pred_labels: \", list(all_beats.keys()), label_sums_ml, \"Total:\", total)\n",
    "\n",
    "    # Surandame vietas su ekstrasistolemis ir išvedame jų sąrašą vizualiniam įvertinimui. \n",
    "    classification=[]\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "        if ((pred_labels[i] != 0) or test_labels[i] != 0):\n",
    "            classification.append({'i':i, 'sample':i_sample, 'annot':test_labels[i], 'pred':pred_labels[i]})\n",
    "\n",
    "    # Vietų sąrašas išvedamas\n",
    "    # Dirbant su daug įrašų sąrašo išvedimą reikia užblokuoti !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    classification = []  # uzblokuota\n",
    "    if (classification):\n",
    "        print('\\nVietos su ekstrasistolėmis test_y arba pred_y:')\n",
    "        for row in classification:\n",
    "            print(f\"i: {row['i']:>7} sample: {row['sample']:>7}   annot_label: {row['annot']:>2}   pred_label: {row['pred']:>2}\")  \n",
    "\n",
    "    # Ciklas per visas paciento įrašo anotacijas (simbolius) ir jų vietas (i_sample)\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "\n",
    "        # Formuojame pūpsnio atributus\n",
    "        beats_attr = {'file_name':file_name, 'sample':int(i_sample), \n",
    "                        'symbol':str(atr_symbol[i]), 'label':test_labels[i], 'pred_label':pred_labels[i]}\n",
    "\n",
    "        # Kaupiame su concat\n",
    "        df_new_row = pd.DataFrame([beats_attr])\n",
    "        all_beats_attr = pd.concat([all_beats_attr, df_new_row])\n",
    "\n",
    " # Suformuojame klasių numerių masyvus confusion matricai skaičiuoti, surandama confusion matrica\n",
    "\n",
    "    # pred_labels turi būti tokio pat ilgio, kaip ir test_labels\n",
    "    if (len(test_labels) != len(pred_labels)):\n",
    "        raise Exception(f\"Klaida! file_name: {file_name}. Nesutampa test_labels ir pred_labels ilgiai\")     \n",
    "\n",
    "    test_labels_mod, pred_labels_mod = get_rid_off_class_3(test_labels, pred_labels)\n",
    "    label_sums_ml_3, total = get_label_sums(pred_labels_mod, all_beats)  \n",
    "    # print(\"pred_labels_3: \", list(all_beats.keys()), label_sums_ml_3, \"Total:\", total)\n",
    "\n",
    "    confusion = confusion_matrix(test_labels_mod, pred_labels_mod)\n",
    "    # print()\n",
    "    # print(confusion)\n",
    "    prec,rec,fsc,sup = precision_recall_fscore_support(test_labels_mod, pred_labels_mod, labels=[0, 1, 2], zero_division=0)\n",
    "\n",
    "    str1 =f\"N:{int(label_sums[0]):>5} S:{(int(label_sums[1])):3} V:{int(label_sums[2]):3} U:{int(label_sums[3]):3}\" \n",
    "    str2 =f\"  Nml:{int(label_sums_ml[0]):>5} Sml:{(int(label_sums_ml[1])):3} Vml:{int(label_sums_ml[2]):3} Uml:{int(label_sums_ml[3]):3}\" \n",
    "    str3 = f\"  Nprec:{prec[0]:>5.2f} Nrec:{rec[0]:5.2f} Nfsc:{fsc[0]:5.2f}\"\n",
    "    str4 = f\"  Sprec:{prec[1]:>5.2f} Srec:{rec[1]:5.2f} Sfsc:{fsc[1]:5.2f}\"\n",
    "    str5 = f\"  Vprec:{prec[2]:>5.2f} Vrec:{rec[2]:5.2f} Vfsc:{fsc[2]:5.2f}\"\n",
    "    # print()\n",
    "    print(str1+str2+str3+str4+str5)\n",
    "\n",
    "    dict_rec_results = {'file_name':file_name,\n",
    "    'userId': userId, 'recId': recId, 'signal_length': signal_length,\n",
    "    'N':label_sums[0], 'S':label_sums[1], 'V':label_sums[2], 'U':label_sums[3],\n",
    "    'Nml':label_sums_ml[0], 'Sml':label_sums_ml[1], 'Vml':label_sums_ml[2], 'Uml':label_sums_ml[3],\n",
    "    'Nprec':prec[0], 'Nrec':rec[0], 'Nfsc':fsc[0],\n",
    "    'Sprec':prec[1], 'Srec':rec[1], 'Sfsc':fsc[1],\n",
    "    'Vprec':prec[2], 'Vrec':rec[2], 'Vfsc':fsc[2] \n",
    "    }\n",
    "    rows_list.append(dict_rec_results)\n",
    "\n",
    "df_rec_results =  pd.DataFrame(rows_list) \n",
    "\n",
    "# Ciklo per pacientų įrašus pabaiga\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\n')\n",
    "runtime(end_time-start_time)\n",
    "\n",
    "filepath = Path(path_for_results, 'klasifikacijos_rezultatai_irasams.csv') \n",
    "df_rec_results.to_csv(filepath)    \n",
    "print(f'\\nRezultatai įrašyti į:  {filepath}')\n",
    "\n",
    "# Pernumeruojame indeksus, kad būtų nuo 0 iš eilės\n",
    "all_beats_attr.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Įrašome sekos atributų masyvą į rec_dir aplanką\n",
    "file_path = Path(path_for_results, 'all_beats_attr.csv')\n",
    "all_beats_attr.to_csv(file_path)\n",
    "print(\"\\nAtributų freimas įrašytas: į \", file_path, \"\\n\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODELIO TIKSLUMO VERTINIMO REZULTATAI\n",
      "Modelis iš aplanko:  model_cnn_fda_vu_v1\n",
      "Pūpsnių klasės:  ['N', 'S', 'V', 'U', 'F'] [1737    3    9    0    0] Total: 1749\n",
      "Klasifikuojamos klasės: ['N', 'S', 'V']\n",
      "\n",
      "APIBENDRINTI REZULTATAI\n",
      "\n",
      "Confusion Matrix\n",
      "      N  S   V\n",
      "N  1624  8  16\n",
      "S     0  3   0\n",
      "V     2  1   6\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix\n",
      "      N     S     V\n",
      "N 0.985 0.005 0.010\n",
      "S 0.000 1.000 0.000\n",
      "V 0.222 0.111 0.667\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N      0.999     0.985     0.992      1648\n",
      "           S      0.250     1.000     0.400         3\n",
      "           V      0.273     0.667     0.387         9\n",
      "\n",
      "    accuracy                          0.984      1660\n",
      "   macro avg      0.507     0.884     0.593      1660\n",
      "weighted avg      0.993     0.984     0.988      1660\n",
      "\n",
      "\n",
      "Apibendrinti_rezultatai įrašyti į:  /home/kesju/DI/MAKETAS/rezultatai_tst/apibendrinti_rezultatai.csv\n"
     ]
    }
   ],
   "source": [
    "# MODELIO TIKSLUMO VERTINIMO IŠ VERTINIMO IMTIES REZULTATAI\n",
    "\n",
    "# Nuskaitome pūpsnių atributų masyvą\n",
    "file_path = Path(path_for_results, 'all_beats_attr.csv')\n",
    "all_beats_attr = pd.read_csv(file_path, index_col=0, dtype = {'file_name': str, \n",
    "                                            'sample': int, 'symbol': str, 'label': int, 'pred_label':int })\n",
    "\n",
    "# Sukūriame anotuotų ir automatiškai priskirtų klasių visų įrašų pūpsniams sąrašus \n",
    "validate_ind_lst = all_beats_attr.index\n",
    "y_validate = np.array(all_beats_attr['label']).astype('int')\n",
    "y_predicted = np.array(all_beats_attr['pred_label']).astype('int')\n",
    "\n",
    "print(\"\\nMODELIO TIKSLUMO VERTINIMO REZULTATAI\")\n",
    "print(\"Modelis iš aplanko: \", model_dir)\n",
    "\n",
    "label_sums, total = get_label_sums(y_validate, all_beats)  \n",
    "print(\"Pūpsnių klasės: \", list(all_beats.keys()), label_sums, \"Total:\", total)\n",
    "print(\"Klasifikuojamos klasės: ['N', 'S', 'V']\")\n",
    "y_validate_mod, y_predicted_mod = get_rid_off_class_3(y_validate, y_predicted)\n",
    "\n",
    "# APIBENDRINTI REZULTATAI\n",
    "\n",
    "print('\\nAPIBENDRINTI REZULTATAI\\n')\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++  čia reiktų įdėtiy_validate, y_predicted valymą nuo 3 klasės\n",
    "\n",
    "# Skaičiuojame ir išvedame klasifikavimo lentelę\n",
    "confusion = confusion_matrix(y_validate_mod, y_predicted_mod)\n",
    "pd.set_option('display.precision',3)\n",
    "show_confusion_matrix(confusion, class_names)\n",
    "# print('\\n')\n",
    "\n",
    "print(\"\\nClassification Report\\n\")\n",
    "# target_names = [key for (key, value) in selected_beats.items()]\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 6000)\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(classification_report(y_validate_mod, y_predicted_mod, target_names=class_names, digits=3))\n",
    "report = classification_report(y_validate_mod, y_predicted_mod, target_names=class_names, output_dict=True)\n",
    "# output_dictbool, default=False, If True, return output as dict.\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "# https://medium.com/@asmaiya/you-can-something-like-this-84d28e0fd31f\n",
    "\n",
    "# Įrašome į diską\n",
    "filepath = Path(path_for_results, 'apibendrinti_rezultatai.csv') \n",
    "df_report.to_csv(filepath)    \n",
    "print(f'\\nApibendrinti_rezultatai įrašyti į:  {filepath}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_lnx38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72fad068c9d13e52ed0ef400fe86b8a1dd89b57112dd527cb7ae681e2ac89056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
