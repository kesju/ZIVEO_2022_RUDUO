{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n",
      "Skriptas zive-arrh EKG segmentų apmokyto klasifikatoriaus tikslumo įvertinimui\n",
      "Modelis CNN VU su EKG sekos reikšmėmis, EKG formos požymiais, RR intervalais prieš ir po R dantelio\n",
      "OS in my system :  win32\n",
      "\n",
      "Bendras duomenų aplankas:  D:\\DI\\Data\\MIT&ZIVE\\VU\n",
      "Zive duomenų aplankas:  DUOM_VU\n",
      "Aplankas su originaliais EKG įrašais ir anotacijomis (.json)  D:\\DI\\Data\\MIT&ZIVE\\VU\\DUOM_VU\\records_npy\n",
      "Pūpsnių atributų failas: all_beats_attr_z.csv\n",
      "Diskretizavimo dažnis:  200\n",
      "Klasifikavimo schema: {'N': 0, 'S': 1, 'V': 2}\n",
      "Klasių skaičius: 3\n",
      "Modelio ir scaler parametrai nuskaitomas iš aplanko:  model_cnn_fda_vu_v0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variantas:  vieno įrašo detalus testavimas \n",
    "\n",
    "# Atnaujintas variantas, po to, kaip padaryti pakeitimai failų varduose 2022 03 26\n",
    "# Šis variantas pritaikytas npy formato zive įrašams, kuriems pakeistas, lyginant su \n",
    "# originaliais įrašais, failo vardas iš `file_name` į `SubjCode`, pridedant `userNr`\n",
    "# prie `file_name`. \n",
    "#\n",
    "# Skriptas zive EKG pūpsnių CNN VU klasifikatoriaus testavimui ir tikslumo įvertinimui, funkcijos \n",
    "# paimamos iš aplanko zive_cnn_fda_vu_v1.py, modelis iš model_cnn_fda_vu_v1, testuojami duomenys\n",
    "# iš db_folder įrašų saugyklos, jame yra ir failas all_beats_attr. \n",
    "\n",
    "# Testavimui imami įrašai iš sąrašo SubjCodes, kuris arba paimamas if failo info_create.json,\n",
    "# arba iš mokymo, validavimo, testavimo sarašų, pvz. train_subjcode_lst.csv. Visiems įrašams iš šių\n",
    "# sąrašų egzistuoja informacija apie pūpsnius faile all_beats_attr.\n",
    " \n",
    "# Skripte yra galimybė išvesti ekstrasistolių vietas įraše.\n",
    "# Dirbant su daug įrašų reiktų užblokuoti: classification = []  # Užblokuota\n",
    " \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys, os, json\n",
    "from pathlib import Path\n",
    "# from icecream import ic\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from zive_util_vu import cm2df, show_confusion_matrix \n",
    "from zive_util_vu import create_dir, create_subdir, get_rev_dictionary\n",
    "from zive_util_vu import runtime, split_SubjCode\n",
    "from zive_util_vu import get_freq_unique_values\n",
    "\n",
    "from zive_util_vu import get_beat_attributes\n",
    "from zive_util_vu import get_userId, read_rec, get_filename \n",
    "from zive_util_vu import confusion_matrix_modified, zive_read_df_rpeaks\n",
    "\n",
    "from zive_cnn_fda_vu_v1 import predict_cnn_fda_vu_v1, zive_read_file_1ch, classify_cnn_fda_vu_v1\n",
    "# Pastaba: zive_read_file_1ch importuoju iš zive_cnn_fda_vu_v1, nors ji yra ir zive_util_vu.py\n",
    "# tam, kad atskirti funkcijas, kurios importuojamos skripte zive analysis, nuo tų funkcijų,\n",
    "# kurios reikalingos tik zive_accuracy_cnn_vu_v1 ir v2. \n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "print(\"Skriptas zive-arrh EKG segmentų apmokyto klasifikatoriaus tikslumo įvertinimui\")\n",
    "print('Modelis CNN VU su EKG sekos reikšmėmis, EKG formos požymiais, RR intervalais prieš ir po R dantelio')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\DI\\Data\\MIT&ZIVE\\VU'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/Data/MIT&ZIVE/VU'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Vietinės talpyklos aplankas ir pūpsnių atributų failas\n",
    "db_folder = 'DUOM_VU'\n",
    "\n",
    "# Vietinės talpyklos aplankas ir pūpsnių atributų failas\n",
    "all_beats_attr_fname = 'all_beats_attr_z.csv'\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "selected_beats = {'N':0, 'S':1, 'V':2}\n",
    "all_beats =  {'N':0, 'S':1, 'V':2, 'U':3}  \n",
    "\n",
    "# Diskretizavimo dažnis:\n",
    "fs = 200\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////\n",
    "\n",
    "#  Nuoroda į aplanką su MIT2ZIVE duomenų rinkiniu\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su EKG įrašais (.npy) ir anotacijomis (.json)\n",
    "rec_dir = Path(db_path, 'records_npy')\n",
    "\n",
    "# Nuoroda į modelio aplanką\n",
    "# model_dir = Path(Duomenu_aplankas, 'DNN', 'best_models', 'all_ft')\n",
    "model_dir = 'model_cnn_fda_vu_v0'\n",
    "\n",
    "# Išvedame parametrus\n",
    "print(\"\\nBendras duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"Zive duomenų aplankas: \", db_folder)\n",
    "print(\"Aplankas su originaliais EKG įrašais ir anotacijomis (.json) \", rec_dir)\n",
    "print(\"Pūpsnių atributų failas:\", all_beats_attr_fname)\n",
    "print(\"Diskretizavimo dažnis: \", fs)\n",
    "print('Klasifikavimo schema:', selected_beats)\n",
    "print('Klasių skaičius:', len(selected_beats))\n",
    "print(\"Modelio ir scaler parametrai nuskaitomas iš aplanko: \", model_dir)\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Atliekama pūpsnių pacientų įrašuose klasifikacija\n",
      "Klasifikuojamų įrašų sąrašas: [10051]\n",
      "Sąrašas nuskaitytas iš: testinis_sarasas.csv\n",
      "\n",
      "Zive įrašas:\n",
      "SubjCode: 10051 userNr: 1005 file_name: 1630735.143 signal_length: 127999\n",
      "userId: 613b1c6f3d08d4370acdc8f3  recordingId: 613f56f73d08d422c4cdcb86\n",
      "test_symbols:  ['N' 'S'] [538   4] 542\n",
      "test_labels:  [0 1] [538   4] 542\n",
      "\n",
      "atr_sample: [  185   422   657   892  1135  1378  1621  1867  2117  2366  2613  2857\n",
      "  3096  3330  3559  3792  4025  4259  4493  4729  4964  5203  5448  5698\n",
      "  5943  6184  6430  6670  6906  7143  7390  7630  7878  8129  8376  8618\n",
      "  8863  9106  9347  9522  9815 10064 10310 10555 10799 11043 11279 11522\n",
      " 11766 12009 12251 12492 12735 12976 13220 13465 13703 13947 14186 14424\n",
      " 14658 14896 15141 15378 15620 15864 16103 16345 16582 16824 17059 17299\n",
      " 17545 17786 18021 18254 18488 18717 18902 19177 19421 19589 19895 20137\n",
      " 20379 20619 20856 21093 21329 21563 21797 22033 22266 22495 22727 22954\n",
      " 23185 23414 23647 23879 24112 24345 24579 24806 25038 25273 25505 25740\n",
      " 25974 26212 26447 26682 26921 27157 27404 27648 27892 28129 28367 28608\n",
      " 28843 29078 29321 29565 29811 30058 30308 30553 30794 31032 31274 31520\n",
      " 31755 31980 32192 32396 32597 32799 33006 33217 33437 33666 33905 34144\n",
      " 34390 34638 34881 35128 35373 35617 35854 36095 36341 36586 36829 37074\n",
      " 37325 37577 37827 38077 38326 38558 38786 39024 39259 39487 39724 39968\n",
      " 40214 40460 40712 40962 41212 41462 41708 41953 42197 42441 42684 42921\n",
      " 43157 43395 43634 43883 44135 44390 44640 44889 45135 45375 45614 45857\n",
      " 46098 46340 46588 46831 47074 47315 47553 47787]\n",
      "\n",
      "atr_symbol: ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'S' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N']\n",
      "pradėjome predict_cnn_fda_vu_v1\n",
      "pred_labels:  [0 2 3] [539   1   2] 542\n",
      "sample:     185   annot_label:  N   pred_label:  U\n",
      "sample:     422   annot_label:  N   pred_label:  V\n",
      "sample:    9522   annot_label:  S   pred_label:  N\n",
      "sample:   18902   annot_label:  S   pred_label:  N\n",
      "sample:   19589   annot_label:  S   pred_label:  N\n",
      "sample:  125790   annot_label:  S   pred_label:  N\n",
      "sample:  127947   annot_label:  N   pred_label:  U\n",
      "rpeaks total: 542\n",
      "excluded rpeaks ('U'): 2\n",
      "classified rpeaks: 540\n",
      "automaticRpeakAnnotations: 5\n",
      "Confusion Matrix\n",
      "     N  S  V\n",
      "N  535  0  1\n",
      "S    4  0  0\n",
      "V    0  0  0\n",
      "\n",
      "\n",
      "Zero values! Cannot calculate Normalized Confusion Matrix\n",
      "N:  536 S:  4 V:  0  Nprec: 0.99 Nrec: 1.00 Nfsc: 1.00  Sprec: 0.00 Srec: 0.00 Sfsc: 0.00  Vprec: 0.00 Vrec: 0.00 Vfsc: 0.00\n",
      "pradėjome predict_cnn_fda_vu_v1\n",
      "\n",
      "\n",
      "Runtime: 00:03:40\n"
     ]
    }
   ],
   "source": [
    "# PASIRUOŠIMAS\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 6000, \"display.max_columns\",200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Naudojamų požymių sąrašas\n",
    "\n",
    "all_features = ['RRl', 'RRr', 'RRl/RRr',\n",
    "                'signal_mean', 'signal_std', 'P_val', 'Q_val', 'R_val', 'S_val', 'T_val',\n",
    "                'P_pos', 'Q_pos', 'R_pos', 'S_pos', 'T_pos', 'QRS', 'PR', 'ST', 'QT', '0', '1', '2',\n",
    "                '3', '4', '5', '6', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
    "                '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32',\n",
    "                '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
    "                '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
    "                '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74',\n",
    "                '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88',\n",
    "                '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
    "                '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114',\n",
    "                '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126',\n",
    "                '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
    "                '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150',\n",
    "                '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162',\n",
    "                '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
    "                '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186',\n",
    "                '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198',\n",
    "                '199']\n",
    "\n",
    "print(\"\\nAtliekama pūpsnių pacientų įrašuose klasifikacija\")\n",
    "\n",
    "# Pacientų įrašų sąrašas testavimui\n",
    "file_path = 'testinis_sarasas.csv'\n",
    "# SubjCodes = [10021, 10022, 10083, 10091] #Testavimui, iš mokymo imties\n",
    "SubjCodes = [10051] #Testavimuas pacientų įrašų sąrašas\n",
    "\n",
    "print(\"Klasifikuojamų įrašų sąrašas:\", SubjCodes)\n",
    "print(f\"Sąrašas nuskaitytas iš: {file_path}\")\n",
    "\n",
    "# Kas kiek išvedamas apdorotų sekų skaičius\n",
    "show_period = 100\n",
    "\n",
    "# Klasių simbolinių vardų sąrašas ir klasių skaičius\n",
    "class_names = list(selected_beats.keys()) \n",
    "n_classes = len(selected_beats)\n",
    "# print(class_names)\n",
    "\n",
    "# Nuskaitome pūpsnių atributų masyvą\n",
    "file_path = Path(rec_dir, all_beats_attr_fname)\n",
    "all_beats_attr = pd.read_csv(file_path, index_col=0, dtype = {'userNr': int, 'recordingNr': int,\n",
    "                                                             'sample': int, 'symbol': str, 'label': int})\n",
    "all_beat_indices = all_beats_attr.index\n",
    "\n",
    "index_start = 0\n",
    "# Sukūriame masyvą, į kurį sudėsime visų įrašų pūpsnių anotuotus ir automatiškai surastus klasių numerius\n",
    "validation_set_stats = pd.DataFrame(columns=['idx', 'test_label', 'pred_label', 'SubjCode'])\n",
    "\n",
    "start_time = time.time()\n",
    "# Ciklas per pacientų įrašus\n",
    "for SubjCode in SubjCodes:\n",
    "    \n",
    "    # Nuskaitome EKG įrašą (npy formatu)\n",
    "    sign_raw = read_rec(rec_dir, SubjCode)\n",
    "    signal_length = sign_raw.shape[0]\n",
    "    signal = sign_raw\n",
    "\n",
    "    # Surandame ir išvedame įrašo atributus\n",
    "    print(\"\\nZive įrašas:\")\n",
    "    file_name = get_filename(rec_dir, SubjCode)\n",
    "    userNr, recNr = split_SubjCode(SubjCode)\n",
    "    print(f\"SubjCode: {SubjCode} userNr: {userNr:>2} file_name: {file_name:>2} signal_length: {signal_length}\")\n",
    "    \n",
    "    filepath = Path(rec_dir, str(SubjCode) + '.json')\n",
    "    with open(filepath,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "        data = json.loads(f.read())\n",
    "    userId = data['userId']\n",
    "    recordingId = data['recordingId']\n",
    "    print(f\"userId: {userId}  recordingId: {recordingId}\")\n",
    "\n",
    "    # Filtruojame signalą\n",
    "    # signal = signal_filter(signal=sign_raw, sampling_rate=200, lowcut=0.2, method=\"butterworth\", order=5)\n",
    "\n",
    "    # Nuskaitome paciento anotacijas ir jų indeksus\n",
    "    df_rpeaks = zive_read_df_rpeaks(rec_dir, str(SubjCode))\n",
    "    atr_sample = df_rpeaks['sampleIndex'].to_numpy()\n",
    "    atr_symbol = df_rpeaks['annotationValue'].to_numpy()\n",
    "  \n",
    "\n",
    "    # SUFORMUOJAME EKG ĮRAŠUI TESTINĮ ir PRISKIRTŲ KLASIŲ NUMERIŲ MASYVUS\n",
    "\n",
    "    # Jei pasitaiko symbol 'U' arba 'F', pūpsniui suteikiame klasę 3, kurią vėliau apvalysime  \n",
    "    test_labels = np.array([all_beats[symbol] for symbol in atr_symbol])\n",
    "\n",
    "    (unique, counts) = np.unique(atr_symbol, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    print(\"test_symbols: \", unique, counts, total)\n",
    "\n",
    "    (unique, counts) = np.unique(test_labels, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    print(\"test_labels: \", unique, counts, total)\n",
    "\n",
    "    print(f\"\\natr_sample: {atr_sample[:200]}\")\n",
    "    print(f\"\\natr_symbol: {atr_symbol[:total]}\")\n",
    "\n",
    "    pred_labels = predict_cnn_fda_vu_v1(signal, atr_sample, model_dir)\n",
    "    # pred_labels turi būti tokio pat ilgio, kaip ir test_labels, praleisti (šiuo atveju pirmas\n",
    "    # ir paskutinis pūpsnys), o taip pat pakliuvęs į ommited sritį, pažymimi klase 3\n",
    "    if (len(test_labels) != len(pred_labels)):\n",
    "        raise Exception(f\"Klaida! SubjCode: {SubjCode}. Nesutampa test_labels ir pred_labels ilgiai\")     \n",
    "\n",
    "    (unique, counts) = np.unique(pred_labels, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    print(\"pred_labels: \",unique, counts, total)\n",
    "\n",
    "    symbol_dict = dict(zip(all_beats.values(), all_beats.keys()))\n",
    "    # print(symbol_dict)\n",
    "\n",
    "    # Surandame vietas su ekstrasistolemis ir išvedame jų sąrašą vizualiniam įvertinimui. \n",
    "    classification=[]\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "        if ((pred_labels[i] != 0) or test_labels[i] != 0):\n",
    "            classification.append({'sample':i_sample, 'annot':symbol_dict[test_labels[i]], 'pred':symbol_dict[pred_labels[i]]})\n",
    "\n",
    "    # Vietų sąrašas išvedamas\n",
    "    # Dirbant su daug įrašų sąrašo išvedimą reikia užblokuoti !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # classification = []  # Užblokuota\n",
    "    if (classification):\n",
    "        tot = 0\n",
    "        tot_U = 0\n",
    "        for row in classification:\n",
    "            print(f\"sample: {row['sample']:>7}   annot_label: {row['annot']:>2}   pred_label: {row['pred']:>2}\")\n",
    "            if (row['pred'] != 'U'):\n",
    "                tot += 1\n",
    "            else:\n",
    "                tot_U +=1     \n",
    "\n",
    "    print(f\"rpeaks total: {len(atr_sample)}\")\n",
    "    print(f\"excluded rpeaks ('U'): {tot_U}\")\n",
    "    print(f\"classified rpeaks: {len(atr_sample) - tot_U}\")\n",
    "    print(f\"automaticRpeakAnnotations: {tot}\")\n",
    "\n",
    "    # SUFORMUOJAME FREIMĄ validation_set_stats SU PŪPSNIŲ KLASIŲ ANOTUOTAIS IR AUTOMATIŠKAI \n",
    "    # SURASTAIS KLASIŲ NUMERIAIS, IŠMETANT KLASES SU NUMERIU = 3\n",
    "\n",
    "    # Surandame pradinį SubjCode įrašo indeksą faile all_beats_attr\n",
    "    selected_ind = all_beat_indices[(all_beats_attr['userNr']==userNr) & (all_beats_attr['recordingNr']==recNr)]\n",
    "    # print(f\"SubjCode: {SubjCode}  first elem: {selected_ind[0]} last elem: {selected_ind[-1]}  tot: {len(selected_ind)}\")\n",
    "    index_start = selected_ind[0]\n",
    "    # print('\\nSubjCode:',SubjCode, 'index_start:', index_start)   \n",
    "\n",
    "    #  Praleisdami indeksą, jei masyvuose test_labels ir pred_labels yra reikšmė == 3,\n",
    "    # suformuojame klasifikuotinų pūpsnių indeksų sąrašą\n",
    "    for idx in range(len(atr_sample)):\n",
    "        flag = (test_labels[idx] == 3) or (pred_labels[idx] == 3)\n",
    "        if (flag == False):\n",
    "            validation_stats = pd.DataFrame([{'idx':index_start+idx,'test_label':test_labels[idx],\n",
    "                                                'pred_label':pred_labels[idx], 'SubjCode': SubjCode}])\n",
    "            validation_set_stats = pd.concat([validation_set_stats, validation_stats])\n",
    "\n",
    "    # Suformuojame klasių numerių msyvus confusion matricai skaičiuoti, surandama confusion matrica\n",
    "    test_y = np.array(validation_set_stats[validation_set_stats['SubjCode']==SubjCode]['test_label']).astype('int') \n",
    "    # print(all_beats_attr.info())\n",
    "    pred_y = np.array(validation_set_stats[validation_set_stats['SubjCode']==SubjCode]['pred_label']).astype('int')\n",
    "   \n",
    "    # Atsikračius pūpsnių su klase = 3 ir suformavus masyvus, pred_y turi būti tokio pat ilgio, kaip ir test_y\n",
    "    if (len(test_y) != len(pred_y)):\n",
    "        raise Exception(f\"Klaida! SubjCode: {SubjCode}. Nesutampa test_y ir pred_y ilgiai\")     \n",
    "\n",
    "    # Skaičiuojame ir išvedame klasifikavimo lentelę\n",
    "    confusion = confusion_matrix(test_y, pred_y)\n",
    "    # print(confusion)\n",
    "    pd.set_option('display.precision',3)\n",
    "    show_confusion_matrix(confusion, class_names)\n",
    "\n",
    "# print('\\n')\n",
    "    prec,rec,fsc,sup = precision_recall_fscore_support(test_y, pred_y, labels=[0, 1, 2], zero_division=0)\n",
    "\n",
    "    str1 =f\"N:{int(sup[0]):>5} S:{(int(sup[1])):3} V:{int(sup[2]):3}\" \n",
    "    str2 = f\"  Nprec:{prec[0]:>5.2f} Nrec:{rec[0]:5.2f} Nfsc:{fsc[0]:5.2f}\"\n",
    "    str3 = f\"  Sprec:{prec[1]:>5.2f} Srec:{rec[1]:5.2f} Sfsc:{fsc[1]:5.2f}\"\n",
    "    str4 = f\"  Vprec:{prec[2]:>5.2f} Vrec:{rec[2]:5.2f} Vfsc:{fsc[2]:5.2f}\"\n",
    "    print(str1+str2+str3+str4)\n",
    "\n",
    "    classification = classify_cnn_fda_vu_v1(signal, atr_sample, model_dir, prediction_labels = ['N', 'S', 'V', 'U'])\n",
    "    # print(classification)\n",
    "    # df_classification = pd.DataFrame(classification)\n",
    "    # print(df_classification.value_counts())\n",
    "\n",
    "    # print(len(validation_set_stats))\n",
    "    # print(len(test_y))\n",
    "    # print(len(pred_y))\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\n')\n",
    "runtime(end_time-start_time)\n",
    "\n",
    "# Sukūriame anotuotų ir automatiškai priskirtų klasių visų įrašų pūpsniams sąrašus \n",
    "validate_ind_lst = list(validation_set_stats['idx'])\n",
    "y_validate = np.array(validation_set_stats['test_label']).astype('int')\n",
    "y_predicted = np.array(validation_set_stats['pred_label']).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Nesutvarkyta !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# Sukuriami užduoto ilgio sekų vaizdai ir įrašomi į disko atitinkamus klasėms subfolderius\n",
    "\n",
    "from zive_util_vu import get_rec_Id, split_seq_file_name, get_symbol_list, get_SubjCode, create_SubjCode\n",
    "from zive_util_vu import read_show_seq_ext_zive, read_seq, get_seq_start_end, read_rec_attrib\n",
    "\n",
    "\n",
    "def read_show_seq_ext_zive_npy(rec_dir, all_beats_attr, idx, win_ls, win_rs, win_ls_ext, win_rs_ext):\n",
    "# Išpjauna užduoto ilgio seką iš mit2zive įrašo ir sukuria jos vaizdą su anotacijomis\n",
    "\n",
    "# rec_dir - paciento EKG įrašų aplankas\n",
    "# recordingId - paciento EKG įrašo Id - int\n",
    "# i_sample - R dantelio, kurio atžvilgiu formuojama seka, indeksas viso EKG įrašo reikšmių masyve - int\n",
    "# win_ls - klasifikuojamo EKG segmento plotis iki R pūpsnio (iš kairės) \n",
    "# win_rs - klasifikuojamo EKG segmento plotis nuo R pūpsnio (iš dešinės)\n",
    "# win_ls_ext - vaizduojamo EKG segmento plotis iki R pūpsnio (iš kairės) \n",
    "# win_rs_ext - vaizduojamo EKG segmento plotis už R pūpsnio (iš dešinės) \n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    sequence, sample, label = read_seq(rec_dir, all_beats_attr, idx, win_ls_ext, win_rs_ext)\n",
    "    if (sample == None):\n",
    "        print(\"klaida!\")\n",
    "        return None\n",
    "    \n",
    "    seq_start = sample - win_ls_ext\n",
    "    seq_end = sample + win_ls_ext\n",
    "\n",
    "    SubjCode = get_SubjCode(idx, all_beats_attr)\n",
    "\n",
    "    # Nuskaitome paciento anotacijas ir jų indeksus\n",
    "    atr_sample, atr_symbol = read_rec_attrib(rec_dir, SubjCode)\n",
    "\n",
    "    # # suformuojame anotacijų žymes\n",
    "    beat_symbols,beat_locs = get_symbol_list(atr_symbol,atr_sample, seq_start, seq_end)\n",
    "\n",
    "    # deltax ir deltay simbolių pozicijų koregavimui\n",
    "    min = np.amin(sequence)\n",
    "    max = np.amax(sequence)\n",
    "    deltay = (max - min)/20\n",
    "    deltax = len(sequence)/100\n",
    "\n",
    "    # suformuojame vaizdą\n",
    "    x = np.arange(0, len(sequence), 1)\n",
    "    ax.plot(x, sequence, color=\"#6c3376\", linewidth=2)\n",
    "    left_mark = win_ls_ext - win_ls\n",
    "    right_mark = win_ls_ext + win_rs\n",
    "    ax.axvline(x = left_mark, color = 'b', linestyle = 'dotted')\n",
    "    ax.axvline(x = right_mark, color = 'b', linestyle = 'dotted')\n",
    "    for i in range(len(beat_locs)):\n",
    "        ax.annotate(beat_symbols[i],(beat_locs[i]-deltax,sequence[beat_locs[i]]+deltay))\n",
    "    ax.set_ylim([min, max+2*deltay])\n",
    "    \n",
    "    return(ax)\n",
    "\n",
    "def get_seq_attributes(all_beats_attr, idx):\n",
    "    # 'userNr', 'recordingNr', 'sample', 'symbol', 'label', 'RRl', 'RRr'\n",
    "    row = all_beats_attr.loc[idx]\n",
    "    return list(row) \n",
    "\n",
    "# ////////////////////// Užduodami parametrai /////////////////////\n",
    "\n",
    "# Bendras aplankas vaizdams\n",
    "images_folder = 'CNN'\n",
    "\n",
    "# užduodame, kiek reikšmių vaizduosime prieš R dantelį ir po\n",
    "wl_side_ext = 360\n",
    "wr_side_ext = 360\n",
    "\n",
    "# Užduodame, kiek sekų vaizdų iš kiekvienos klasės įrašysime į diską\n",
    "img_max = 10\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////\n",
    "\n",
    "print(\"\\nBendras aplankas vaizdams:\", images_folder)\n",
    "print(\"\\nMax sekų vaizdų skaičius iš kiekvienos klasės:\", img_max)\n",
    "\n",
    "if (img_max == 0):\n",
    "    sys.exit()\n",
    "\n",
    "# sukuriame bendrą aplanką vaizdams\n",
    "images_dir = Path(sets_path, 'saved_images', images_folder)\n",
    "create_dir(images_dir)\n",
    "\n",
    "# klasių simbolinių vardų sąrašas\n",
    "class_names = selected_beats.keys()\n",
    "\n",
    "# sukuriame aplankus sekų vaizdams klasėse\n",
    "create_subdir(images_dir, class_names)\n",
    "\n",
    "# Sukuriame vaizdų klasėse skaitiklį\n",
    "n_classes = len(class_names)\n",
    "skait = np.zeros((n_classes, n_classes), dtype=int)\n",
    "# print(skait)\n",
    "\n",
    "# sukuriame selected_beats reversiją\n",
    "rev_dict = get_rev_dictionary(selected_beats)\n",
    "\n",
    "y_test = df_seq_errors['labels'].to_numpy(dtype=int)\n",
    "y_pred = df_seq_errors['preds'].to_numpy(dtype=int)\n",
    "\n",
    "\n",
    "# *********************** derinimui *******************************\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# print(f\"\\nAccuracy: {acc:.2f}\\n\")\n",
    "# cnf_matrix = confusion_matrix_modified(y_test, y_pred, n_classes)\n",
    "# show_confusion_matrix(cnf_matrix, class_names)\n",
    "# ******************************************************************\n",
    "\n",
    "# Ciklas per sekas\n",
    "\n",
    "icycle = 0 \n",
    "leng = len(y_pred)\n",
    "\n",
    "for idx in validate_ind_lst:\n",
    "    if (icycle >= leng):\n",
    "        continue\n",
    "\n",
    "# *********************** derinimui ******************************   \n",
    "    # row = get_seq_attributes(all_beats_attr, idx)\n",
    "    # print(idx, row)\n",
    "# ****************************************************************\n",
    "\n",
    "    # anotuotos klasės (klasių nr ir simboliniai pažymėjimai)\n",
    "    label = y_test[icycle]\n",
    "    label_symb = rev_dict[label]\n",
    "\n",
    "    # print(f\" {idx} label {label} symb {label_symb}\")\n",
    "\n",
    "    # klasifikatoriaus priskirtos klasės (klasių nr ir simboliniai pažymėjimai)\n",
    "    pred = y_pred[icycle]\n",
    "    pred_symb = rev_dict[pred]\n",
    "    icycle +=1\n",
    "\n",
    "    # print(f\" {idx} pred {pred} symb {pred_symb}\")\n",
    "\n",
    "    # patikriname, ar neviršytas skaitiklis, jei viršytas, peršokame\n",
    "    if (skait[label,pred] >= img_max):\n",
    "        continue\n",
    "    else:\n",
    "        skait[label,pred] += 1\n",
    "\n",
    "    SubjCode = get_SubjCode(idx, all_beats_attr)\n",
    "    seq_name = str(SubjCode) + '_' + str(idx)\n",
    "    \n",
    "     # 'Išpjauname' užduoto ilgio sekas ir sukuriame jų vaizdus\n",
    "    fig = plt.figure(facecolor=(1, 1, 1), figsize=(18,3))\n",
    "    # print(\"rec_dir =\", rec_dir)\n",
    "    ax = read_show_seq_ext_zive_npy(rec_dir, all_beats_attr, idx, wl_side, wr_side, wl_side_ext, wr_side_ext) \n",
    "    if (ax == None):\n",
    "        print(f'Sekai {idx} negali suformuoti išplėstinio vaizdo')\n",
    "        plt.close()\n",
    "        continue\n",
    "\n",
    "    # suformuosime koreguotą failo vardą\n",
    "    file_name = seq_name + '_' + pred_symb + \".png\" \n",
    "\n",
    "    # suformuosime kelią į atitinkamą sub-aplanką\n",
    "    image_subdir = Path(images_dir, label_symb)\n",
    "    if (os.path.exists(image_subdir) == False):\n",
    "        print('Klaida! ', image_subdir,' neegzistuoja')\n",
    "    file_path = Path(image_subdir, file_name)\n",
    "    # print('file_name: ',file_name, 'file_path: ', file_path)   \n",
    "\n",
    "    # Įrašome į atitinkamą anotacijai sub-aplanką \n",
    "    ax.set_title(file_name)\n",
    "    plt.savefig(file_path, bbox_inches='tight', pad_inches = 0.2)\n",
    "    plt.close()\n",
    "\n",
    "    # if (icycle >= len(y_pred)):\n",
    "        # break\n",
    "\n",
    "# ciklo per validate_ind_lst pabaiga\n",
    "\n",
    "print(\"\\n\")\n",
    "df = cm2df(skait, class_names)\n",
    "print(df)\n",
    "\n",
    "print(\"\\nPabaiga.........\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ecg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f36dab35816871602f0a4fffa6415a4e758bca001397bb3d9f7e90aab6637a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
