{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS in my system :  linux\n",
      "tf version: 2.6.0\n",
      "sklearn version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "# Variantas, kai suformuojamas json masyvas su rpeaks, ML anotacijomis ir klasteriais.\n",
    "# // Klasteriai\n",
    "# [\n",
    "#   {\n",
    "#     annotationValue: 'N',\n",
    "#     clusterNumber: 0,\n",
    "#     rpeakLocations: [ 120, 240, 360 ]\n",
    "#   },\n",
    "#   {\n",
    "#     annotationValue: 'N',\n",
    "#     clusterNumber: 1,\n",
    "#     rpeakLocations: [ 453, 578, 667 ]\n",
    "#   },\n",
    "#   {\n",
    "#     annotationValue: 'V',\n",
    "#     clusterNumber: 0,\n",
    "#     rpeakLocations: [ 6554, 7554, 65542 ]\n",
    "#   },\n",
    "# ]\n",
    "\n",
    "\n",
    "# Bandymai rodyti užklojant po kelis pūpsnius. V2: duomenys imame iš originalios saugyklos,\n",
    "# užduodant įrašo filename\n",
    "# Klasterizuojami ir vaizduojami ML anotuoti pūpsniai atskirai kiekvienoje iš grupių\n",
    "# su ML anotacijomis N, S, V.\n",
    "# \n",
    "# Klasterizacija atliekama esant pakankamam N, S ar V grupės dydžiui. U grupė neklasterizuojama.\n",
    "#  \n",
    "# Skriptas EKG įrašo pūpsnių klasterizacijai panaudojant VU FDA požymius\n",
    "# Šis variantas pritaikytas įrašams, kuriems rpeaks surandami su Neurokitu,\n",
    "# o anotacijos yra gautos su ML.anotuotams įrašams. Yra ir kitas variantas\n",
    "# (zive_clustering_of_annotated_records.ipynb), pritaikytas darbui su rpeaks\n",
    "# ir anotacijomis, atsisiųtomis iš duomneų bazės.   \n",
    "\n",
    "# Planas:\n",
    "# Nuskaitome EKG įrašą\n",
    "# Surandame su Neurokit2 R pikus\n",
    "# Apskaičiuojame visiems pūpsniams požymius ir suformuojame požymių masyvą\n",
    "# Surandame visiems R pikams ML anotacijas\n",
    "# Atliekame klasterizaciją\n",
    "# Atvaizduojame klasterius grafiškai\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys, os, json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sklearn\n",
    "import neurokit2 as nk\n",
    "from zive_clustering import get_sequences_min_max, show_beats, show_beats_in_same_plot\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Į sys.path įtraukiamas aukščiau esantis aplankas, reikalingas modulių importavimui\n",
    "# https://www.geeksforgeeks.org/get-parent-of-current-directory-using-python/ panaudojau šitą\n",
    "path = os.getcwd() # Current Directory\n",
    "parent = os.path.dirname(path) # parent directory\n",
    "sys.path.insert(1, parent)\n",
    "\n",
    "from zive_util_vu import runtime\n",
    "from zive_util_vu import create_dir, get_rec_file_name, get_recId\n",
    "from zive_util_vu import get_seq_start_end, read_rec, read_rec_attrib, split_SubjCode\n",
    "from zive_cnn_fda_vu_v3_micro import read_RR_arr_from_signal, read_seq_from_signal\n",
    "from zive_cnn_fda_vu_v3_micro import get_beat_features_set_fda_vu_v1_micro\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "\n",
    "print('tf version:', tf.__version__)\n",
    "print('sklearn version:', sklearn.__version__)\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option(\"display.max_rows\", 6000)\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Naudojamų požymių sąrašas \n",
    "all_features = ['seq_size','RR_l_0', 'RR_r_0', 'RR_r/RR_l','wl_side','wr_side',\n",
    "                'signal_mean', 'signal_std', 'P_val', 'Q_val', 'R_val', 'S_val', 'T_val',\n",
    "                'P_pos', 'Q_pos', 'R_pos', 'S_pos', 'T_pos', 'QRS', 'PR', 'ST', 'QT', '0', '1', '2',\n",
    "                '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
    "                '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32',\n",
    "                '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
    "                '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
    "                '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74',\n",
    "                '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88',\n",
    "                '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
    "                '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114',\n",
    "                '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126',\n",
    "                '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
    "                '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150',\n",
    "                '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162',\n",
    "                '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
    "                '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186',\n",
    "                '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198',\n",
    "                '199']\n",
    "\n",
    "\n",
    "def clustering(df_attr_features_ml_group_X, features, scaler, n_clusters):\n",
    "    \n",
    "    if (n_clusters > 1):\n",
    "        # Paliekame tik užduotus požymius ir normalizuojame\n",
    "        df_tmp = df_attr_features_ml_group_X[features]\n",
    "        # print(data_frame_init.head())\n",
    "        # Duomenis normalizuojame\n",
    "        X = scaler.transform(df_tmp)\n",
    "\n",
    "        # define the model\n",
    "        model = KMeans(n_clusters, random_state=0)\n",
    "\n",
    "        # fit the model\n",
    "        model.fit(X)\n",
    "\n",
    "        # assign a cluster to each example\n",
    "        yhat = model.predict(X)\n",
    "        # print(type(yhat), yhat.shape)\n",
    "\n",
    "        # retrieve unique clusters\n",
    "        clusters = np.unique(yhat)\n",
    "        # print(clusters)\n",
    "    else:\n",
    "        yhat = np.zeros(len(df_attr_features_ml_group_X), int)\n",
    "\n",
    "    # Paliekame masyvus tik su atributais, be požymių, požymių stulpelius panaikiname\n",
    "    df_attr_ml_group_X = df_attr_features_ml_group_X.drop(features, axis=1, inplace=False)\n",
    "\n",
    "    # Papildome atributus klasterių numeriais \n",
    "    df_attr_ml_group_X['cluster'] = list(yhat)\n",
    "    return df_attr_ml_group_X\n",
    "\n",
    "\n",
    "def get_clusters_n(len_group):\n",
    "    \"\"\"\n",
    "    Nustato, į kiek klasterių dalinti pūpsnių grupę, priklausomai \n",
    "    nuo grupės dydžio len_group\n",
    "    len_group: int, grupės dydis\n",
    "    \"\"\"\n",
    "    clusters_n = 0\n",
    "    if (len_group >= 500):\n",
    "        clusters_n = 10\n",
    "    elif len_group >= 100 and len_group <500:\n",
    "        clusters_n = 5\n",
    "    elif len_group >= 10 and len_group <100:\n",
    "        clusters_n = 3\n",
    "    return clusters_n\n",
    "\n",
    "def get_rpeaks_of_clusters(df_attr_ml_group_N):\n",
    "    # for col in df_attr_ml_group_N.columns:\n",
    "        #     print(col)\n",
    "    # for index, row in df_attr_ml_group_N.iterrows():\n",
    "    #     if (row[\"idx\"] < 10):\n",
    "    #         row_string = f'idx: {row[\"idx\"]} atr_sample: {row[\"atr_sample\"]} atr_symbol: {row[\"atr_symbol\"]} cluster: {row[\"cluster\"]}'\n",
    "    #         print (row_string)\n",
    "\n",
    "    list_dict_clusters = []\n",
    "    group_by_cluster = df_attr_ml_group_N.groupby(['cluster'])\n",
    "    for cluster_number, frame in group_by_cluster:\n",
    "        # print(frame.head(5), end=\"\\n\\n\")\n",
    "        lst_rpeaks = frame[\"atr_sample\"].values.tolist()\n",
    "        # print(lst_rpeaks)\n",
    "        dict_cluster = {\n",
    "                # \"annotationValue\": annotationValue,\n",
    "                \"clusterNumber\": cluster_number,\n",
    "                \"rpeakLocations\": lst_rpeaks\n",
    "            }\n",
    "        list_dict_clusters.append(dict_cluster)\n",
    "    return list_dict_clusters       \n",
    "\n",
    "\n",
    "def show_beats_in_group(signal, df_attr_ml_group_X, group_symbol, w_side, min, max, fig_width, fig_height, max_graphs, print_rpeaks):\n",
    "        \n",
    "        # Sugrupuojame atributus pagal klasterius,\n",
    "        # surandame klasterių indeksus mažėjančia klasterių dydžio tvarka \n",
    "    gr = df_attr_ml_group_X.groupby(['cluster'])\n",
    "    sr_sizes = gr.size()\n",
    "    sr_sizes = sr_sizes.sort_values(ascending=False)\n",
    "    df_sizes = sr_sizes.to_frame(name='sizes').reset_index()\n",
    "\n",
    "    # čia įdedame spausdinimo ciklą per klasterius, išvesdami klasterių statistiką\n",
    "    print(\"\\nML anotacija\", group_symbol, \":\" )\n",
    "    for item, row in df_sizes.iterrows():\n",
    "        cluster = row['cluster']\n",
    "        df_gr = gr.get_group(cluster)\n",
    "        atr_symbol_clust = np.array(list(df_gr['atr_symbol']))\n",
    "        (unique, counts) = np.unique(atr_symbol_clust, return_counts=True)\n",
    "        total = counts.sum()\n",
    "        print(f'item: {item:>6}   cluster: {cluster:>6}   statistika: {unique} {counts} {total}')\n",
    "\n",
    "        # Jei print_rpeaks == True, tai S, V ir U atvejais išvedame anotacijų rpeaks\n",
    "        if (print_rpeaks and ((group_symbol == \"S\" or group_symbol == \"V\" or group_symbol == \"U\"))):\n",
    "            # print(df_gr.head(6))\n",
    "            dict_X = dict(zip(df_gr['idx'], df_gr['atr_sample']))\n",
    "            print(group_symbol,': (idx, rpeak)', dict_X)\n",
    "\n",
    "    # Ciklas per užduotus klasterius\n",
    "    clusters_sorted = sr_sizes.index\n",
    "    n_clusters = gr.ngroups\n",
    "\n",
    "    # Ciklas per klasterius\n",
    "    for item in range(n_clusters):\n",
    "        cluster = clusters_sorted[item]\n",
    "        df_gr = gr.get_group(cluster)\n",
    "        print('\\nitem:', item, 'cluster:', cluster, 'size:', len(df_gr))\n",
    "\n",
    "        #  Statistika apie pūpsnius klasteryje\n",
    "        atr_symbol_clust = np.array(list(df_gr['atr_symbol']))\n",
    "        (unique, counts) = np.unique(atr_symbol_clust, return_counts=True)\n",
    "        total = counts.sum()\n",
    "        print(\"statistika klasteryje: \", unique, counts, total)\n",
    "\n",
    "        if (len(df_gr) == 1):\n",
    "            dict_attr = {'seq_nr':0, 'rpeak':df_gr['atr_sample'].values[0], 'symbol':df_gr['atr_symbol'].values[0]}\n",
    "            print(dict_attr)        \n",
    "\n",
    "        # Grafika\n",
    "        # mark1\n",
    "        min, max = get_sequences_min_max(signal, df_gr, w_side)\n",
    "        show_beats_in_same_plot(signal, df_gr, w_side, min, max, fig_width, fig_height)\n",
    "# mark2\n",
    "        show_N_beats_in_same_plot(signal, df_gr, w_side, min, max, fig_width, fig_height)\n",
    "        \n",
    "        if ((max_graphs != 0) and (len(df_gr) != 1)):\n",
    "            show_beats(signal, df_gr, w_side, min, max, fig_width, fig_height, max_graphs= max_graphs)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def show_N_beats_in_same_plot(signal, df_gr, w_side,  min, max, fig_width, fig_height):\n",
    "# Atvaizduojami klasterio pūpsniai klojant vienas ant kito\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ------------\n",
    "        signal: numpy array, float\n",
    "        df_gr: dataframe after grouping by 'cluster'\n",
    "        w_side: window width from rpeak to one side\n",
    "        min: float\n",
    "        max: float\n",
    "        fig_width: int\n",
    "        fig_height: int\n",
    "    \"\"\"\n",
    "    deltay = (max - min)/20\n",
    "\n",
    "    # print(df_gr.head())\n",
    "\n",
    "    #  Suvidurkiname sekas\n",
    "    seq_nr = 0\n",
    "    avg_sequence = np.zeros((w_side*2))\n",
    "    for index, row in df_gr.iterrows():\n",
    "        # Formuojami grafiniai vaizdai\n",
    "        seq_start = row['atr_sample'] - w_side\n",
    "        if (seq_start < 0):\n",
    "            continue\n",
    "        seq_end = row['atr_sample'] + w_side\n",
    "        if (seq_end >= len(signal)):\n",
    "            continue\n",
    "        # beat_rpeak = row['atr_sample']\n",
    "        # beat_symbol = row['atr_symbol']\n",
    "        sequence = signal[seq_start:seq_end]\n",
    "        avg_sequence = np.add(avg_sequence, sequence)\n",
    "        seq_nr += 1\n",
    "    avg_sequence = avg_sequence/seq_nr    \n",
    "\n",
    "\n",
    "# Formuojamas grafinis vaizdas\n",
    "    fig = plt.figure(facecolor=(1, 1, 1), figsize=(fig_width, fig_height))\n",
    "    ax = plt.gca()\n",
    "    # suformuojame vaizdą\n",
    "    x = np.arange(0, len(avg_sequence), 1)\n",
    "    ax.plot(x, sequence, color=\"#6c3376\", linewidth=2)\n",
    "    ax.set_ylim([min, max+2*deltay])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skriptas bandymams klasterizuoti EKG įrašo pūpsnius su ML anotacijomis kiekvienai anotacijai atskirai\n",
      "Naudojami VU FDA požymiai, scaler ir modelio parametrai nuskaitomi iš modelio CNN VU aplanko\n",
      "\n",
      "Bendras duomenų aplankas:  /home/kesju/DI\n",
      "Zive duomenų aplankas:  DUOM_2022_RUDUO_2\n",
      "Aplankas su EKG įrašais (.npy) ir anotacijomis (.json)  /home/kesju/DI/DUOM_2022_RUDUO_2/records_npy\n",
      "Diskretizavimo dažnis:  200\n",
      "Klasifikavimo schema: {'N': 0, 'S': 1, 'V': 2}\n",
      "Klasių skaičius: 3\n",
      "Visos galimos anotacijos: ['N', 'S', 'V', 'U']\n",
      "Scaler ir modelio parametrai nuskaitomi iš aplanko:  model_cnn_fda_vu_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 13:15:01.659247: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-21 13:15:01.664667: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasterizuojamas įrašas: 10792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 13:15:11.823207: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atmetus 1 ir paskutini: 581\n",
      "atmetus 1 ir paskutini: [  477   722   964  1212  1303  1457  1696  1938  2178  2413  2650  2891\n",
      "  3131  3368  3607  3847  4087  4325  4563  4800  5032  5260  5487  5715\n",
      "  5950  6193  6438  6678  6922  7167  7407  7645  7888  8132  8367  8603\n",
      "  8835  9062  9284  9515  9748  9980 10218 10459 10699 10936 11181 11425\n",
      " 11668 11907]\n",
      "idxs_su_U: [1, 268, 270, 302, 320, 321, 346, 434, 436, 474, 530]\n",
      "atmetus su 'U': 570\n",
      "atr_sample_be_U: [  477   964  1212  1303  1457  1696  1938  2178  2413  2650  2891  3131\n",
      "  3368  3607  3847  4087  4325  4563  4800  5032  5260  5487  5715  5950\n",
      "  6193  6438  6678  6922  7167  7407  7645  7888  8132  8367  8603  8835\n",
      "  9062  9284  9515  9748  9980 10218 10459 10699 10936 11181 11425 11668\n",
      " 11907 12139]\n",
      "atr_symbol_be_U: ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      "class labels:  ['N' 'S'] [523  47] 570\n",
      "\n",
      "SubjCode: 10792 userNr: 1079\n",
      "file_name: 1642627.41 userId: 61f1676d632a33abc40c7a21 recId: 61f169b8632a33c19e0c7b61 signal_length: 127999\n",
      "\n",
      "Bendra N, S ir V statistika įraše:\n",
      "statistika: ['N' 'S'] [523  47] 570\n",
      "U skaičius: 11\n",
      "\n",
      "Informacija apie klasterius:\n",
      "\n",
      "Klasteriai su 'N' anotacija:\n",
      "[{'clusterNumber': 0, 'rpeakLocations': [3131, 3368, 3607, 3847, 4087, 4325, 4563, 4800, 5032, 5260, 5487, 5715, 5950, 6193, 6438, 6678, 6922, 7167, 7407, 9284, 9515, 9748, 9980, 10218, 10459, 10699, 10936, 12139, 12373, 13086, 13321, 13547, 13768, 13994, 17305, 17542, 17774, 18004, 18240, 18945, 19185, 20620, 20861, 21101, 21578, 22264, 22494, 22727, 22965, 23203, 23444, 24399, 24637, 25337, 25572, 25806, 26037, 26276, 26520, 27943, 30042, 30274, 30507, 31462, 41752, 45032, 45277, 46462, 47635, 47876, 48111, 48351, 49501, 49726, 49951, 50184, 50419, 50652, 50897, 55150, 57728, 57971, 58213, 59642, 59872, 60104, 60339, 60569, 62437, 63374, 64072, 64308, 66407, 67342, 67576, 68267, 68509, 71363, 73217, 73910, 75810, 76045, 76276, 76514, 79331, 79562, 79797, 80039, 80281, 81470, 81711, 81956, 83387, 84096, 84329, 84561, 84796, 85036, 86444, 86677, 87381, 87624, 87867, 88107, 88354, 88600, 88841, 89082, 89786, 90022, 90255, 90484, 90723, 92105, 92334, 92571, 92810, 93048, 93784, 95191, 95424, 98751, 98992, 99238, 99480, 99721, 102792, 103030, 103398, 103976, 104216, 104920, 105158, 105393, 105633, 105876, 106113, 106352, 108030, 108273, 108758, 109004, 109243, 109487, 110904, 111141, 112281, 112511, 112748, 114187, 114899, 115132, 116530, 116759, 117230, 117465, 117707, 118896, 119132, 119368, 119824, 120054, 121011, 122435, 122675, 123607, 124071, 124303, 125021, 125259, 126189, 126425, 126659, 126896, 127134, 127367]}, {'clusterNumber': 1, 'rpeakLocations': [477]}, {'clusterNumber': 2, 'rpeakLocations': [1303, 1457, 1696]}, {'clusterNumber': 3, 'rpeakLocations': [15167, 18478, 23689, 24873, 26765, 28406, 31703, 32642, 33344, 34281, 36174, 38048, 38751, 40340, 41280, 41991, 45519, 48594, 51141, 55638, 57253, 58707, 61730, 61964, 62677, 63605, 65251, 67803, 69474, 71600, 73444, 74869, 76995, 77703, 80519, 82199, 83624, 85276, 85979, 89327, 90962, 94266, 95901, 99964, 101602, 103273, 104452, 107544, 109732, 111378, 112990, 115611, 118190, 120532, 121256, 122916]}, {'clusterNumber': 4, 'rpeakLocations': [27234, 32173, 36637, 45991, 49058, 56107, 58826, 65714, 72067, 77464, 80992, 85741, 94386, 96363, 110200, 113466, 116068, 121724]}, {'clusterNumber': 5, 'rpeakLocations': [7645, 7888, 8132, 8367, 8603, 8835, 9062, 11181, 11425, 11668, 11907, 12612, 12850, 14224, 14455, 14688, 14929, 15644, 15884, 16118, 16354, 16593, 16831, 17069, 19423, 19660, 19901, 20143, 20383, 21341, 21812, 22040, 27710, 28177, 28865, 29099, 29334, 29569, 29809, 30742, 30980, 31219, 33107, 33806, 34043, 34750, 34986, 35220, 35452, 35693, 35934, 37108, 37339, 37576, 37813, 38513, 39430, 39649, 39867, 40099, 40804, 41043, 42449, 42683, 42912, 43137, 43371, 43606, 43840, 44085, 44324, 44556, 44790, 46697, 46932, 47164, 47397, 51609, 51847, 52084, 52315, 52547, 52788, 53024, 53257, 53489, 53730, 53967, 54199, 54436, 54675, 54909, 55397, 56561, 56788, 57020, 58461, 60801, 61037, 61266, 61496, 63140, 64541, 64774, 65011, 66179, 66644, 66880, 67112, 68752, 68992, 69229, 70185, 70423, 70658, 70889, 71123, 72537, 72766, 72993, 74152, 74389, 74625, 74988, 75576, 76755, 78173, 78411, 78643, 78870, 79100, 82669, 82910, 83151, 86910, 87142, 91414, 91643, 91875, 93299, 93542, 94028, 95662, 96838, 97074, 97314, 97558, 97798, 98034, 98269, 98511, 100430, 100664, 100899, 101130, 101364, 102074, 102315, 102554, 106585, 106818, 107058, 107303, 108511, 110671, 111843, 112065, 113950, 114427, 114664, 115371, 116995, 117949, 118659, 119598, 120292, 122201, 123372, 123842, 124543, 124784, 125496, 125728, 125957, 127603]}, {'clusterNumber': 6, 'rpeakLocations': [27319, 32257, 36721, 46076, 96449, 110286, 113551, 121810]}, {'clusterNumber': 7, 'rpeakLocations': [1938, 2178, 2413, 2650, 2891]}, {'clusterNumber': 8, 'rpeakLocations': [964, 1212]}, {'clusterNumber': 9, 'rpeakLocations': [15403, 18712, 23812, 23995, 24160, 25105, 27475, 28633, 32411, 32872, 33575, 34514, 36876, 38278, 38882, 39047, 39207, 41512, 46230, 49283, 56337, 57487, 59260, 62198, 62801, 63836, 65799, 68031, 69593, 71725, 72303, 73675, 77115, 77822, 77935, 81234, 83860, 85827, 86211, 94809, 96602, 104579, 110439, 111515, 113711, 116153, 120769, 121964, 123038]}]\n",
      "\n",
      "Klasteriai su 'S' anotacija:\n",
      "[{'clusterNumber': 0, 'rpeakLocations': [26883, 31833, 36298, 40464, 42116, 45641, 48724, 51261, 55764, 65372, 80645, 82318, 85396, 89446, 91082, 96020, 100083, 101726, 107681, 109852, 113109, 115734, 118310, 121375]}, {'clusterNumber': 1, 'rpeakLocations': [15256, 18567, 24964, 28494, 32729, 33436, 34368, 38139, 41368, 57344, 61821, 62052, 63695, 67892, 73532, 83714, 86069, 120623]}, {'clusterNumber': 2, 'rpeakLocations': [49142, 56191, 72153, 77549, 81076]}]\n",
      "\n",
      "Klasteris su 'U' anotacija:\n",
      "[{'clusterNumber': 0, 'rpeakLocations': [722, 59173, 59410, 65949, 69829, 69941, 75339, 94723, 94960, 103737, 116302]}]\n",
      "\n",
      "visi klaster rpeaks\n",
      "[{'atr_symbol': 'N', 'clusters': [{'clusterNumber': 0, 'rpeakLocations': [3131, 3368, 3607, 3847, 4087, 4325, 4563, 4800, 5032, 5260, 5487, 5715, 5950, 6193, 6438, 6678, 6922, 7167, 7407, 9284, 9515, 9748, 9980, 10218, 10459, 10699, 10936, 12139, 12373, 13086, 13321, 13547, 13768, 13994, 17305, 17542, 17774, 18004, 18240, 18945, 19185, 20620, 20861, 21101, 21578, 22264, 22494, 22727, 22965, 23203, 23444, 24399, 24637, 25337, 25572, 25806, 26037, 26276, 26520, 27943, 30042, 30274, 30507, 31462, 41752, 45032, 45277, 46462, 47635, 47876, 48111, 48351, 49501, 49726, 49951, 50184, 50419, 50652, 50897, 55150, 57728, 57971, 58213, 59642, 59872, 60104, 60339, 60569, 62437, 63374, 64072, 64308, 66407, 67342, 67576, 68267, 68509, 71363, 73217, 73910, 75810, 76045, 76276, 76514, 79331, 79562, 79797, 80039, 80281, 81470, 81711, 81956, 83387, 84096, 84329, 84561, 84796, 85036, 86444, 86677, 87381, 87624, 87867, 88107, 88354, 88600, 88841, 89082, 89786, 90022, 90255, 90484, 90723, 92105, 92334, 92571, 92810, 93048, 93784, 95191, 95424, 98751, 98992, 99238, 99480, 99721, 102792, 103030, 103398, 103976, 104216, 104920, 105158, 105393, 105633, 105876, 106113, 106352, 108030, 108273, 108758, 109004, 109243, 109487, 110904, 111141, 112281, 112511, 112748, 114187, 114899, 115132, 116530, 116759, 117230, 117465, 117707, 118896, 119132, 119368, 119824, 120054, 121011, 122435, 122675, 123607, 124071, 124303, 125021, 125259, 126189, 126425, 126659, 126896, 127134, 127367]}, {'clusterNumber': 1, 'rpeakLocations': [477]}, {'clusterNumber': 2, 'rpeakLocations': [1303, 1457, 1696]}, {'clusterNumber': 3, 'rpeakLocations': [15167, 18478, 23689, 24873, 26765, 28406, 31703, 32642, 33344, 34281, 36174, 38048, 38751, 40340, 41280, 41991, 45519, 48594, 51141, 55638, 57253, 58707, 61730, 61964, 62677, 63605, 65251, 67803, 69474, 71600, 73444, 74869, 76995, 77703, 80519, 82199, 83624, 85276, 85979, 89327, 90962, 94266, 95901, 99964, 101602, 103273, 104452, 107544, 109732, 111378, 112990, 115611, 118190, 120532, 121256, 122916]}, {'clusterNumber': 4, 'rpeakLocations': [27234, 32173, 36637, 45991, 49058, 56107, 58826, 65714, 72067, 77464, 80992, 85741, 94386, 96363, 110200, 113466, 116068, 121724]}, {'clusterNumber': 5, 'rpeakLocations': [7645, 7888, 8132, 8367, 8603, 8835, 9062, 11181, 11425, 11668, 11907, 12612, 12850, 14224, 14455, 14688, 14929, 15644, 15884, 16118, 16354, 16593, 16831, 17069, 19423, 19660, 19901, 20143, 20383, 21341, 21812, 22040, 27710, 28177, 28865, 29099, 29334, 29569, 29809, 30742, 30980, 31219, 33107, 33806, 34043, 34750, 34986, 35220, 35452, 35693, 35934, 37108, 37339, 37576, 37813, 38513, 39430, 39649, 39867, 40099, 40804, 41043, 42449, 42683, 42912, 43137, 43371, 43606, 43840, 44085, 44324, 44556, 44790, 46697, 46932, 47164, 47397, 51609, 51847, 52084, 52315, 52547, 52788, 53024, 53257, 53489, 53730, 53967, 54199, 54436, 54675, 54909, 55397, 56561, 56788, 57020, 58461, 60801, 61037, 61266, 61496, 63140, 64541, 64774, 65011, 66179, 66644, 66880, 67112, 68752, 68992, 69229, 70185, 70423, 70658, 70889, 71123, 72537, 72766, 72993, 74152, 74389, 74625, 74988, 75576, 76755, 78173, 78411, 78643, 78870, 79100, 82669, 82910, 83151, 86910, 87142, 91414, 91643, 91875, 93299, 93542, 94028, 95662, 96838, 97074, 97314, 97558, 97798, 98034, 98269, 98511, 100430, 100664, 100899, 101130, 101364, 102074, 102315, 102554, 106585, 106818, 107058, 107303, 108511, 110671, 111843, 112065, 113950, 114427, 114664, 115371, 116995, 117949, 118659, 119598, 120292, 122201, 123372, 123842, 124543, 124784, 125496, 125728, 125957, 127603]}, {'clusterNumber': 6, 'rpeakLocations': [27319, 32257, 36721, 46076, 96449, 110286, 113551, 121810]}, {'clusterNumber': 7, 'rpeakLocations': [1938, 2178, 2413, 2650, 2891]}, {'clusterNumber': 8, 'rpeakLocations': [964, 1212]}, {'clusterNumber': 9, 'rpeakLocations': [15403, 18712, 23812, 23995, 24160, 25105, 27475, 28633, 32411, 32872, 33575, 34514, 36876, 38278, 38882, 39047, 39207, 41512, 46230, 49283, 56337, 57487, 59260, 62198, 62801, 63836, 65799, 68031, 69593, 71725, 72303, 73675, 77115, 77822, 77935, 81234, 83860, 85827, 86211, 94809, 96602, 104579, 110439, 111515, 113711, 116153, 120769, 121964, 123038]}]}, {'atr_symbol': 'S', 'clusters': [{'clusterNumber': 0, 'rpeakLocations': [26883, 31833, 36298, 40464, 42116, 45641, 48724, 51261, 55764, 65372, 80645, 82318, 85396, 89446, 91082, 96020, 100083, 101726, 107681, 109852, 113109, 115734, 118310, 121375]}, {'clusterNumber': 1, 'rpeakLocations': [15256, 18567, 24964, 28494, 32729, 33436, 34368, 38139, 41368, 57344, 61821, 62052, 63695, 67892, 73532, 83714, 86069, 120623]}, {'clusterNumber': 2, 'rpeakLocations': [49142, 56191, 72153, 77549, 81076]}]}, {'atr_symbol': 'U', 'clusters': [{'clusterNumber': 0, 'rpeakLocations': [722, 59173, 59410, 65949, 69829, 69941, 75339, 94723, 94960, 103737, 116302]}]}]\n",
      "\n",
      "list_dict_clusters_full įrašytas į: visi_clusters_rpeaks.json\n",
      "Runtime: 00:00:27\n"
     ]
    }
   ],
   "source": [
    "# Pagrindinis skriptas\n",
    "\n",
    "print(\"Skriptas bandymams klasterizuoti EKG įrašo pūpsnius su ML anotacijomis kiekvienai anotacijai atskirai\")\n",
    "print('Naudojami VU FDA požymiai, scaler ir modelio parametrai nuskaitomi iš modelio CNN VU aplanko')\n",
    "\n",
    "\n",
    "# //////////////// NURODOMI DUOMENŲ PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\\\DI'   # variantas: Windows\n",
    "    # Duomenu_aplankas = 'F:\\DI\\Data\\MIT&ZIVE\\VU'   # variantas: Herkulis\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Vietinės talpyklos aplankas ir pūpsnių atributų failas\n",
    "db_folder = 'DUOM_2022_RUDUO_2'\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "selected_beats = {'N':0, 'S':1, 'V':2}\n",
    "all_beats =  {'N':0, 'S':1, 'V':2, 'U':3}  \n",
    "\n",
    "# Diskretizavimo dažnis:\n",
    "fs = 200\n",
    "\n",
    "#  Nuoroda į aplanką su duomenų rinkiniu\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su EKG įrašais (.npy) ir anotacijomis (.json)\n",
    "rec_dir = Path(db_path, 'records_npy')\n",
    "\n",
    "# Nuoroda į modelio aplanką\n",
    "# model_dir = Path(Duomenu_aplankas, 'DNN', 'best_models', 'all_ft')\n",
    "model_dir = 'model_cnn_fda_vu_v1'\n",
    "\n",
    "# Išvedame parametrus\n",
    "print(\"\\nBendras duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"Zive duomenų aplankas: \", db_folder)\n",
    "print(\"Aplankas su EKG įrašais (.npy) ir anotacijomis (.json) \", rec_dir)\n",
    "print(\"Diskretizavimo dažnis: \", fs)\n",
    "print('Klasifikavimo schema:', selected_beats)\n",
    "print('Klasių skaičius:', len(selected_beats))\n",
    "print('Visos galimos anotacijos:', list(all_beats.keys()))\n",
    "print(\"Scaler ir modelio parametrai nuskaitomi iš aplanko: \", model_dir)\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "# mark1\n",
    "\n",
    "# NURODOME PACIENTŲ SĄRAŠĄ. GALIMI ĮVAIRŪS VARIANTAI\n",
    "\n",
    "SubjCode = 10030 # quality = 0, labai stabilus įrašas, be triukšmų\n",
    "# Column1\tuserNr\trecordingNr\trecId\t                    file_name\tN\tS\tV\tU\tNml\tSml\tVml\tUml\tNprec\tNrec\tNfsc\tSprec\tSrec\tSfsc\tVprec\tVrec\tVfsc\tErr%\tnesutmp\tquality\t\n",
    "# 16\t    1003\t0\t        613f57ea3d08d45609cdcc86\t1630726.223\t603\t0\t1\t0\t602\t0\t0\t2\t1,00\t1,00\t1,00\t0,00\t0,00\t0,00\t0,00\t0,00\t0,00\t0,20\t0\t    0\t    labai stabilus įrašas, be triukšmų, 3 min.\n",
    "\n",
    "# SubjCode = 10130 # quality = 0, izolinija vaikšto nedaug, labai nedaug vietomis išlenda raumenų triušmai, 381 V, bet atpažino 326\n",
    "# 107\t    1013\t0\t        6144cd8bbd0cc52fe9275398\t1631080.771\t509\t0\t381\t0\t551\t8\t326\t5\t0,92\t0,99\t0,95\t0,00\t0,00\t0,00\t1,00\t0,86\t0,93\t6,10\t0\t    0\tizolinija vaikšto nedaug, labai nedaug vietomis išlenda raumenų triušmai, 381 V, bet atpažino 326, 8 min.\n",
    "\n",
    "# SubjCode = 101322 # quality = 1, Yra intervalų su paplaukiančia izolinija, taip pat yra intervalų su padidėjusiu raumenų triukšmu, bei kontaktinio triūkšmo. Daug V, nemažai akivaizdžių (apie 20%) neatpažinta\n",
    "# 129\t    1013\t22\t        6144cd8bbd0cc52ca32753a4\t1631032.393\t862\t0\t49\t0\t849\t6\t39\t17\t0,98\t0,99\t0,98\t0,00\t0,00\t0,00\t0,87\t0,69\t0,77\t2,90\t0\t1\tNaudota cluster testavimui.  Yra intervalų su paplaukiančia izolinija, taip pat yra intervalų su padidėjusiu raumenų triukšmu, bei kontaktinio triūkšmo. Daug V, nemažai akivaizdžių (apie 20%) neatpažinta\n",
    "\n",
    "# SubjCode = 10140 # quality = 2, Vietomis daug triukšmų, panašu į kontaktinius\n",
    "# 148\t1014\t0\t6145ae5ebd0cc5e15f2756e4\t1630947.302\t816\t0\t0\t0\t738\t0\t9\t69\t1,00\t0,99\t0,99\t0,00\t0,00\t0,00\t0,00\t0,00\t0,00\t1,20\t0\t2\tVietomis daug triukšmų, panašu į kontaktinius\n",
    "\n",
    "SubjCode = 101940 # quality = 0\n",
    "# 266\t1019\t40\t6145fd97bd0cc54b03275bba\t1631027.284\t691\t0\t51\t0\t690\t0\t47\t5\n",
    "\n",
    "\n",
    "SubjCode = 10792\n",
    "# ////////////////////////////  PARAMETRAI VAIZDAVIMUI  ////////////////////////////////////////////////////\n",
    "\n",
    "# Maksimalus grafikų skaičius, išvedant kiekvieną grafiką klasteryje atskirai \n",
    "max_graphs = 0\n",
    "\n",
    "# EKG pūpsnio reikšmių lango į vieną pusę plotis\n",
    "w_side = 80*5\n",
    "\n",
    "# Lango, kuriame vaizduojami grafikai, plotis ir aukštis\n",
    "fig_width, fig_height = 20, 6\n",
    "\n",
    "# Užduodame, ar rodyti klasterį su U\n",
    "U_flag = True  #  True - rodyti\n",
    "\n",
    "# Užduodame, ar išvesti S, V, U anotacijoms rpeaks\n",
    "print_rpeaks = False  # True - rodyti\n",
    "\n",
    "\n",
    "# //////////////// PASIRUOŠIMAS ////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Klasių simbolinių vardų sąrašas ir klasių skaičius\n",
    "class_names = list(selected_beats.keys()) \n",
    "n_classes = len(selected_beats)\n",
    "# print(class_names)\n",
    "\n",
    "# nuskaitome modelio parametrus\n",
    "model_path = Path(parent, model_dir, 'best_model_final_2.h5')\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    " # Nuskaitome scaler objectą\n",
    "path_scaler = Path(parent, model_dir, 'scaler.pkl')  \n",
    "scaler = pickle.load(open(path_scaler,'rb'))\n",
    "\n",
    "\n",
    "# //////////////// NUSKAITOMAS ĮRAŠAS /////////////////////////////////////////////////////\n",
    "\n",
    "print(\"Klasterizuojamas įrašas:\", SubjCode)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Nuskaitome EKG įrašą (npy formatu)\n",
    "file_path = Path(rec_dir, str(SubjCode) + '.npy')\n",
    "sign_raw = np.load(file_path)\n",
    "# sign_raw = read_rec(rec_dir, SubjCode)\n",
    "signal_length = sign_raw.shape[0]\n",
    "signal = sign_raw\n",
    "\n",
    "# Surandame ir išvedame įrašo atributus\n",
    "userNr, recNr = split_SubjCode(SubjCode)\n",
    "userId, recId, file_name = get_recId(rec_dir, userNr, recNr)\n",
    "# print(f\"\\nSubjCode: {SubjCode} userNr: {userNr:>2} file_name: {file_name:>2} userId: {userId} recId: {recId} signal_length: {signal_length}\")\n",
    "\n",
    "\n",
    "# //////// NUSTATOME rpeaak VIETAS, APSKAIČIUOJAME PŪPSNIŲ POŽYMIUS IR SURANDAME ML ANOTACIJAS //////////\n",
    "\n",
    "# Nustatome R pikų vietas\n",
    "_, rpeaks = nk.ecg_peaks(signal, sampling_rate=200, correct_artifacts=False)\n",
    "atr_sample = rpeaks['ECG_R_Peaks']\n",
    "# print(type(atr_sample))\n",
    "# print(\"Neurokit:\",atr_sample[:50])\n",
    "\n",
    "\n",
    "idx_lst = list(range(1, len(atr_sample)-1))  # pastaba: idx_lst sąrašas nuo 1 iki atr_sample-2\n",
    "\n",
    "# Formuojame iš pūpsnių požymių masyvą: data_frame yra tik tos eilutės,\n",
    "# kurių indeksai nepapuolė į omitted (atitinka automatines anotacijas 'U')\n",
    "df_attr_features_be_U, omitted = get_beat_features_set_fda_vu_v1_micro(signal, atr_sample, idx_lst)\n",
    "\n",
    "data_frame = df_attr_features_be_U.set_index('idx')\n",
    "df_attr_features_be_U.columns = df_attr_features_be_U.columns.astype(str)\n",
    "\n",
    "# paruošiame požymių masyvą klasifikatoriui\n",
    "test_x = df_attr_features_be_U[all_features]\n",
    "x_test = scaler.transform(test_x)\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "# print(\"len(test_x):\", len(test_x))\n",
    "\n",
    "# Pūpsnių klasių atpažinimas (ML anotacijos)\n",
    "predictions = model.predict(x_test)\n",
    "atr_labels_be_U = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "# //////////////// PARUOŠIAME DUOMENŲ MASYVUS KLASTERIZACIJAI  //////////////////////////////////\n",
    "# Čia įdėsime filtravimą 0.5 Hz\n",
    "# .....................\n",
    "# .....................\n",
    "# .....................\n",
    "\n",
    "\n",
    "# Parengiame R pikų ir ML anotacijų masyvus taip, kad juose nebūtų elementų iš omitted,\n",
    "# taip pat atmetame reikšmes su indeksu 1 ir len(atr_sample)-1)\n",
    "\n",
    "# Atmetame reikšmes su indeksu 1 ir len(atr_sample)-1)\n",
    "atr_sample = atr_sample[idx_lst]\n",
    "print(\"atmetus 1 ir paskutini:\",len(atr_sample))\n",
    "print(\"atmetus 1 ir paskutini:\", atr_sample[:50])\n",
    "\n",
    "# Suformuojame atr_sample_be_U\n",
    "idxs_su_U = []\n",
    "if (not omitted.empty):\n",
    "    idxs_su_U = list(omitted['idx'])\n",
    "    print(\"idxs_su_U:\",idxs_su_U)\n",
    "    atr_sample_be_U = np.asarray([atr_sample[item] for item in range(len(atr_sample)) if (item not in idxs_su_U)])\n",
    "print(\"atmetus su 'U':\",len(atr_sample_be_U))\n",
    "print(\"atr_sample_be_U:\", atr_sample_be_U[:50])\n",
    "\n",
    "# Suformuojame atr_symbol_be_U panaudodami atpažintus atr_labels_be_U\n",
    "invers_all_beats = {v: k for k, v in all_beats.items()}\n",
    "atr_symbol_be_U = np.array([invers_all_beats[sample] for sample in atr_labels_be_U])\n",
    "print(\"atr_symbol_be_U:\",atr_symbol_be_U[:50])\n",
    "\n",
    "# Pūpsnių statistika\n",
    "(unique, counts) = np.unique(atr_symbol_be_U, return_counts=True)\n",
    "total = counts.sum()\n",
    "print(\"class labels: \", unique, counts, total)\n",
    "\n",
    "# Pridedame atributus atr_sample_be_U, atr_symbol_be_U prie požymių datafreimo,\n",
    "# skirto klasterizacijai\n",
    "df_attr_features_be_U['atr_sample'] = atr_sample_be_U\n",
    "df_attr_features_be_U['atr_symbol'] = atr_symbol_be_U\n",
    "# print(\"\\nMasyvas be U: df_attr_features_be_U len:\", len(df_attr_features_be_U) )\n",
    "# print(df_attr_features_be_U.columns)\n",
    "\n",
    "# Šitoj vietoj turime:\n",
    "# atr_sample_be_U\n",
    "# atr_labels_be_U\n",
    "# atr_symbol_be_U\n",
    "# df_attr_features_be_U\n",
    "\n",
    "\n",
    "# # Suformuojame masyvą su `U` df_attr_su_U, kuris bus naudojamas kaip atskiras klasteris\n",
    "# # df_attr_su_U = pd.DataFrame(columns=['atr_sample', 'atr_symbol',  'cluster'])\n",
    "df_attr_su_U = pd.DataFrame()\n",
    "if (idxs_su_U):\n",
    "    attr_su_U = []\n",
    "    for item in idxs_su_U:\n",
    "        dict_tmp = {\n",
    "            'idx': item,\n",
    "            'atr_sample': atr_sample[item],\n",
    "            'atr_symbol': 'U',\n",
    "            'cluster': 0\n",
    "        }\n",
    "        attr_su_U.append(dict_tmp)\n",
    "    df_attr_su_U = pd.DataFrame(attr_su_U)\n",
    "# print(\"\\nKlasteris su U: df_attr_su_U len:\", len(df_attr_su_U) )\n",
    "# print(df_attr_su_U.head())\n",
    "\n",
    "# end_time = time.time()\n",
    "# print('\\npožymiai:')\n",
    "# runtime(end_time-start_time)\n",
    "\n",
    "\n",
    "# /////////////////  ML anotacijų N, S, V grupių klasterizacija. Anotacijos U neklasterizuojamos\n",
    "\n",
    "# Išvedame įrašo atributus\n",
    "userId, recId, file_name = get_recId(rec_dir, userNr, recNr)\n",
    "print(f\"\\nSubjCode: {SubjCode} userNr: {userNr:>2}\")\n",
    "print(f\"file_name: {file_name:>2} userId: {userId} recId: {recId} signal_length: {signal_length}\")\n",
    "\n",
    "# Bendra įrašo anotacijų (atmetus U) statistika\n",
    "atr_symbol_group = np.array(list(df_attr_features_be_U['atr_symbol']))\n",
    "(unique, counts) = np.unique(atr_symbol_group, return_counts=True)\n",
    "total = counts.sum()\n",
    "print(\"\\nBendra N, S ir V statistika įraše:\")\n",
    "print(f'statistika: {unique} {counts} {total}')\n",
    "print(\"U skaičius:\", len(df_attr_su_U))\n",
    "\n",
    "# Sugrupuojame atributus pagal ML grupes\n",
    "ml_groups = df_attr_features_be_U.groupby(['atr_symbol'])\n",
    "\n",
    "# start1\n",
    "\n",
    "# Klasterizuojame ML grupes  N, S, V kiekvieną atskirai\n",
    "# N grupės klasterizacija\n",
    "print(\"\\nInformacija apie klasterius:\")\n",
    "list_dict_clusters_full = []\n",
    "\n",
    "if 'N' in ml_groups.groups.keys():\n",
    "    df_attr_features_ml_group_N = ml_groups.get_group('N')\n",
    "    n_clusters_N = get_clusters_n(len(df_attr_features_ml_group_N))\n",
    "    df_attr_ml_group_N = clustering(df_attr_features_ml_group_N, all_features, scaler, n_clusters_N)\n",
    "    list_dict_clusters = get_rpeaks_of_clusters(df_attr_ml_group_N)\n",
    "    print(\"\\nKlasteriai su 'N' anotacija:\")\n",
    "    print(list_dict_clusters)\n",
    "    list_dict_clusters_full.append({'atr_symbol': 'N', \"clusters\":list_dict_clusters})\n",
    "\n",
    "    # print(\"\\nMasyvas su papildomu parametru:\")\n",
    "    # print(list_dict_clusters_N)\n",
    "    # print(\"\\nMasyvas be papildomo parametro:\")\n",
    "    # print(list_dict_clusters)\n",
    "    # show_beats_in_group(signal, df_attr_ml_group_N, 'N', w_side, min, max, fig_width, fig_height, max_graphs, False)\n",
    "\n",
    "# S grupės klasterizacija\n",
    "if 'S' in ml_groups.groups.keys():\n",
    "    df_attr_features_ml_group_S = ml_groups.get_group('S')\n",
    "    n_clusters_S = get_clusters_n(len(df_attr_features_ml_group_S))\n",
    "    df_attr_ml_group_S = clustering(df_attr_features_ml_group_S, all_features, scaler, n_clusters_S)\n",
    "    list_dict_clusters = get_rpeaks_of_clusters(df_attr_ml_group_S)\n",
    "    print(\"\\nKlasteriai su 'S' anotacija:\")\n",
    "    print(list_dict_clusters)\n",
    "    list_dict_clusters = get_rpeaks_of_clusters(df_attr_ml_group_S)\n",
    "    list_dict_clusters_full.append({'atr_symbol': 'S', \"clusters\":list_dict_clusters})\n",
    "\n",
    "    # show_beats_in_group(signal, df_attr_ml_group_S, 'S', w_side, min, max, fig_width, fig_height, max_graphs, print_rpeaks)\n",
    "\n",
    "\n",
    "# V grupės klasterizacija\n",
    "if 'V' in ml_groups.groups.keys():\n",
    "    df_attr_features_ml_group_V = ml_groups.get_group('V')\n",
    "    n_clusters_V = get_clusters_n(len(df_attr_features_ml_group_V))\n",
    "    df_attr_ml_group_V = clustering(df_attr_features_ml_group_V, all_features, scaler, n_clusters_V)\n",
    "    \n",
    "    # print()\n",
    "    # for index, row in df_attr_ml_group_V.iterrows():\n",
    "    #     if (row[\"idx\"] < 10):\n",
    "    #         row_string = f'idx: {row[\"idx\"]} atr_sample: {row[\"atr_sample\"]} atr_symbol: {row[\"atr_symbol\"]} cluster: {row[\"cluster\"]}'\n",
    "    #         print (row_string)\n",
    "\n",
    "    list_dict_clusters = get_rpeaks_of_clusters(df_attr_ml_group_V)\n",
    "    print(\"\\nKlasteriai su 'V' anotacija:\")\n",
    "    print(list_dict_clusters)\n",
    "    list_dict_clusters = get_rpeaks_of_clusters(df_attr_ml_group_V)\n",
    "    list_dict_clusters_full.append({'atr_symbol': 'V', \"clusters\":list_dict_clusters})\n",
    "    # show_beats_in_group(signal, df_attr_ml_group_V, 'V', w_side, min, max, fig_width, fig_height, max_graphs, print_rpeaks)\n",
    "\n",
    "# Rodome klasterių grafikus grupei U\n",
    "if (not df_attr_su_U.empty and U_flag):\n",
    "    # print()\n",
    "    # for index, row in df_attr_su_U.iterrows():\n",
    "    #     # if (row[\"idx\"] < 10):\n",
    "    #     row_string = f'idx: {row[\"idx\"]} atr_sample: {row[\"atr_sample\"]} atr_symbol: {row[\"atr_symbol\"]} cluster: {row[\"cluster\"]}'\n",
    "    #     print (row_string)\n",
    "\n",
    "    # # Papildome atributus klasterių numeriais \n",
    "    # yhat = np.zeros(len(df_attr_su_U), int)\n",
    "    # df_attr_su_U['cluster'] = list(yhat)\n",
    "\n",
    "    # print()\n",
    "    # for index, row in df_attr_su_U.iterrows():\n",
    "    #     # if (row[\"idx\"] < 10):\n",
    "    #     row_string = f'idx: {row[\"idx\"]} atr_sample: {row[\"atr_sample\"]} atr_symbol: {row[\"atr_symbol\"]} cluster: {row[\"cluster\"]}'\n",
    "    #     print (row_string)\n",
    "\n",
    "    list_dict_clusters = get_rpeaks_of_clusters(df_attr_su_U)\n",
    "    print(\"\\nKlasteris su 'U' anotacija:\")\n",
    "    print(list_dict_clusters)\n",
    "    list_dict_clusters_full.append({'atr_symbol': 'U', \"clusters\":list_dict_clusters})\n",
    "    # show_beats_in_group(signal, df_attr_su_U, 'U', w_side, min, max, fig_width, fig_height, max_graphs, print_rpeaks)    \n",
    "\n",
    "print(\"\\nvisi klaster rpeaks\")\n",
    "print(list_dict_clusters_full)\n",
    "\n",
    "# Serializuojame ir įrašome į failą\n",
    "json_object = json.dumps(list_dict_clusters_full)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"visi_clusters_rpeaks.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "print(\"\\nlist_dict_clusters_full įrašytas į: visi_clusters_rpeaks.json\")\n",
    "\n",
    "end_time = time.time()\n",
    "runtime(end_time-start_time)\n",
    "\n",
    "# mark2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_lnx38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72fad068c9d13e52ed0ef400fe86b8a1dd89b57112dd527cb7ae681e2ac89056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
